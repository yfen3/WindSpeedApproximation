{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85e59f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version is 3.1.1\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the data for expeirment\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "import seaborn as sns\n",
    "import TsModel\n",
    "import GprModel\n",
    "import TsModel_constant\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Keras version is {keras.__version__}\")\n",
    "print(f\"Num GPUs Available: {torch.cuda.device_count()}\")\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa034de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp27_results = {\n",
    "    'tsl_train_accuracy' : tsl_train_accuracy,\n",
    "    'tsl_test_accuracy' :tsl_test_accuracy,\n",
    "    'tsl_r2s':tsl_r2s,\n",
    "    'tsl_time': tsl_time,\n",
    "    'tsc_train_accuracy':tsc_train_accuracy,\n",
    "    'tsc_test_accuracy':tsc_test_accuracy,\n",
    "    'tsc_r2s':tsc_r2s,\n",
    "    'tsc_time':tsc_time,\n",
    "    'gp_tsl_train_accuracy':gp_tsl_train_accuracy,\n",
    "    'gp_tsl_test_accuracy':gp_tsl_test_accuracy,\n",
    "    'gp_tsl_r2s':gp_tsl_r2s,\n",
    "    'gp_tsl_time':gp_tsl_time,\n",
    "    'gp_tsc_train_accuracy':gp_tsc_train_accuracy,\n",
    "    'gp_tsc_test_accuracy':gp_tsc_test_accuracy,\n",
    "    'gp_tsc_r2s':gp_tsc_r2s,\n",
    "    'gp_tsc_time':gp_tsc_time,\n",
    "    'gp_nn_tsl_train_accuracy':gp_nn_tsl_train_accuracy,\n",
    "    'gp_nn_tsl_test_accuracy':gp_nn_tsl_test_accuracy,\n",
    "    'gp_nn_tsl_r2s':gp_nn_tsl_r2s,\n",
    "    'nn_tsl_r2s':nn_tsl_r2s,\n",
    "    'gp_nn_tsl_time':gp_nn_tsl_time,\n",
    "    'gp_nn_tsc_train_accuracy':gp_nn_tsc_train_accuracy,\n",
    "    'gp_nn_tsc_test_accuracy':gp_nn_tsc_test_accuracy,\n",
    "    'gp_nn_tsc_r2s':gp_nn_tsc_r2s,\n",
    "    'nn_tsc_r2s':nn_tsc_r2s,\n",
    "    'gp_nn_tsc_time':gp_nn_tsc_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2102da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'exp27_results' (dict)\n"
     ]
    }
   ],
   "source": [
    "#%store exp27_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6605d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the solar data set\n",
    "x_train = pd.read_csv('Data/FES/solar2_x_train.csv')\n",
    "x_test = pd.read_csv('Data/FES/solar2_x_test.csv')\n",
    "y_train = pd.read_csv('Data/FES/solar2_y_train.csv')\n",
    "y_test = pd.read_csv('Data/FES/solar2_y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9fe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_folds = 10\n",
    "\n",
    "# Source: From the TSmodel\n",
    "def preprocess_data(train_x, test_x, train_y, test_y):\n",
    "    feature_scaler = StandardScaler()\n",
    "    scaled_train_x = feature_scaler.fit_transform(train_x)\n",
    "    scaled_test_x = feature_scaler.transform(test_x)\n",
    "\n",
    "    # target_scaler = StandardScaler()  \n",
    "    # scaled_train_y = target_scaler.fit_transform(train_y)\n",
    "    # scaled_test_y = target_scaler.transform(test_y)    \n",
    "    # return scaled_train_x, scaled_test_x, scaled_train_y, scaled_test_y, feature_scaler, target_scaler    \n",
    "\n",
    "    return scaled_train_x, scaled_test_x, feature_scaler    \n",
    "\n",
    "def build_neural_network_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(1, activation=keras.activations.relu))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da3320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, feature_scaler = preprocess_data(x_train, x_test, y_train, y_test)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "529b9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nn_exp():\n",
    "    neural_network_model = build_neural_network_model()\n",
    "\n",
    "    neural_network_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = neural_network_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        epochs=200, \n",
    "        shuffle=True\n",
    "    )\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    print(f'time used: {time_used}')\n",
    "\n",
    "    return neural_network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b0fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19701040.0000 - root_mean_squared_error: 4366.4409\n",
      "Epoch 2/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24217564.0000 - root_mean_squared_error: 4843.8818\n",
      "Epoch 3/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18489640.0000 - root_mean_squared_error: 4266.4468\n",
      "Epoch 4/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15091379.0000 - root_mean_squared_error: 3816.8047\n",
      "Epoch 5/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18977292.0000 - root_mean_squared_error: 4328.4956\n",
      "Epoch 6/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12045947.0000 - root_mean_squared_error: 3427.9216\n",
      "Epoch 7/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17032314.0000 - root_mean_squared_error: 4054.2266\n",
      "Epoch 8/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16926220.0000 - root_mean_squared_error: 4077.7678\n",
      "Epoch 9/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19685632.0000 - root_mean_squared_error: 4410.4048\n",
      "Epoch 10/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13530560.0000 - root_mean_squared_error: 3586.4221\n",
      "Epoch 11/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 26878504.0000 - root_mean_squared_error: 5040.8921\n",
      "Epoch 12/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24743958.0000 - root_mean_squared_error: 4936.2471\n",
      "Epoch 13/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23104766.0000 - root_mean_squared_error: 4771.0327\n",
      "Epoch 14/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13999445.0000 - root_mean_squared_error: 3680.7922\n",
      "Epoch 15/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18012816.0000 - root_mean_squared_error: 4150.6689\n",
      "Epoch 16/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20130302.0000 - root_mean_squared_error: 4410.3086\n",
      "Epoch 17/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20945690.0000 - root_mean_squared_error: 4499.1895\n",
      "Epoch 18/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17172830.0000 - root_mean_squared_error: 4094.4453\n",
      "Epoch 19/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20599864.0000 - root_mean_squared_error: 4458.8965\n",
      "Epoch 20/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13217492.0000 - root_mean_squared_error: 3568.9839\n",
      "Epoch 21/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13509303.0000 - root_mean_squared_error: 3593.4932\n",
      "Epoch 22/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21435498.0000 - root_mean_squared_error: 4549.4629\n",
      "Epoch 23/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18411376.0000 - root_mean_squared_error: 4152.1416\n",
      "Epoch 24/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15818407.0000 - root_mean_squared_error: 3875.2554\n",
      "Epoch 25/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20873618.0000 - root_mean_squared_error: 4516.8511\n",
      "Epoch 26/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17499452.0000 - root_mean_squared_error: 4152.9390\n",
      "Epoch 27/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16953496.0000 - root_mean_squared_error: 4089.7827\n",
      "Epoch 28/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21074360.0000 - root_mean_squared_error: 4454.0396\n",
      "Epoch 29/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18697294.0000 - root_mean_squared_error: 4283.7329\n",
      "Epoch 30/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12606653.0000 - root_mean_squared_error: 3440.2915\n",
      "Epoch 31/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23946996.0000 - root_mean_squared_error: 4508.6968\n",
      "Epoch 32/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12034808.0000 - root_mean_squared_error: 3425.5859\n",
      "Epoch 33/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20289374.0000 - root_mean_squared_error: 4446.3320\n",
      "Epoch 34/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19843270.0000 - root_mean_squared_error: 4280.3491\n",
      "Epoch 35/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11342709.0000 - root_mean_squared_error: 3251.9214\n",
      "Epoch 36/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14572106.0000 - root_mean_squared_error: 3738.9070\n",
      "Epoch 37/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12465699.0000 - root_mean_squared_error: 3395.2654\n",
      "Epoch 38/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15040780.0000 - root_mean_squared_error: 3797.1721\n",
      "Epoch 39/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9876749.0000 - root_mean_squared_error: 3070.2305\n",
      "Epoch 40/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12790234.0000 - root_mean_squared_error: 3543.2261\n",
      "Epoch 41/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13165743.0000 - root_mean_squared_error: 3520.6128\n",
      "Epoch 42/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18082000.0000 - root_mean_squared_error: 4201.4727\n",
      "Epoch 43/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19293814.0000 - root_mean_squared_error: 4179.7319\n",
      "Epoch 44/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10585018.0000 - root_mean_squared_error: 3094.6348\n",
      "Epoch 45/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16744104.0000 - root_mean_squared_error: 4003.2131\n",
      "Epoch 46/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12873147.0000 - root_mean_squared_error: 3466.1721\n",
      "Epoch 47/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15111460.0000 - root_mean_squared_error: 3742.0425\n",
      "Epoch 48/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15530355.0000 - root_mean_squared_error: 3912.1785\n",
      "Epoch 49/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15021644.0000 - root_mean_squared_error: 3763.6992\n",
      "Epoch 50/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4634680.5000 - root_mean_squared_error: 2000.2335\n",
      "Epoch 51/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23071516.0000 - root_mean_squared_error: 4736.4443\n",
      "Epoch 52/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20168972.0000 - root_mean_squared_error: 4391.3022\n",
      "Epoch 53/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15001835.0000 - root_mean_squared_error: 3785.1499\n",
      "Epoch 54/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11902940.0000 - root_mean_squared_error: 3389.2617\n",
      "Epoch 55/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13602814.0000 - root_mean_squared_error: 3590.9287\n",
      "Epoch 56/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9420926.0000 - root_mean_squared_error: 3000.4719\n",
      "Epoch 57/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11114895.0000 - root_mean_squared_error: 3295.9583\n",
      "Epoch 58/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8702623.0000 - root_mean_squared_error: 2705.7607\n",
      "Epoch 59/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11271485.0000 - root_mean_squared_error: 3293.3479\n",
      "Epoch 60/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11359876.0000 - root_mean_squared_error: 3284.4465\n",
      "Epoch 61/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16541114.0000 - root_mean_squared_error: 3973.2083\n",
      "Epoch 62/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8861265.0000 - root_mean_squared_error: 2831.2664\n",
      "Epoch 63/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17443600.0000 - root_mean_squared_error: 4047.6335\n",
      "Epoch 64/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13044536.0000 - root_mean_squared_error: 3432.7036\n",
      "Epoch 65/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19491394.0000 - root_mean_squared_error: 4363.4370\n",
      "Epoch 66/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10620977.0000 - root_mean_squared_error: 3112.9575\n",
      "Epoch 67/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14339277.0000 - root_mean_squared_error: 3751.3396\n",
      "Epoch 68/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10125124.0000 - root_mean_squared_error: 3033.8806\n",
      "Epoch 69/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16439743.0000 - root_mean_squared_error: 3938.7107\n",
      "Epoch 70/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27480192.0000 - root_mean_squared_error: 5033.0186\n",
      "Epoch 71/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10968910.0000 - root_mean_squared_error: 3197.1021\n",
      "Epoch 72/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14824832.0000 - root_mean_squared_error: 3745.5320\n",
      "Epoch 73/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17497132.0000 - root_mean_squared_error: 4143.2075\n",
      "Epoch 74/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12549228.0000 - root_mean_squared_error: 3489.2595\n",
      "Epoch 75/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17384922.0000 - root_mean_squared_error: 4129.5742\n",
      "Epoch 76/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20804812.0000 - root_mean_squared_error: 4426.7817\n",
      "Epoch 77/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11453790.0000 - root_mean_squared_error: 3221.1377\n",
      "Epoch 78/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20763970.0000 - root_mean_squared_error: 4283.0098\n",
      "Epoch 79/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12657162.0000 - root_mean_squared_error: 3473.8357\n",
      "Epoch 80/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9016260.0000 - root_mean_squared_error: 2953.1116\n",
      "Epoch 81/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14829793.0000 - root_mean_squared_error: 3766.8472\n",
      "Epoch 82/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10646002.0000 - root_mean_squared_error: 3049.0889\n",
      "Epoch 83/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13670582.0000 - root_mean_squared_error: 3666.5903\n",
      "Epoch 84/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12550306.0000 - root_mean_squared_error: 3448.8389\n",
      "Epoch 85/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18307558.0000 - root_mean_squared_error: 4236.6289\n",
      "Epoch 86/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16479145.0000 - root_mean_squared_error: 4039.1555\n",
      "Epoch 87/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11416955.0000 - root_mean_squared_error: 3308.2476\n",
      "Epoch 88/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14743740.0000 - root_mean_squared_error: 3737.9592\n",
      "Epoch 89/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18252170.0000 - root_mean_squared_error: 4158.7847\n",
      "Epoch 90/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15651819.0000 - root_mean_squared_error: 3890.3423\n",
      "Epoch 91/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13565180.0000 - root_mean_squared_error: 3636.6418\n",
      "Epoch 92/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14932701.0000 - root_mean_squared_error: 3774.6204\n",
      "Epoch 93/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10636645.0000 - root_mean_squared_error: 3194.8013\n",
      "Epoch 94/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13832846.0000 - root_mean_squared_error: 3660.8916\n",
      "Epoch 95/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16145454.0000 - root_mean_squared_error: 3979.4197\n",
      "Epoch 96/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14477688.0000 - root_mean_squared_error: 3773.9915\n",
      "Epoch 97/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11100184.0000 - root_mean_squared_error: 3282.3333\n",
      "Epoch 98/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9977047.0000 - root_mean_squared_error: 3039.3926\n",
      "Epoch 99/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9108896.0000 - root_mean_squared_error: 2903.7495\n",
      "Epoch 100/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22046950.0000 - root_mean_squared_error: 4398.4390\n",
      "Epoch 101/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15415147.0000 - root_mean_squared_error: 3815.7698\n",
      "Epoch 102/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19953356.0000 - root_mean_squared_error: 4343.7524\n",
      "Epoch 103/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8835432.0000 - root_mean_squared_error: 2747.6541\n",
      "Epoch 104/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17375418.0000 - root_mean_squared_error: 4057.6404\n",
      "Epoch 105/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12330453.0000 - root_mean_squared_error: 3480.5405\n",
      "Epoch 106/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11996596.0000 - root_mean_squared_error: 3377.8506\n",
      "Epoch 107/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13655188.0000 - root_mean_squared_error: 3599.1101\n",
      "Epoch 108/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17016966.0000 - root_mean_squared_error: 3982.0403\n",
      "Epoch 109/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10442156.0000 - root_mean_squared_error: 3186.4248\n",
      "Epoch 110/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10360080.0000 - root_mean_squared_error: 3136.7290\n",
      "Epoch 111/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12362602.0000 - root_mean_squared_error: 3378.4751\n",
      "Epoch 112/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16245837.0000 - root_mean_squared_error: 4013.7461\n",
      "Epoch 113/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8546536.0000 - root_mean_squared_error: 2755.7288\n",
      "Epoch 114/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19737094.0000 - root_mean_squared_error: 4343.0811\n",
      "Epoch 115/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17786984.0000 - root_mean_squared_error: 4119.1411\n",
      "Epoch 116/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10391170.0000 - root_mean_squared_error: 3170.4832\n",
      "Epoch 117/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15363116.0000 - root_mean_squared_error: 3745.8813\n",
      "Epoch 118/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9241306.0000 - root_mean_squared_error: 2932.8000\n",
      "Epoch 119/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11548248.0000 - root_mean_squared_error: 3335.1826\n",
      "Epoch 120/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11294957.0000 - root_mean_squared_error: 3269.4028\n",
      "Epoch 121/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9525989.0000 - root_mean_squared_error: 2986.1394\n",
      "Epoch 122/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15505749.0000 - root_mean_squared_error: 3764.9824\n",
      "Epoch 123/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15051365.0000 - root_mean_squared_error: 3810.7712\n",
      "Epoch 124/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14627786.0000 - root_mean_squared_error: 3703.3740\n",
      "Epoch 125/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17103448.0000 - root_mean_squared_error: 4074.0850\n",
      "Epoch 126/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11516691.0000 - root_mean_squared_error: 3353.2332\n",
      "Epoch 127/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10046730.0000 - root_mean_squared_error: 3068.5176\n",
      "Epoch 128/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15608923.0000 - root_mean_squared_error: 3905.5125\n",
      "Epoch 129/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15246958.0000 - root_mean_squared_error: 3845.3730\n",
      "Epoch 130/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16584432.0000 - root_mean_squared_error: 3989.9414\n",
      "Epoch 131/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10855964.0000 - root_mean_squared_error: 3099.8538\n",
      "Epoch 132/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12182748.0000 - root_mean_squared_error: 3371.8027\n",
      "Epoch 133/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11523666.0000 - root_mean_squared_error: 3293.3020\n",
      "Epoch 134/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10538379.0000 - root_mean_squared_error: 3173.3989\n",
      "Epoch 135/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 24561738.0000 - root_mean_squared_error: 4770.3218\n",
      "Epoch 136/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14830587.0000 - root_mean_squared_error: 3752.8867\n",
      "Epoch 137/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12538892.0000 - root_mean_squared_error: 3404.4082\n",
      "Epoch 138/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15663235.0000 - root_mean_squared_error: 3882.7939\n",
      "Epoch 139/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11520009.0000 - root_mean_squared_error: 3297.4482\n",
      "Epoch 140/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19542866.0000 - root_mean_squared_error: 4306.3984\n",
      "Epoch 141/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7557581.0000 - root_mean_squared_error: 2646.5732\n",
      "Epoch 142/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11017353.0000 - root_mean_squared_error: 3215.8210\n",
      "Epoch 143/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10928622.0000 - root_mean_squared_error: 3189.1418\n",
      "Epoch 144/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12719760.0000 - root_mean_squared_error: 3517.2703\n",
      "Epoch 145/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15258761.0000 - root_mean_squared_error: 3848.0847\n",
      "Epoch 146/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20245890.0000 - root_mean_squared_error: 4316.5581\n",
      "Epoch 147/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9940365.0000 - root_mean_squared_error: 3030.6638\n",
      "Epoch 148/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14599473.0000 - root_mean_squared_error: 3694.0566\n",
      "Epoch 149/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20824256.0000 - root_mean_squared_error: 4397.4434\n",
      "Epoch 150/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25598076.0000 - root_mean_squared_error: 4771.5713\n",
      "Epoch 151/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17757458.0000 - root_mean_squared_error: 4189.6509\n",
      "Epoch 152/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12079759.0000 - root_mean_squared_error: 3422.7893\n",
      "Epoch 153/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9903136.0000 - root_mean_squared_error: 3024.2893\n",
      "Epoch 154/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14426478.0000 - root_mean_squared_error: 3772.2476\n",
      "Epoch 155/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17059956.0000 - root_mean_squared_error: 4055.8203\n",
      "Epoch 156/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20867848.0000 - root_mean_squared_error: 4488.8442\n",
      "Epoch 157/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10088801.0000 - root_mean_squared_error: 2966.1829\n",
      "Epoch 158/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14638003.0000 - root_mean_squared_error: 3720.6270\n",
      "Epoch 159/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18705566.0000 - root_mean_squared_error: 4192.5625\n",
      "Epoch 160/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12487461.0000 - root_mean_squared_error: 3487.4851\n",
      "Epoch 161/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23969246.0000 - root_mean_squared_error: 4665.6841\n",
      "Epoch 162/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15909729.0000 - root_mean_squared_error: 3930.3821\n",
      "Epoch 163/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17067970.0000 - root_mean_squared_error: 3997.3210\n",
      "Epoch 164/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12260355.0000 - root_mean_squared_error: 3388.7766\n",
      "Epoch 165/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9607922.0000 - root_mean_squared_error: 2907.6467\n",
      "Epoch 166/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12078389.0000 - root_mean_squared_error: 3413.4072\n",
      "Epoch 167/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22239650.0000 - root_mean_squared_error: 4566.2671\n",
      "Epoch 168/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19534468.0000 - root_mean_squared_error: 4383.4209\n",
      "Epoch 169/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15403195.0000 - root_mean_squared_error: 3727.6106\n",
      "Epoch 170/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14008013.0000 - root_mean_squared_error: 3685.9470\n",
      "Epoch 171/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10722644.0000 - root_mean_squared_error: 3232.0425\n",
      "Epoch 172/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13257633.0000 - root_mean_squared_error: 3547.0835\n",
      "Epoch 173/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16139132.0000 - root_mean_squared_error: 3971.4312\n",
      "Epoch 174/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26238068.0000 - root_mean_squared_error: 4893.8828\n",
      "Epoch 175/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16938010.0000 - root_mean_squared_error: 4018.9038\n",
      "Epoch 176/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14945816.0000 - root_mean_squared_error: 3808.5098\n",
      "Epoch 177/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13076326.0000 - root_mean_squared_error: 3494.7986\n",
      "Epoch 178/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14261354.0000 - root_mean_squared_error: 3631.1799\n",
      "Epoch 179/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11375748.0000 - root_mean_squared_error: 3282.7588\n",
      "Epoch 180/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16097347.0000 - root_mean_squared_error: 3953.4011\n",
      "Epoch 181/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13859268.0000 - root_mean_squared_error: 3679.0242\n",
      "Epoch 182/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17941112.0000 - root_mean_squared_error: 4199.6323\n",
      "Epoch 183/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17693448.0000 - root_mean_squared_error: 4137.4897\n",
      "Epoch 184/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17330810.0000 - root_mean_squared_error: 4119.3677\n",
      "Epoch 185/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10635875.0000 - root_mean_squared_error: 3112.8196\n",
      "Epoch 186/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11790707.0000 - root_mean_squared_error: 3391.0837\n",
      "Epoch 187/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14074434.0000 - root_mean_squared_error: 3662.6167\n",
      "Epoch 188/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13171117.0000 - root_mean_squared_error: 3576.0112\n",
      "Epoch 189/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14039419.0000 - root_mean_squared_error: 3712.1458\n",
      "Epoch 190/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13066865.0000 - root_mean_squared_error: 3572.7620\n",
      "Epoch 191/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18340542.0000 - root_mean_squared_error: 4175.0898\n",
      "Epoch 192/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 23131204.0000 - root_mean_squared_error: 4680.9072\n",
      "Epoch 193/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6036275.0000 - root_mean_squared_error: 2347.1162\n",
      "Epoch 194/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9137793.0000 - root_mean_squared_error: 2902.8992\n",
      "Epoch 195/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12590094.0000 - root_mean_squared_error: 3379.1746\n",
      "Epoch 196/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9280214.0000 - root_mean_squared_error: 2993.5251\n",
      "Epoch 197/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15664288.0000 - root_mean_squared_error: 3834.1477\n",
      "Epoch 198/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15152515.0000 - root_mean_squared_error: 3847.1699\n",
      "Epoch 199/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18495616.0000 - root_mean_squared_error: 4233.3408\n",
      "Epoch 200/200\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17981698.0000 - root_mean_squared_error: 4164.2891\n",
      "time used: 58.65141439437866\n"
     ]
    }
   ],
   "source": [
    "nn_model = do_nn_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25993f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_model.save('small_wind_turbine_nn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16800056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 3678.7893583953223\n",
      "FCM training RMSE: 3660.2964572324213\n",
      "FCM training RMSE: 3646.315740580821\n",
      "FCM training RMSE: 3659.016794216825\n",
      "FCM training RMSE: 3663.7835639433574\n",
      "FCM training RMSE: 3670.9343897557997\n",
      "FCM training RMSE: 3659.3620484088497\n",
      "FCM training RMSE: 3664.339857759407\n",
      "FCM training RMSE: 3676.3822555986544\n",
      "FCM training RMSE: 3653.0596309199104\n"
     ]
    }
   ],
   "source": [
    "# TS model\n",
    "# Linear conclusion\n",
    "\n",
    "def ts_relu_wrapper(pred):\n",
    "    return np.maximum(0, pred)\n",
    "\n",
    "# TS with linear conclusion\n",
    "tsl_train_accuracy = []\n",
    "tsl_test_accuracy = []\n",
    "tsl_r2s = []\n",
    "tsl_time = []\n",
    "tsl_model = None\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    ts_model = TsModel.TsModel(number_of_rules=25, fuzzification_coefficient=1.2)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ts_model.fit(x_train, y_train)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    tsl_train_pred = ts_relu_wrapper(ts_model.predict(x_train))\n",
    "    tsl_test_pred = ts_relu_wrapper(ts_model.predict(x_test))\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, tsl_train_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, tsl_test_pred)\n",
    "\n",
    "    tsl_train_accuracy.append(train_rmse)\n",
    "    tsl_test_accuracy.append(test_rmse)\n",
    "    tsl_r2 = r2_score(y_test, tsl_test_pred)\n",
    "    tsl_r2s.append(tsl_r2)\n",
    "    tsl_time.append(time_used)\n",
    "    tsl_model = ts_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6bc550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS Linear Train RMSE: 3661.832 ± 9.995\n",
      "TS Linear Test RMSE: 3971.672 ± 30.634\n",
      "TS Linear R2: 0.192 ± 0.012\n",
      "TS Linear Time: 0.559 ± 0.108\n"
     ]
    }
   ],
   "source": [
    "tsl_train_accuracy_mean = np.round(np.mean(tsl_train_accuracy), 3)\n",
    "tsl_train_accuracy_std = np.round(np.std(tsl_train_accuracy), 3)\n",
    "tsl_test_accuracy_mean = np.round(np.mean(tsl_test_accuracy), 3)\n",
    "tsl_test_accuracy_std = np.round(np.std(tsl_test_accuracy),3)\n",
    "tsl_r2_mean = np.round(np.mean(tsl_r2s),3)\n",
    "tsl_r2_std = np.round(np.std(tsl_r2s),3)\n",
    "tsl_time_mean = np.round(np.mean(tsl_time),3)\n",
    "tsl_time_std = np.round(np.std(tsl_time),3)\n",
    "\n",
    "print(f\"TS Linear Train RMSE: {tsl_train_accuracy_mean} ± {tsl_train_accuracy_std}\")\n",
    "print(f\"TS Linear Test RMSE: {tsl_test_accuracy_mean} ± {tsl_test_accuracy_std}\")\n",
    "print(f\"TS Linear R2: {tsl_r2_mean} ± {tsl_r2_std}\")\n",
    "print(f\"TS Linear Time: {tsl_time_mean} ± {tsl_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba9a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2281, 150)\n",
      "[[7.32792119e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.39623733e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.08463102e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.08385908e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.29541373e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.88274324e-13 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[7.32792119e-07 1.97844388e-08 4.71245135e-05 ... 6.63351971e-06\n",
      "  1.67023347e-09 8.85226867e-10]\n",
      " [1.39623733e-11 2.04584127e-10 5.90703492e-11 ... 1.01543271e-10\n",
      "  8.75418696e-11 2.61449876e-09]\n",
      " [9.08463102e-06 1.62217179e-05 7.52686544e-04 ... 9.82679546e-01\n",
      "  9.53090238e-06 1.82888765e-06]\n",
      " ...\n",
      " [1.08385908e-11 6.29947933e-11 1.01502809e-10 ... 2.75054132e-10\n",
      "  2.95706530e-09 2.00089854e-10]\n",
      " [7.29541373e-11 4.27933540e-10 7.16067388e-10 ... 1.83508161e-09\n",
      "  1.50935433e-08 1.39723087e-09]\n",
      " [8.88274324e-13 1.59208960e-11 8.85253339e-12 ... 1.50339955e-10\n",
      "  9.88216838e-09 8.58402478e-11]]\n",
      "FCM training RMSE: 3805.9222877919588\n",
      "(2281, 150)\n",
      "[[2.45485856e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.93109258e-12 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.74895499e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.77748412e-12 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.31755117e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.65603354e-13 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[2.45485856e-06 1.06153069e-09 1.23032471e-06 ... 1.32644334e-06\n",
      "  4.34503806e-09 2.38067433e-08]\n",
      " [8.93109258e-12 9.99901199e-01 6.65224518e-11 ... 7.81169033e-09\n",
      "  7.04800185e-10 1.25278199e-09]\n",
      " [1.74895499e-06 2.04408206e-07 5.51252945e-06 ... 1.55711891e-03\n",
      "  4.24297619e-06 1.44650460e-06]\n",
      " ...\n",
      " [4.77748412e-12 1.14601813e-08 2.22753223e-11 ... 1.69854336e-09\n",
      "  1.40064787e-07 1.39026137e-10]\n",
      " [4.31755117e-11 1.62540406e-07 2.11617236e-10 ... 1.94523536e-08\n",
      "  9.14662433e-07 1.39207839e-09]\n",
      " [4.65603354e-13 4.68636842e-10 2.31982522e-12 ... 5.57502766e-10\n",
      "  7.77376964e-06 1.55570019e-11]]\n",
      "FCM training RMSE: 3799.134413269917\n",
      "(2281, 150)\n",
      "[[2.97817480e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.32264253e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.15111227e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.00348439e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.25398296e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.42667425e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[2.97817480e-09 9.99842380e-01 1.04791204e-09 ... 4.32574856e-10\n",
      "  3.32078309e-07 1.00595431e-06]\n",
      " [2.32264253e-08 2.14979787e-11 1.00190248e-10 ... 3.28082900e-09\n",
      "  5.38959011e-09 6.33449988e-12]\n",
      " [1.15111227e-07 4.69133311e-05 9.44727628e-08 ... 1.98648424e-08\n",
      "  4.63442951e-05 7.01933528e-08]\n",
      " ...\n",
      " [8.00348439e-10 2.95542017e-11 2.94992125e-09 ... 9.99916179e-01\n",
      "  1.88205658e-09 6.01708556e-12]\n",
      " [6.25398296e-09 1.98490513e-10 1.51008049e-08 ... 9.99679994e-01\n",
      "  1.57048476e-08 3.96911578e-11]\n",
      " [2.42667425e-10 3.63474732e-12 8.85046448e-09 ... 6.66844504e-06\n",
      "  4.70367993e-10 4.28455010e-13]]\n",
      "FCM training RMSE: 3806.6741829278394\n",
      "(2281, 150)\n",
      "[[6.76026524e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.25792146e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.36074436e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.13214047e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.12702597e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.47169304e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[6.76026524e-07 3.76383496e-07 1.39437140e-08 ... 4.29231052e-09\n",
      "  1.68721176e-09 1.51850329e-06]\n",
      " [7.25792146e-08 6.14302262e-09 3.49110740e-07 ... 3.04570270e-09\n",
      "  9.99775478e-01 6.94387666e-10]\n",
      " [3.36074436e-06 2.09833944e-07 4.03874161e-08 ... 8.31631998e-08\n",
      "  1.06035411e-08 9.88641912e-08]\n",
      " ...\n",
      " [5.13214047e-09 6.62886470e-11 6.16451063e-10 ... 2.88093131e-09\n",
      "  1.11836289e-08 1.28571119e-11]\n",
      " [6.12702597e-08 6.55760583e-10 6.75376070e-09 ... 2.00987095e-08\n",
      "  1.55809533e-07 1.20797487e-10]\n",
      " [1.47169304e-07 3.38802743e-09 2.64072618e-08 ... 5.05355747e-06\n",
      "  3.97927841e-07 5.52622899e-10]]\n",
      "FCM training RMSE: 3808.5881558450674\n",
      "(2281, 150)\n",
      "[[3.23551354e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.92524504e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.17175587e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.22391198e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.47389636e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.84998031e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[3.23551354e-09 4.44780233e-09 3.71725077e-07 ... 1.17602821e-08\n",
      "  4.79963101e-06 3.42409039e-09]\n",
      " [7.92524504e-11 6.77352775e-10 6.08199044e-10 ... 3.34117238e-08\n",
      "  2.24244413e-11 2.48214925e-09]\n",
      " [2.17175587e-06 4.35122165e-06 4.29324281e-03 ... 4.01589791e-06\n",
      "  2.10271064e-05 2.53634927e-06]\n",
      " ...\n",
      " [2.22391198e-09 1.40963274e-07 3.04558684e-09 ... 7.55842555e-10\n",
      "  9.18369687e-12 7.49158180e-05]\n",
      " [1.47389636e-08 9.21697943e-07 2.79747383e-08 ... 8.11084838e-09\n",
      "  8.26007057e-11 3.82719901e-04]\n",
      " [7.84998031e-09 8.44040284e-06 6.87849935e-09 ... 3.32386040e-10\n",
      "  2.10126300e-12 9.99982571e-01]]\n",
      "FCM training RMSE: 3800.4724343461694\n",
      "(2281, 150)\n",
      "[[1.88437931e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.48762295e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.64685854e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.15297158e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.60881851e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.30279631e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[1.88437931e-09 1.72870542e-05 2.36051492e-09 ... 4.77141084e-05\n",
      "  2.77142219e-07 1.16191191e-04]\n",
      " [6.48762295e-06 5.31745031e-13 8.93092497e-09 ... 1.44368713e-13\n",
      "  2.81168746e-12 3.36304337e-12]\n",
      " [1.64685854e-07 7.42649130e-06 2.42346260e-07 ... 1.87337561e-06\n",
      "  2.57255444e-06 6.40075471e-05]\n",
      " ...\n",
      " [5.15297158e-07 4.77132568e-10 9.91596554e-08 ... 1.67707139e-10\n",
      "  1.52295382e-09 6.14953185e-09]\n",
      " [2.60881851e-06 1.65569296e-09 4.22714376e-07 ... 5.69963062e-10\n",
      "  5.41814670e-09 2.31297407e-08]\n",
      " [7.30279631e-07 8.86763393e-10 3.63410776e-07 ... 2.43864527e-10\n",
      "  3.17940278e-09 5.78478536e-09]]\n",
      "FCM training RMSE: 3808.067192910432\n",
      "(2281, 150)\n",
      "[[2.47342168e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.18741736e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.97939641e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.54912305e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42921735e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.96962690e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[2.47342168e-04 5.70071532e-05 1.21497295e-09 ... 1.45326655e-04\n",
      "  1.25851927e-08 2.83131088e-09]\n",
      " [1.18741736e-10 3.99474120e-12 9.99971880e-01 ... 6.44421744e-11\n",
      "  1.39070777e-08 4.11912394e-09]\n",
      " [9.97939641e-01 2.17514771e-06 7.40801168e-08 ... 4.12444217e-05\n",
      "  3.76091874e-07 2.20086838e-07]\n",
      " ...\n",
      " [1.54912305e-10 2.32226469e-12 1.09206659e-08 ... 5.60881564e-11\n",
      "  5.33092086e-10 1.81679924e-10]\n",
      " [1.42921735e-09 2.02992834e-11 1.51045893e-07 ... 5.36407776e-10\n",
      "  5.74993042e-09 1.74645026e-09]\n",
      " [7.96962690e-11 4.11031583e-13 7.62434780e-10 ... 6.28685737e-12\n",
      "  5.76451675e-11 1.01750621e-10]]\n",
      "FCM training RMSE: 3807.982347485733\n",
      "(2281, 150)\n",
      "[[5.22664143e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.21348573e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.39095632e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.39883801e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.10834107e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.76327058e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[5.22664143e-09 1.81243603e-09 1.33333284e-08 ... 2.46372570e-04\n",
      "  8.89155837e-08 4.07608430e-09]\n",
      " [2.21348573e-10 1.39816400e-09 1.95837233e-09 ... 3.84173767e-11\n",
      "  4.95699213e-09 4.33497457e-11]\n",
      " [1.39095632e-06 1.94673800e-07 1.09531516e-06 ... 9.97909481e-01\n",
      "  3.95753768e-05 8.24718880e-07]\n",
      " ...\n",
      " [1.39883801e-07 9.99923695e-01 2.89216261e-10 ... 1.54425192e-10\n",
      "  1.09928160e-06 2.69581891e-09]\n",
      " [9.10834107e-07 9.99597459e-01 2.89109199e-09 ... 1.42016247e-09\n",
      "  1.69749684e-05 1.86164021e-08]\n",
      " [7.76327058e-06 7.93492121e-06 1.33727639e-10 ... 7.45653520e-11\n",
      "  3.59534765e-07 1.07313302e-08]]\n",
      "FCM training RMSE: 3803.6692229696137\n",
      "(2281, 150)\n",
      "[[4.49729001e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.87644527e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.25038511e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.85116590e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.61576535e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99992557e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[4.49729001e-09 9.83901523e-09 6.72106572e-05 ... 1.44735300e-06\n",
      "  5.57349949e-06 1.19756071e-09]\n",
      " [8.87644527e-10 4.84693521e-10 4.65011224e-11 ... 4.00627158e-10\n",
      "  7.05955231e-12 9.99963217e-01]\n",
      " [8.25038511e-07 6.37868798e-07 9.66431710e-05 ... 6.20471229e-04\n",
      "  5.78393061e-06 5.49231917e-08]\n",
      " ...\n",
      " [7.85116590e-05 1.30183969e-10 1.64342082e-10 ... 4.51674730e-10\n",
      "  9.39152609e-12 1.25648506e-08]\n",
      " [3.61576535e-04 1.02369799e-09 1.34072876e-09 ... 3.77412682e-09\n",
      "  6.98429320e-11 1.47890013e-07]\n",
      " [9.99992557e-01 3.05246809e-11 7.61735504e-12 ... 1.23142875e-10\n",
      "  9.13111368e-13 2.28248182e-10]]\n",
      "FCM training RMSE: 3807.283782128258\n",
      "(2281, 150)\n",
      "[[4.37915913e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.56258948e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.66027550e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.38535064e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.06048738e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.37097750e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2281, 25)\n",
      "[[4.37915913e-09 3.54726107e-08 2.67107373e-07 ... 4.53675964e-09\n",
      "  6.00826790e-06 2.22165881e-09]\n",
      " [7.56258948e-08 6.57151634e-10 1.84844929e-09 ... 5.16749136e-11\n",
      "  8.65506770e-12 1.83899289e-09]\n",
      " [3.66027550e-08 5.64672584e-08 4.42097473e-05 ... 8.16108658e-08\n",
      "  6.32009523e-07 2.16622310e-08]\n",
      " ...\n",
      " [1.38535064e-09 2.05647737e-10 1.07152467e-07 ... 3.01961145e-09\n",
      "  1.00518638e-11 9.99914336e-01]\n",
      " [1.06048738e-08 1.45567103e-09 8.50706601e-07 ... 1.45459256e-08\n",
      "  6.29085222e-11 9.99688899e-01]\n",
      " [4.37097750e-10 1.66824256e-11 2.17292434e-07 ... 9.03105114e-09\n",
      "  1.60767973e-12 6.94049986e-06]]\n",
      "FCM training RMSE: 3798.1688115035645\n"
     ]
    }
   ],
   "source": [
    "# TS model\n",
    "# Constant conclusion\n",
    "tsc_train_accuracy = []\n",
    "tsc_test_accuracy = []\n",
    "tsc_r2s = []\n",
    "tsc_time = []\n",
    "tsc_model = None\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    ts_model = TsModel_constant.TsModel_constant(number_of_rules=25, fuzzification_coefficient=1.2)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ts_model.fit(x_train, y_train)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    tsc_train_pred = ts_relu_wrapper(ts_model.predict(x_train))\n",
    "    tsc_test_pred = ts_relu_wrapper(ts_model.predict(x_test))\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, tsc_train_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, tsc_test_pred)\n",
    "\n",
    "    tsc_train_accuracy.append(train_rmse)\n",
    "    tsc_test_accuracy.append(test_rmse)\n",
    "    tsc_r2 = r2_score(y_test, tsc_test_pred)\n",
    "    tsc_r2s.append(tsc_r2)\n",
    "    tsc_time.append(time_used)\n",
    "    tsc_model = ts_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122ffc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS Constant Train RMSE: 3804.596 ± 3.765\n",
      "TS Constant Test RMSE: 4036.276 ± 6.63\n",
      "TS Constant R2: 0.166 ± 0.003\n",
      "TS Constant Time: 0.532 ± 0.109\n"
     ]
    }
   ],
   "source": [
    "tsc_train_accuracy_mean = np.round(np.mean(tsc_train_accuracy), 3)\n",
    "tsc_train_accuracy_std = np.round(np.std(tsc_train_accuracy), 3)\n",
    "tsc_test_accuracy_mean = np.round(np.mean(tsc_test_accuracy), 3)\n",
    "tsc_test_accuracy_std = np.round(np.std(tsc_test_accuracy),3)\n",
    "tsc_r2_mean = np.round(np.mean(tsc_r2s),3)\n",
    "tsc_r2_std = np.round(np.std(tsc_r2s),3)\n",
    "tsc_time_mean = np.round(np.mean(tsc_time),3)\n",
    "tsc_time_std = np.round(np.std(tsc_time),3)\n",
    "\n",
    "print(f\"TS Constant Train RMSE: {tsc_train_accuracy_mean} ± {tsc_train_accuracy_std}\")\n",
    "print(f\"TS Constant Test RMSE: {tsc_test_accuracy_mean} ± {tsc_test_accuracy_std}\")\n",
    "print(f\"TS Constant R2: {tsc_r2_mean} ± {tsc_r2_std}\")\n",
    "print(f\"TS Constant Time: {tsc_time_mean} ± {tsc_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3646ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 3798.377 ± 0.0\n",
      "GP Test RMSE: 4041.761 ± 0.0\n",
      "GP R2: 0.163 ± 0.0\n",
      "GP Time: 0.028 ± 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_tsl_train_accuracy = []\n",
    "gp_tsl_test_accuracy = []\n",
    "gp_tsl_r2s = []\n",
    "gp_tsl_time = []\n",
    "gpr_tsl_model = None\n",
    "\n",
    "# From ts linear\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_tsl_model.fit(tsl_model.cen, tsl_model.predict(tsl_model.cen + 1e-8))\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_tsl_model.predict(x_train)\n",
    "    test_means = gpr_tsl_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_tsl_train_accuracy.append(train_rmse)\n",
    "    gp_tsl_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_tsl_r2s.append(gp_r2)\n",
    "    gp_tsl_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_tsl_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_tsl_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_tsl_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_tsl_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_tsl_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_tsl_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_tsl_time),3)\n",
    "gp_time_std = np.round(np.std(gp_tsl_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960ae86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 3791.361 ± 0.0\n",
      "GP Test RMSE: 4036.922 ± 0.0\n",
      "GP R2: 0.165 ± 0.0\n",
      "GP Time: 0.033 ± 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_tsc_train_accuracy = []\n",
    "gp_tsc_test_accuracy = []\n",
    "gp_tsc_r2s = []\n",
    "gp_tsc_time = []\n",
    "gpr_tsc_model = None\n",
    "\n",
    "# From ts constant\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_tsc_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_tsc_model.fit(tsc_model.cen, tsc_model.predict(tsc_model.cen + 1e-8))\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_tsc_model.predict(x_train)\n",
    "    test_means = gpr_tsc_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_tsc_train_accuracy.append(train_rmse)\n",
    "    gp_tsc_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_tsc_r2s.append(gp_r2)\n",
    "    gp_tsc_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_tsc_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_tsc_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_tsc_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_tsc_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_tsc_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_tsc_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_tsc_time),3)\n",
    "gp_time_std = np.round(np.std(gp_tsc_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d1d833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "GP Train RMSE: 3834.463 ± 0.0\n",
      "GP Test RMSE: 4049.936 ± 0.0\n",
      "GP R2: 0.16 ± 0.0\n",
      "GP Time: 0.031 ± 0.01\n",
      "TS NN R2: 0.899 ± 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_nn_tsl_train_accuracy = []\n",
    "gp_nn_tsl_test_accuracy = []\n",
    "gp_nn_tsl_r2s = []\n",
    "nn_tsl_r2s = []\n",
    "gp_nn_tsl_time = []\n",
    "gpr_nn_tsl_model = None\n",
    "\n",
    "# From NN and ts linear\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_nn_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    inputs = tsl_model.cen\n",
    "    ts_predictions = tsl_model.predict(tsl_model.cen + 1e-8)\n",
    "    nn_predictions = nn_model.predict(inputs)\n",
    "    gpr_nn_tsl_model.fit(inputs, nn_predictions)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_nn_tsl_model.predict(x_train)\n",
    "    test_means = gpr_nn_tsl_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_nn_tsl_train_accuracy.append(train_rmse)\n",
    "    gp_nn_tsl_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_nn_tsl_r2s.append(gp_r2)\n",
    "    gp_nn_tsl_time.append(time_used)\n",
    "    nn_tsl_r2s.append(r2_score(ts_predictions, nn_predictions))\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_nn_tsl_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_nn_tsl_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_nn_tsl_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_nn_tsl_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_nn_tsl_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_nn_tsl_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_nn_tsl_time),3)\n",
    "gp_time_std = np.round(np.std(gp_nn_tsl_time),3)\n",
    "nn_ts_r2_mean = np.round(np.mean(nn_tsl_r2s),3)\n",
    "nn_ts_r2_std = np.round(np.std(nn_tsl_r2s),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n",
    "print(f\"TS NN R2: {nn_ts_r2_mean} ± {nn_ts_r2_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f6c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "GP Train RMSE: 3847.208 ± 0.0\n",
      "GP Test RMSE: 4061.21 ± 0.0\n",
      "GP R2: 0.155 ± 0.0\n",
      "GP Time: 0.036 ± 0.01\n",
      "TS NN R2: 0.873 ± 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_nn_tsc_train_accuracy = []\n",
    "gp_nn_tsc_test_accuracy = []\n",
    "gp_nn_tsc_r2s = []\n",
    "nn_tsc_r2s = []\n",
    "gp_nn_tsc_time = []\n",
    "gpr_nn_tsc_model = None\n",
    "\n",
    "# From NN and ts constant\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_nn_tsc_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    inputs = tsc_model.cen\n",
    "    ts_predictions = tsc_model.predict(tsc_model.cen + 1e-8)\n",
    "    nn_predictions = nn_model.predict(inputs)\n",
    "    gpr_nn_tsc_model.fit(inputs, nn_predictions)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_nn_tsc_model.predict(x_train)\n",
    "    test_means = gpr_nn_tsc_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_nn_tsc_train_accuracy.append(train_rmse)\n",
    "    gp_nn_tsc_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_nn_tsc_r2s.append(gp_r2)\n",
    "    gp_nn_tsc_time.append(time_used)\n",
    "    nn_tsc_r2s.append(r2_score(ts_predictions, nn_predictions))\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_nn_tsc_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_nn_tsc_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_nn_tsc_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_nn_tsc_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_nn_tsc_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_nn_tsc_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_nn_tsc_time),3)\n",
    "gp_time_std = np.round(np.std(gp_nn_tsc_time),3)\n",
    "nn_ts_r2_mean = np.round(np.mean(nn_tsc_r2s),3)\n",
    "nn_ts_r2_std = np.round(np.std(nn_tsc_r2s),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n",
    "print(f\"TS NN R2: {nn_ts_r2_mean} ± {nn_ts_r2_std}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
