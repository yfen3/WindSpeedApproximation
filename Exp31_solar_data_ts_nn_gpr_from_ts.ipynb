{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85e59f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version is 3.1.1\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the data for expeirment\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "import seaborn as sns\n",
    "import TsModel\n",
    "import GprModel\n",
    "import TsModel_constant\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Keras version is {keras.__version__}\")\n",
    "print(f\"Num GPUs Available: {torch.cuda.device_count()}\")\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa034de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp31_results = {\n",
    "    'gp_tsl_train_accuracy':gp_tsl_train_accuracy,\n",
    "    'gp_tsl_test_accuracy':gp_tsl_test_accuracy,\n",
    "    'gp_tsl_r2s':gp_tsl_r2s,\n",
    "    'gp_tsl_time':gp_tsl_time,\n",
    "    'gp_tsc_train_accuracy':gp_tsc_train_accuracy,\n",
    "    'gp_tsc_test_accuracy':gp_tsc_test_accuracy,\n",
    "    'gp_tsc_r2s':gp_tsc_r2s,\n",
    "    'gp_tsc_time':gp_tsc_time,\n",
    "    'gp_nn_tsl_train_accuracy':gp_nn_tsl_train_accuracy,\n",
    "    'gp_nn_tsl_test_accuracy':gp_nn_tsl_test_accuracy,\n",
    "    'gp_nn_tsl_r2s':gp_nn_tsl_r2s,\n",
    "    'nn_tsl_r2s':nn_tsl_r2s,\n",
    "    'gp_nn_tsl_time':gp_nn_tsl_time,\n",
    "    'gp_nn_tsc_train_accuracy':gp_nn_tsc_train_accuracy,\n",
    "    'gp_nn_tsc_test_accuracy':gp_nn_tsc_test_accuracy,\n",
    "    'gp_nn_tsc_r2s':gp_nn_tsc_r2s,\n",
    "    'nn_tsc_r2s':nn_tsc_r2s,\n",
    "    'gp_nn_tsc_time':gp_nn_tsc_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2102da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'exp31_results' (dict)\n"
     ]
    }
   ],
   "source": [
    "#%store exp31_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6605d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the solar data set\n",
    "x_train = pd.read_csv('Data/FES/solar_x_train.csv')\n",
    "x_test = pd.read_csv('Data/FES/solar_x_test.csv')\n",
    "y_train = pd.read_csv('Data/FES/solar_y_train.csv')\n",
    "y_test = pd.read_csv('Data/FES/solar_y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9fe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_folds = 10\n",
    "\n",
    "# Source: From the TSmodel\n",
    "def preprocess_data(train_x, test_x, train_y, test_y):\n",
    "    feature_scaler = StandardScaler()\n",
    "    scaled_train_x = feature_scaler.fit_transform(train_x)\n",
    "    scaled_test_x = feature_scaler.transform(test_x)\n",
    "\n",
    "    # target_scaler = StandardScaler()  \n",
    "    # scaled_train_y = target_scaler.fit_transform(train_y)\n",
    "    # scaled_test_y = target_scaler.transform(test_y)    \n",
    "    # return scaled_train_x, scaled_test_x, scaled_train_y, scaled_test_y, feature_scaler, target_scaler    \n",
    "\n",
    "    return scaled_train_x, scaled_test_x, feature_scaler    \n",
    "\n",
    "def build_neural_network_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(1, activation=keras.activations.relu))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da3320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, feature_scaler = preprocess_data(x_train, x_test, y_train, y_test)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd4fc524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nn_exp():\n",
    "    neural_network_model = build_neural_network_model()\n",
    "\n",
    "    neural_network_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.05),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = neural_network_model.fit(\n",
    "        x_train, \n",
    "        y_train,\n",
    "        epochs=300, \n",
    "        shuffle=True\n",
    "    )\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    plt.plot(history.history['root_mean_squared_error'])\n",
    "    \n",
    "    return neural_network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b0fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7712271.5000 - root_mean_squared_error: 2776.3455\n",
      "Epoch 2/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7408079.5000 - root_mean_squared_error: 2720.2529\n",
      "Epoch 3/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7336200.0000 - root_mean_squared_error: 2708.0938\n",
      "Epoch 4/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7228772.0000 - root_mean_squared_error: 2686.4927\n",
      "Epoch 5/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7247996.0000 - root_mean_squared_error: 2691.6431\n",
      "Epoch 6/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7107924.0000 - root_mean_squared_error: 2662.8125\n",
      "Epoch 7/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6509557.0000 - root_mean_squared_error: 2551.0427\n",
      "Epoch 8/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6384384.0000 - root_mean_squared_error: 2526.4395\n",
      "Epoch 9/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6846639.5000 - root_mean_squared_error: 2611.4414\n",
      "Epoch 10/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6404826.5000 - root_mean_squared_error: 2530.2900\n",
      "Epoch 11/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6303024.0000 - root_mean_squared_error: 2510.1902\n",
      "Epoch 12/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6541024.5000 - root_mean_squared_error: 2555.7195\n",
      "Epoch 13/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6448936.5000 - root_mean_squared_error: 2538.2791\n",
      "Epoch 14/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5910268.0000 - root_mean_squared_error: 2430.7708\n",
      "Epoch 15/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5917053.5000 - root_mean_squared_error: 2430.2983\n",
      "Epoch 16/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6268510.0000 - root_mean_squared_error: 2501.4834\n",
      "Epoch 17/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5323730.5000 - root_mean_squared_error: 2305.1599\n",
      "Epoch 18/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5523341.5000 - root_mean_squared_error: 2348.5859\n",
      "Epoch 19/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5587524.5000 - root_mean_squared_error: 2362.8916\n",
      "Epoch 20/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5423575.0000 - root_mean_squared_error: 2327.6089\n",
      "Epoch 21/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5642406.0000 - root_mean_squared_error: 2374.6384\n",
      "Epoch 22/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4825300.5000 - root_mean_squared_error: 2193.2617\n",
      "Epoch 23/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5318470.0000 - root_mean_squared_error: 2305.3127\n",
      "Epoch 24/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4858386.0000 - root_mean_squared_error: 2201.2012\n",
      "Epoch 25/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5026730.0000 - root_mean_squared_error: 2241.2876\n",
      "Epoch 26/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4574719.0000 - root_mean_squared_error: 2138.3594\n",
      "Epoch 27/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4429836.0000 - root_mean_squared_error: 2101.4983\n",
      "Epoch 28/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4657030.0000 - root_mean_squared_error: 2157.4119\n",
      "Epoch 29/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4520159.5000 - root_mean_squared_error: 2125.8850\n",
      "Epoch 30/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4608138.0000 - root_mean_squared_error: 2145.7351\n",
      "Epoch 31/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4357672.0000 - root_mean_squared_error: 2083.0979\n",
      "Epoch 32/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4387677.5000 - root_mean_squared_error: 2093.8953\n",
      "Epoch 33/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4518674.0000 - root_mean_squared_error: 2124.1113\n",
      "Epoch 34/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4285624.5000 - root_mean_squared_error: 2069.3076\n",
      "Epoch 35/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3782612.7500 - root_mean_squared_error: 1943.8066\n",
      "Epoch 36/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4342061.0000 - root_mean_squared_error: 2080.6853\n",
      "Epoch 37/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3959523.7500 - root_mean_squared_error: 1989.6193\n",
      "Epoch 38/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4121708.7500 - root_mean_squared_error: 2029.3868\n",
      "Epoch 39/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3855255.0000 - root_mean_squared_error: 1962.1902\n",
      "Epoch 40/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3825041.5000 - root_mean_squared_error: 1955.2489\n",
      "Epoch 41/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3732418.2500 - root_mean_squared_error: 1929.2395\n",
      "Epoch 42/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3660621.0000 - root_mean_squared_error: 1912.6212\n",
      "Epoch 43/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3555603.7500 - root_mean_squared_error: 1885.0801\n",
      "Epoch 44/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3585931.2500 - root_mean_squared_error: 1893.3939\n",
      "Epoch 45/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3352659.7500 - root_mean_squared_error: 1830.7588\n",
      "Epoch 46/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3415445.0000 - root_mean_squared_error: 1847.4348\n",
      "Epoch 47/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3196288.2500 - root_mean_squared_error: 1786.9688\n",
      "Epoch 48/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3264105.0000 - root_mean_squared_error: 1806.1096\n",
      "Epoch 49/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3318343.5000 - root_mean_squared_error: 1821.0485\n",
      "Epoch 50/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3312922.7500 - root_mean_squared_error: 1819.1367\n",
      "Epoch 51/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3301857.2500 - root_mean_squared_error: 1815.5256\n",
      "Epoch 52/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3181144.2500 - root_mean_squared_error: 1783.3403\n",
      "Epoch 53/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3100997.2500 - root_mean_squared_error: 1760.3582\n",
      "Epoch 54/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2969593.2500 - root_mean_squared_error: 1721.3416\n",
      "Epoch 55/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2696712.0000 - root_mean_squared_error: 1639.4696\n",
      "Epoch 56/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2975982.2500 - root_mean_squared_error: 1722.1959\n",
      "Epoch 57/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2872660.2500 - root_mean_squared_error: 1694.2697\n",
      "Epoch 58/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2752192.7500 - root_mean_squared_error: 1658.5867\n",
      "Epoch 59/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2649002.7500 - root_mean_squared_error: 1627.2915\n",
      "Epoch 60/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2506412.7500 - root_mean_squared_error: 1580.8660\n",
      "Epoch 61/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2503086.2500 - root_mean_squared_error: 1581.2526\n",
      "Epoch 62/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2427952.7500 - root_mean_squared_error: 1556.7391\n",
      "Epoch 63/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2389373.7500 - root_mean_squared_error: 1543.4725\n",
      "Epoch 64/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2288519.5000 - root_mean_squared_error: 1512.5050\n",
      "Epoch 65/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2419916.7500 - root_mean_squared_error: 1553.2573\n",
      "Epoch 66/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2335987.7500 - root_mean_squared_error: 1527.8064\n",
      "Epoch 67/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2217600.7500 - root_mean_squared_error: 1485.6840\n",
      "Epoch 68/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2140026.2500 - root_mean_squared_error: 1461.8306\n",
      "Epoch 69/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2119141.7500 - root_mean_squared_error: 1454.6860\n",
      "Epoch 70/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2074803.3750 - root_mean_squared_error: 1438.8942\n",
      "Epoch 71/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2178489.5000 - root_mean_squared_error: 1475.0259\n",
      "Epoch 72/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2079164.3750 - root_mean_squared_error: 1441.6447\n",
      "Epoch 73/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2119749.5000 - root_mean_squared_error: 1454.2061\n",
      "Epoch 74/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2092493.3750 - root_mean_squared_error: 1445.6416\n",
      "Epoch 75/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1918973.1250 - root_mean_squared_error: 1384.2810\n",
      "Epoch 76/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1895765.6250 - root_mean_squared_error: 1376.5610\n",
      "Epoch 77/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1859876.6250 - root_mean_squared_error: 1362.8309\n",
      "Epoch 78/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1835630.3750 - root_mean_squared_error: 1353.9386\n",
      "Epoch 79/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1853585.3750 - root_mean_squared_error: 1360.1565\n",
      "Epoch 80/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1615300.7500 - root_mean_squared_error: 1270.0571\n",
      "Epoch 81/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1700391.3750 - root_mean_squared_error: 1303.2631\n",
      "Epoch 82/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1620291.2500 - root_mean_squared_error: 1271.8256\n",
      "Epoch 83/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1790116.2500 - root_mean_squared_error: 1335.9829\n",
      "Epoch 84/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1581330.1250 - root_mean_squared_error: 1256.3735\n",
      "Epoch 85/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1560304.7500 - root_mean_squared_error: 1248.7938\n",
      "Epoch 86/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1542113.3750 - root_mean_squared_error: 1241.2164\n",
      "Epoch 87/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1466896.0000 - root_mean_squared_error: 1209.6001\n",
      "Epoch 88/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1464850.5000 - root_mean_squared_error: 1210.0620\n",
      "Epoch 89/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1385783.3750 - root_mean_squared_error: 1176.1718\n",
      "Epoch 90/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1487452.5000 - root_mean_squared_error: 1218.8927\n",
      "Epoch 91/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1320071.7500 - root_mean_squared_error: 1145.6274\n",
      "Epoch 92/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1347377.1250 - root_mean_squared_error: 1160.2026\n",
      "Epoch 93/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1289889.0000 - root_mean_squared_error: 1135.2269\n",
      "Epoch 94/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1210526.5000 - root_mean_squared_error: 1099.4448\n",
      "Epoch 95/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1280703.1250 - root_mean_squared_error: 1131.4343\n",
      "Epoch 96/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1152565.2500 - root_mean_squared_error: 1072.1652\n",
      "Epoch 97/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1241178.5000 - root_mean_squared_error: 1113.2676\n",
      "Epoch 98/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1164027.0000 - root_mean_squared_error: 1078.5963\n",
      "Epoch 99/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1145376.5000 - root_mean_squared_error: 1067.9155\n",
      "Epoch 100/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1071647.3750 - root_mean_squared_error: 1034.1106\n",
      "Epoch 101/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1130687.3750 - root_mean_squared_error: 1063.0166\n",
      "Epoch 102/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1055593.1250 - root_mean_squared_error: 1025.2267\n",
      "Epoch 103/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1056377.1250 - root_mean_squared_error: 1027.3380\n",
      "Epoch 104/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1031937.0625 - root_mean_squared_error: 1015.6374\n",
      "Epoch 105/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1031490.3125 - root_mean_squared_error: 1014.9808\n",
      "Epoch 106/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 915465.7500 - root_mean_squared_error: 954.1593\n",
      "Epoch 107/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 982569.4375 - root_mean_squared_error: 990.9415\n",
      "Epoch 108/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 827034.9375 - root_mean_squared_error: 908.0707\n",
      "Epoch 109/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 929986.0000 - root_mean_squared_error: 963.1285\n",
      "Epoch 110/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 888249.7500 - root_mean_squared_error: 940.7655\n",
      "Epoch 111/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 787978.5000 - root_mean_squared_error: 886.5988\n",
      "Epoch 112/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 888798.1875 - root_mean_squared_error: 941.7121\n",
      "Epoch 113/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 809530.5625 - root_mean_squared_error: 898.0621\n",
      "Epoch 114/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 893874.5000 - root_mean_squared_error: 944.2936\n",
      "Epoch 115/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 787355.5000 - root_mean_squared_error: 886.7972\n",
      "Epoch 116/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 802606.7500 - root_mean_squared_error: 895.3215\n",
      "Epoch 117/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 789686.1875 - root_mean_squared_error: 887.4506\n",
      "Epoch 118/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 663006.1875 - root_mean_squared_error: 812.9584\n",
      "Epoch 119/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 748528.1875 - root_mean_squared_error: 864.5729\n",
      "Epoch 120/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 679567.0000 - root_mean_squared_error: 823.9460\n",
      "Epoch 121/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 694607.4375 - root_mean_squared_error: 832.2985\n",
      "Epoch 122/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 687303.0625 - root_mean_squared_error: 828.6870\n",
      "Epoch 123/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 620608.5000 - root_mean_squared_error: 786.8837\n",
      "Epoch 124/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 675912.3750 - root_mean_squared_error: 821.2485\n",
      "Epoch 125/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 604185.3750 - root_mean_squared_error: 776.9710\n",
      "Epoch 126/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 600590.8125 - root_mean_squared_error: 774.6353\n",
      "Epoch 127/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 609215.8125 - root_mean_squared_error: 780.1617\n",
      "Epoch 128/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605181.9375 - root_mean_squared_error: 777.4185\n",
      "Epoch 129/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603615.5625 - root_mean_squared_error: 776.1304\n",
      "Epoch 130/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555301.1875 - root_mean_squared_error: 744.4541\n",
      "Epoch 131/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513918.1562 - root_mean_squared_error: 716.0596\n",
      "Epoch 132/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533262.9375 - root_mean_squared_error: 729.7490\n",
      "Epoch 133/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499216.3125 - root_mean_squared_error: 702.7139\n",
      "Epoch 134/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504644.1875 - root_mean_squared_error: 708.1443\n",
      "Epoch 135/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 516937.9688 - root_mean_squared_error: 717.0688\n",
      "Epoch 136/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 489266.7188 - root_mean_squared_error: 698.4890\n",
      "Epoch 137/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492213.4375 - root_mean_squared_error: 701.1416\n",
      "Epoch 138/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 442489.3438 - root_mean_squared_error: 664.6541\n",
      "Epoch 139/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475819.4375 - root_mean_squared_error: 689.2108\n",
      "Epoch 140/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 421308.5000 - root_mean_squared_error: 648.5070\n",
      "Epoch 141/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 461356.4062 - root_mean_squared_error: 678.0282\n",
      "Epoch 142/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 425539.6875 - root_mean_squared_error: 651.6281\n",
      "Epoch 143/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 408757.3438 - root_mean_squared_error: 638.6608\n",
      "Epoch 144/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 388174.0000 - root_mean_squared_error: 622.2010\n",
      "Epoch 145/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 396492.9062 - root_mean_squared_error: 627.8264\n",
      "Epoch 146/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 398336.9688 - root_mean_squared_error: 630.7277\n",
      "Epoch 147/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 357465.8750 - root_mean_squared_error: 597.1700\n",
      "Epoch 148/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 385526.5938 - root_mean_squared_error: 620.3420\n",
      "Epoch 149/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 373121.5000 - root_mean_squared_error: 610.6062\n",
      "Epoch 150/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 377054.0312 - root_mean_squared_error: 613.6301\n",
      "Epoch 151/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 372753.8438 - root_mean_squared_error: 609.8693\n",
      "Epoch 152/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 358225.9688 - root_mean_squared_error: 597.9651\n",
      "Epoch 153/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 299120.7812 - root_mean_squared_error: 543.3533\n",
      "Epoch 154/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 305149.7500 - root_mean_squared_error: 551.8724\n",
      "Epoch 155/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 321839.3125 - root_mean_squared_error: 567.0619\n",
      "Epoch 156/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 310904.0000 - root_mean_squared_error: 556.4868\n",
      "Epoch 157/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 326085.6250 - root_mean_squared_error: 569.3754\n",
      "Epoch 158/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 311457.5625 - root_mean_squared_error: 557.8888\n",
      "Epoch 159/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 315916.8438 - root_mean_squared_error: 559.8312\n",
      "Epoch 160/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 327370.9375 - root_mean_squared_error: 571.3790\n",
      "Epoch 161/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 292002.9062 - root_mean_squared_error: 539.4174\n",
      "Epoch 162/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 290816.4688 - root_mean_squared_error: 538.9414\n",
      "Epoch 163/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 271587.0938 - root_mean_squared_error: 520.8425\n",
      "Epoch 164/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 256619.4219 - root_mean_squared_error: 506.0908\n",
      "Epoch 165/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 288596.5000 - root_mean_squared_error: 536.9352\n",
      "Epoch 166/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 242981.0938 - root_mean_squared_error: 491.6820\n",
      "Epoch 167/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 273444.4062 - root_mean_squared_error: 522.0007\n",
      "Epoch 168/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 218517.3281 - root_mean_squared_error: 466.5475\n",
      "Epoch 169/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 247739.9844 - root_mean_squared_error: 497.5800\n",
      "Epoch 170/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 252901.0781 - root_mean_squared_error: 502.7588\n",
      "Epoch 171/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 222171.0938 - root_mean_squared_error: 470.9369\n",
      "Epoch 172/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 254757.0625 - root_mean_squared_error: 503.9516\n",
      "Epoch 173/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 235837.1094 - root_mean_squared_error: 484.2755\n",
      "Epoch 174/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 220629.6562 - root_mean_squared_error: 469.1004\n",
      "Epoch 175/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 280135.6562 - root_mean_squared_error: 526.4182\n",
      "Epoch 176/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 216244.5156 - root_mean_squared_error: 464.4133\n",
      "Epoch 177/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 230728.3594 - root_mean_squared_error: 479.5116\n",
      "Epoch 178/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 227833.4688 - root_mean_squared_error: 477.0928\n",
      "Epoch 179/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201225.4062 - root_mean_squared_error: 447.7106\n",
      "Epoch 180/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 192709.8594 - root_mean_squared_error: 438.4825\n",
      "Epoch 181/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 190943.2344 - root_mean_squared_error: 436.3569\n",
      "Epoch 182/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 224904.5469 - root_mean_squared_error: 473.3979\n",
      "Epoch 183/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 214310.7344 - root_mean_squared_error: 462.7118\n",
      "Epoch 184/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201924.8594 - root_mean_squared_error: 448.4352\n",
      "Epoch 185/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 218631.0312 - root_mean_squared_error: 467.1935\n",
      "Epoch 186/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 219110.8438 - root_mean_squared_error: 467.9890\n",
      "Epoch 187/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 213837.3906 - root_mean_squared_error: 461.1224\n",
      "Epoch 188/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 201324.4375 - root_mean_squared_error: 448.3656\n",
      "Epoch 189/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 198459.4219 - root_mean_squared_error: 444.9424\n",
      "Epoch 190/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 184331.7344 - root_mean_squared_error: 429.1086\n",
      "Epoch 191/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167044.6562 - root_mean_squared_error: 407.8673\n",
      "Epoch 192/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 156415.0625 - root_mean_squared_error: 394.5350\n",
      "Epoch 193/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 186148.3125 - root_mean_squared_error: 431.2073\n",
      "Epoch 194/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 177655.3125 - root_mean_squared_error: 421.3390\n",
      "Epoch 195/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187599.0625 - root_mean_squared_error: 432.1371\n",
      "Epoch 196/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 169349.4531 - root_mean_squared_error: 411.1283\n",
      "Epoch 197/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 182814.7969 - root_mean_squared_error: 426.5399\n",
      "Epoch 198/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168001.1562 - root_mean_squared_error: 409.2488\n",
      "Epoch 199/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 164523.4844 - root_mean_squared_error: 404.6256\n",
      "Epoch 200/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 191138.4219 - root_mean_squared_error: 436.5757\n",
      "Epoch 201/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 187341.0781 - root_mean_squared_error: 430.7830\n",
      "Epoch 202/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 176378.4688 - root_mean_squared_error: 419.3651\n",
      "Epoch 203/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 162810.6094 - root_mean_squared_error: 402.8513\n",
      "Epoch 204/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154396.9219 - root_mean_squared_error: 392.5817\n",
      "Epoch 205/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 163668.3125 - root_mean_squared_error: 403.8840\n",
      "Epoch 206/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147216.1875 - root_mean_squared_error: 383.3964\n",
      "Epoch 207/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163045.1094 - root_mean_squared_error: 403.1820\n",
      "Epoch 208/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144782.5156 - root_mean_squared_error: 380.2331\n",
      "Epoch 209/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 163719.7812 - root_mean_squared_error: 404.2425\n",
      "Epoch 210/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172563.6875 - root_mean_squared_error: 412.3542\n",
      "Epoch 211/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126391.1016 - root_mean_squared_error: 355.1120\n",
      "Epoch 212/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 157588.5000 - root_mean_squared_error: 396.6636\n",
      "Epoch 213/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 142699.4219 - root_mean_squared_error: 377.4415\n",
      "Epoch 214/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133083.9219 - root_mean_squared_error: 364.6361\n",
      "Epoch 215/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 167242.8594 - root_mean_squared_error: 408.6616\n",
      "Epoch 216/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 173584.8281 - root_mean_squared_error: 414.9257\n",
      "Epoch 217/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 152779.9062 - root_mean_squared_error: 390.2418\n",
      "Epoch 218/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138872.8438 - root_mean_squared_error: 371.5836\n",
      "Epoch 219/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 139082.6094 - root_mean_squared_error: 372.7529\n",
      "Epoch 220/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122045.8203 - root_mean_squared_error: 348.2433\n",
      "Epoch 221/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 147057.4062 - root_mean_squared_error: 383.2523\n",
      "Epoch 222/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 151436.2188 - root_mean_squared_error: 388.9274\n",
      "Epoch 223/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 181519.4375 - root_mean_squared_error: 422.6810\n",
      "Epoch 224/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119675.0859 - root_mean_squared_error: 345.0327\n",
      "Epoch 225/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127060.4297 - root_mean_squared_error: 355.9750\n",
      "Epoch 226/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 148102.9375 - root_mean_squared_error: 384.1340\n",
      "Epoch 227/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143612.6719 - root_mean_squared_error: 378.4631\n",
      "Epoch 228/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 138149.5156 - root_mean_squared_error: 369.8347\n",
      "Epoch 229/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140193.7969 - root_mean_squared_error: 374.2440\n",
      "Epoch 230/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141161.0312 - root_mean_squared_error: 374.8497\n",
      "Epoch 231/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109253.4375 - root_mean_squared_error: 328.8879\n",
      "Epoch 232/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 144399.9062 - root_mean_squared_error: 378.9388\n",
      "Epoch 233/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119050.9141 - root_mean_squared_error: 344.1927\n",
      "Epoch 234/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123761.5312 - root_mean_squared_error: 351.5847\n",
      "Epoch 235/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 133209.4531 - root_mean_squared_error: 364.3923\n",
      "Epoch 236/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 141574.4688 - root_mean_squared_error: 376.0612\n",
      "Epoch 237/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111652.2500 - root_mean_squared_error: 333.6612\n",
      "Epoch 238/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 172044.0625 - root_mean_squared_error: 412.4859\n",
      "Epoch 239/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117126.1094 - root_mean_squared_error: 341.5378\n",
      "Epoch 240/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123382.1719 - root_mean_squared_error: 350.7471\n",
      "Epoch 241/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 158141.7188 - root_mean_squared_error: 397.1262\n",
      "Epoch 242/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111662.3672 - root_mean_squared_error: 331.2905\n",
      "Epoch 243/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 159436.4219 - root_mean_squared_error: 397.1591\n",
      "Epoch 244/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 140974.1875 - root_mean_squared_error: 374.1079\n",
      "Epoch 245/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125879.9844 - root_mean_squared_error: 354.4171\n",
      "Epoch 246/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114420.7109 - root_mean_squared_error: 337.9329\n",
      "Epoch 247/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116306.4844 - root_mean_squared_error: 340.5139\n",
      "Epoch 248/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 155424.5625 - root_mean_squared_error: 391.7564\n",
      "Epoch 249/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134775.3906 - root_mean_squared_error: 365.7009\n",
      "Epoch 250/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116604.7188 - root_mean_squared_error: 340.6001\n",
      "Epoch 251/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128633.0078 - root_mean_squared_error: 358.0549\n",
      "Epoch 252/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 143425.7500 - root_mean_squared_error: 377.8933\n",
      "Epoch 253/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122946.0234 - root_mean_squared_error: 349.8007\n",
      "Epoch 254/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 127136.6094 - root_mean_squared_error: 354.0009\n",
      "Epoch 255/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117933.3047 - root_mean_squared_error: 342.6096\n",
      "Epoch 256/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 159701.5156 - root_mean_squared_error: 398.6663\n",
      "Epoch 257/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 137690.9688 - root_mean_squared_error: 369.3435\n",
      "Epoch 258/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118610.9453 - root_mean_squared_error: 343.1235\n",
      "Epoch 259/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138403.5469 - root_mean_squared_error: 371.3700\n",
      "Epoch 260/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 134044.7656 - root_mean_squared_error: 365.0678\n",
      "Epoch 261/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 139605.2188 - root_mean_squared_error: 372.3856\n",
      "Epoch 262/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 111494.2969 - root_mean_squared_error: 333.5258\n",
      "Epoch 263/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132170.4375 - root_mean_squared_error: 362.5686\n",
      "Epoch 264/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 103438.7266 - root_mean_squared_error: 321.2942\n",
      "Epoch 265/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 141165.7031 - root_mean_squared_error: 373.7623\n",
      "Epoch 266/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129014.6328 - root_mean_squared_error: 357.8079\n",
      "Epoch 267/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 144756.7344 - root_mean_squared_error: 379.5231\n",
      "Epoch 268/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 151168.2031 - root_mean_squared_error: 386.0774\n",
      "Epoch 269/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114351.9844 - root_mean_squared_error: 336.6652\n",
      "Epoch 270/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120619.8594 - root_mean_squared_error: 347.1333\n",
      "Epoch 271/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 124524.1797 - root_mean_squared_error: 350.3337\n",
      "Epoch 272/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 126194.2188 - root_mean_squared_error: 354.5882\n",
      "Epoch 273/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 105404.5156 - root_mean_squared_error: 322.6633\n",
      "Epoch 274/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114358.7656 - root_mean_squared_error: 337.3185\n",
      "Epoch 275/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 129735.9531 - root_mean_squared_error: 359.5811\n",
      "Epoch 276/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113984.2891 - root_mean_squared_error: 336.4795\n",
      "Epoch 277/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 123954.7891 - root_mean_squared_error: 351.6056\n",
      "Epoch 278/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 132125.7344 - root_mean_squared_error: 362.7242\n",
      "Epoch 279/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 148702.8125 - root_mean_squared_error: 383.4302\n",
      "Epoch 280/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 119728.0625 - root_mean_squared_error: 345.2322\n",
      "Epoch 281/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 154297.7031 - root_mean_squared_error: 390.0021\n",
      "Epoch 282/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 118692.5859 - root_mean_squared_error: 342.8923\n",
      "Epoch 283/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110889.8828 - root_mean_squared_error: 332.6241\n",
      "Epoch 284/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135352.5469 - root_mean_squared_error: 366.3725\n",
      "Epoch 285/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135549.6094 - root_mean_squared_error: 366.2995\n",
      "Epoch 286/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 128446.3281 - root_mean_squared_error: 357.9717\n",
      "Epoch 287/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110139.5703 - root_mean_squared_error: 331.2208\n",
      "Epoch 288/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 127381.0938 - root_mean_squared_error: 355.1111\n",
      "Epoch 289/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 125646.8047 - root_mean_squared_error: 353.6487\n",
      "Epoch 290/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112829.3203 - root_mean_squared_error: 335.1363\n",
      "Epoch 291/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 135584.8594 - root_mean_squared_error: 366.0330\n",
      "Epoch 292/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 126325.7500 - root_mean_squared_error: 354.4028\n",
      "Epoch 293/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111383.6953 - root_mean_squared_error: 333.1804\n",
      "Epoch 294/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 123970.3516 - root_mean_squared_error: 350.3792\n",
      "Epoch 295/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122874.1328 - root_mean_squared_error: 350.2188\n",
      "Epoch 296/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 168160.9844 - root_mean_squared_error: 403.1616\n",
      "Epoch 297/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 120434.9844 - root_mean_squared_error: 346.1473\n",
      "Epoch 298/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 99530.5781 - root_mean_squared_error: 314.3181\n",
      "Epoch 299/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106333.4141 - root_mean_squared_error: 325.5608\n",
      "Epoch 300/300\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 106828.4375 - root_mean_squared_error: 324.6743\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model = do_nn_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16800056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 269.5596057487083\n"
     ]
    }
   ],
   "source": [
    "# TS model\n",
    "# Linear conclusion\n",
    "\n",
    "def ts_relu_wrapper(pred):\n",
    "    return np.maximum(0, pred)\n",
    "\n",
    "# TS with linear conclusion\n",
    "tsl_model = TsModel.TsModel(number_of_rules=25, fuzzification_coefficient=1.2)\n",
    "\n",
    "start_time = time.time()\n",
    "tsl_model.fit(x_train, y_train)\n",
    "time_used = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba9a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2207, 150)\n",
      "[[2.48875363e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.28078458e-16 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.58695968e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.79521141e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.96038604e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.22184768e-12 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2207, 25)\n",
      "[[2.48875363e-09 9.95890496e-11 1.71494769e-09 ... 1.83873268e-11\n",
      "  9.99690977e-01 4.54981202e-10]\n",
      " [5.28078458e-16 2.76686871e-17 3.50741785e-15 ... 4.52959808e-18\n",
      "  1.03902297e-10 6.05327611e-16]\n",
      " [2.58695968e-08 8.90924374e-09 1.58169400e-08 ... 4.07632875e-10\n",
      "  2.46174377e-06 5.24244467e-09]\n",
      " ...\n",
      " [9.79521141e-01 9.72796035e-07 9.62941491e-07 ... 2.49340353e-07\n",
      "  1.62918828e-06 4.65514858e-07]\n",
      " [3.96038604e-10 2.56735009e-11 8.46889065e-08 ... 6.08500064e-12\n",
      "  2.35499028e-07 8.42394936e-09]\n",
      " [1.22184768e-12 2.86682780e-14 6.18998725e-14 ... 3.97392861e-15\n",
      "  3.96844221e-08 2.42944649e-14]]\n",
      "FCM training RMSE: 493.0692050487675\n"
     ]
    }
   ],
   "source": [
    "# TS model\n",
    "# Constant conclusion\n",
    "\n",
    "\n",
    "tsc_model = TsModel_constant.TsModel_constant(number_of_rules=25, fuzzification_coefficient=1.2)\n",
    "\n",
    "start_time = time.time()\n",
    "tsc_model.fit(x_train, y_train)\n",
    "time_used = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a5513c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 562.127 ± 352.531\n",
      "GP Test RMSE: 1739.661 ± 1125.231\n",
      "GP R2: 0.039 ± 0.761\n",
      "GP Time: 33.007 ± 50.083\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_train_accuracy = []\n",
    "gp_test_accuracy = []\n",
    "gp_r2s = []\n",
    "gp_time = []\n",
    "gpr_model = None\n",
    "\n",
    "# From ts linear\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "    indices = np.random.choice(x_train.shape[0], 2000, replace=False)        \n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_model.fit(x_train[indices,:], y_train[indices,:])\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_model.predict(x_train)\n",
    "    test_means = gpr_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_train_accuracy.append(train_rmse)\n",
    "    gp_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_r2s.append(gp_r2)\n",
    "    gp_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_time),3)\n",
    "gp_time_std = np.round(np.std(gp_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3646ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 399.168 ± 0.0\n",
      "GP Test RMSE: 379.511 ± 0.0\n",
      "GP R2: 0.968 ± 0.0\n",
      "GP Time: 0.03 ± 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_tsl_train_accuracy = []\n",
    "gp_tsl_test_accuracy = []\n",
    "gp_tsl_r2s = []\n",
    "gp_tsl_time = []\n",
    "gpr_tsl_model = None\n",
    "\n",
    "# From ts linear\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_tsl_model.fit(tsl_model.cen, ts_relu_wrapper(tsl_model.predict(tsl_model.cen + 1e-8)))\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_tsl_model.predict(x_train)\n",
    "    test_means = gpr_tsl_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_tsl_train_accuracy.append(train_rmse)\n",
    "    gp_tsl_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_tsl_r2s.append(gp_r2)\n",
    "    gp_tsl_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_tsl_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_tsl_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_tsl_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_tsl_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_tsl_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_tsl_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_tsl_time),3)\n",
    "gp_time_std = np.round(np.std(gp_tsl_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960ae86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 387.903 ± 0.0\n",
      "GP Test RMSE: 365.297 ± 0.0\n",
      "GP R2: 0.97 ± 0.0\n",
      "GP Time: 0.028 ± 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_tsc_train_accuracy = []\n",
    "gp_tsc_test_accuracy = []\n",
    "gp_tsc_r2s = []\n",
    "gp_tsc_time = []\n",
    "gpr_tsc_model = None\n",
    "\n",
    "# From ts constant\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_tsc_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_tsc_model.fit(tsc_model.cen, ts_relu_wrapper(tsc_model.predict(tsc_model.cen + 1e-8)))\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_tsc_model.predict(x_train)\n",
    "    test_means = gpr_tsc_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_tsc_train_accuracy.append(train_rmse)\n",
    "    gp_tsc_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_tsc_r2s.append(gp_r2)\n",
    "    gp_tsc_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_tsc_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_tsc_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_tsc_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_tsc_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_tsc_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_tsc_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_tsc_time),3)\n",
    "gp_time_std = np.round(np.std(gp_tsc_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d1d833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "GP Train RMSE: 465.925 ± 0.0\n",
      "GP Test RMSE: 442.991 ± 0.0\n",
      "GP R2: 0.956 ± 0.0\n",
      "GP Time: 0.032 ± 0.011\n",
      "TS NN R2: 0.993 ± 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_nn_tsl_train_accuracy = []\n",
    "gp_nn_tsl_test_accuracy = []\n",
    "gp_nn_tsl_r2s = []\n",
    "nn_tsl_r2s = []\n",
    "gp_nn_tsl_time = []\n",
    "gpr_nn_tsl_model = None\n",
    "\n",
    "# From NN and ts linear\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_nn_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    inputs = tsl_model.cen\n",
    "    ts_predictions = ts_relu_wrapper(tsl_model.predict(tsl_model.cen + 1e-8))\n",
    "    nn_predictions = nn_model.predict(inputs)\n",
    "    gpr_nn_tsl_model.fit(inputs, nn_predictions)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_nn_tsl_model.predict(x_train)\n",
    "    test_means = gpr_nn_tsl_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_nn_tsl_train_accuracy.append(train_rmse)\n",
    "    gp_nn_tsl_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_nn_tsl_r2s.append(gp_r2)\n",
    "    gp_nn_tsl_time.append(time_used)\n",
    "    nn_tsl_r2s.append(r2_score(ts_predictions, nn_predictions))\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_nn_tsl_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_nn_tsl_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_nn_tsl_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_nn_tsl_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_nn_tsl_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_nn_tsl_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_nn_tsl_time),3)\n",
    "gp_time_std = np.round(np.std(gp_nn_tsl_time),3)\n",
    "nn_ts_r2_mean = np.round(np.mean(nn_tsl_r2s),3)\n",
    "nn_ts_r2_std = np.round(np.std(nn_tsl_r2s),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n",
    "print(f\"TS NN R2: {nn_ts_r2_mean} ± {nn_ts_r2_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0f6c458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 446.769 ± 0.0\n",
      "GP Test RMSE: 420.203 ± 0.0\n",
      "GP R2: 0.96 ± 0.0\n",
      "GP Time: 0.036 ± 0.008\n",
      "TS NN R2: 0.993 ± 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_nn_tsc_train_accuracy = []\n",
    "gp_nn_tsc_test_accuracy = []\n",
    "gp_nn_tsc_r2s = []\n",
    "nn_tsc_r2s = []\n",
    "gp_nn_tsc_time = []\n",
    "gpr_nn_tsc_model = None\n",
    "\n",
    "# From NN and ts constant\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "    gpr_nn_tsc_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    inputs = tsc_model.cen\n",
    "    ts_predictions = tsc_model.predict(tsc_model.cen + 1e-8)\n",
    "    nn_predictions = nn_model.predict(inputs)\n",
    "    gpr_nn_tsc_model.fit(inputs, nn_predictions)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_nn_tsc_model.predict(x_train)\n",
    "    test_means = gpr_nn_tsc_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_nn_tsc_train_accuracy.append(train_rmse)\n",
    "    gp_nn_tsc_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_nn_tsc_r2s.append(gp_r2)\n",
    "    gp_nn_tsc_time.append(time_used)\n",
    "    nn_tsc_r2s.append(r2_score(ts_predictions, nn_predictions))\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_nn_tsc_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_nn_tsc_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_nn_tsc_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_nn_tsc_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_nn_tsc_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_nn_tsc_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_nn_tsc_time),3)\n",
    "gp_time_std = np.round(np.std(gp_nn_tsc_time),3)\n",
    "nn_ts_r2_mean = np.round(np.mean(nn_tsc_r2s),3)\n",
    "nn_ts_r2_std = np.round(np.std(nn_tsc_r2s),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n",
    "print(f\"TS NN R2: {nn_ts_r2_mean} ± {nn_ts_r2_std}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
