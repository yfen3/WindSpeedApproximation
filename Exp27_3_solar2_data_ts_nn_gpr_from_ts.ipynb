{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e85e59f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version is 3.1.1\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "# Get the data for expeirment\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, RBF\n",
    "import TsModel\n",
    "import TsModel_constant\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "from keras import layers, models\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Keras version is {keras.__version__}\")\n",
    "print(f\"Num GPUs Available: {torch.cuda.device_count()}\")\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This tests the fitlered solar plant 2 data,\n",
    "all spikes with daily diff > 15000 are removed.\n",
    "\n",
    "TS and TS-C are carried out on the opt #c=8\n",
    "\n",
    "Clustering results are listed along with the GP results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fa034de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp27_3_results = {\n",
    "    'nn_train_accuracy' : nn_train_accuracy,\n",
    "    'nn_test_accuracy':nn_test_accuracy,\n",
    "    'nn_r2s':nn_r2s,\n",
    "    'nn_time':nn_time,\n",
    "    'gp_train_accuracy':gp_train_accuracy,\n",
    "    'gp_test_accuracy':gp_test_accuracy,\n",
    "    'gp_r2s':gp_r2s,\n",
    "    'gp_time':gp_time,\n",
    "    'tsl_opt_train_accuracy' : tsl_opt_train_accuracy,\n",
    "    'tsl_opt_test_accuracy' :tsl_opt_test_accuracy,\n",
    "    'tsl_r2s':tsl_r2s,\n",
    "    'tsl_time': tsl_time,\n",
    "    'tsc_opt_train_accuracy':tsc_opt_train_accuracy,\n",
    "    'tsc_opt_test_accuracy':tsc_opt_test_accuracy,\n",
    "    'tsc_r2s':tsc_r2s,\n",
    "    'tsc_time':tsc_time,\n",
    "    'gp_tsl_train_accuracy':gp_tsl_train_accuracy,\n",
    "    'gp_tsl_test_accuracy':gp_tsl_test_accuracy,\n",
    "    'tsl_train_accuracy':tsl_train_accuracy,\n",
    "    'tsl_test_accuracy':tsl_test_accuracy,\n",
    "    'gp_tsl_r2s':gp_tsl_r2s,\n",
    "    'gp_tsl_time':gp_tsl_time,\n",
    "    'gp_tsc_train_accuracy':gp_tsc_train_accuracy,\n",
    "    'gp_tsc_test_accuracy':gp_tsc_test_accuracy,\n",
    "    'tsc_train_accuracy':tsc_train_accuracy,\n",
    "    'tsc_test_accuracy':tsc_test_accuracy,\n",
    "    'gp_tsc_r2s':gp_tsc_r2s,\n",
    "    'gp_tsc_time':gp_tsc_time,\n",
    "    'gp_nn_tsl_train_accuracy':gp_nn_tsl_train_accuracy,\n",
    "    'gp_nn_tsl_test_accuracy':gp_nn_tsl_test_accuracy,\n",
    "    'gp_nn_tsl_r2s':gp_nn_tsl_r2s,\n",
    "    'nn_tsl_r2s':nn_tsl_r2s,\n",
    "    'gp_nn_tsl_time':gp_nn_tsl_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2102da05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'exp27_3_results' (dict)\n"
     ]
    }
   ],
   "source": [
    "#%store exp27_3_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6605d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the solar data set\n",
    "x_train = pd.read_csv('Data/FES/solar2_x_train_filtered.csv')\n",
    "x_test = pd.read_csv('Data/FES/solar2_x_test_filtered.csv')\n",
    "y_train = pd.read_csv('Data/FES/solar2_y_train_filtered.csv')\n",
    "y_test = pd.read_csv('Data/FES/solar2_y_test_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9fe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_folds = 10\n",
    "\n",
    "# Source: From the TSmodel\n",
    "def preprocess_data(train_x, test_x, train_y, test_y):\n",
    "    feature_scaler = StandardScaler()\n",
    "    scaled_train_x = feature_scaler.fit_transform(train_x)\n",
    "    scaled_test_x = feature_scaler.transform(test_x)\n",
    "\n",
    "    # target_scaler = StandardScaler()  \n",
    "    # scaled_train_y = target_scaler.fit_transform(train_y)\n",
    "    # scaled_test_y = target_scaler.transform(test_y)    \n",
    "    # return scaled_train_x, scaled_test_x, scaled_train_y, scaled_test_y, feature_scaler, target_scaler    \n",
    "\n",
    "    return scaled_train_x, scaled_test_x, feature_scaler    \n",
    "\n",
    "def build_neural_network_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(10, activation=keras.activations.tanh))    \n",
    "    model.add(layers.Dense(1, activation=keras.activations.relu))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da3320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, feature_scaler = preprocess_data(x_train, x_test, y_train, y_test)\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529b9590",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_accuracy = []\n",
    "nn_test_accuracy = []\n",
    "nn_r2s = []\n",
    "nn_time = []\n",
    "histories = []\n",
    "\n",
    "def do_nn_exp():\n",
    "    for fold in range(number_of_folds):\n",
    "        neural_network_model = build_neural_network_model()\n",
    "\n",
    "        neural_network_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "            loss=keras.losses.MeanSquaredError(),\n",
    "            metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        history = neural_network_model.fit(\n",
    "            x_train, \n",
    "            y_train,\n",
    "            epochs=200, \n",
    "            shuffle=True\n",
    "        )\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        _, train_rmse = neural_network_model.evaluate(x_train, y_train)\n",
    "        nn_train_accuracy.append(train_rmse)\n",
    "        _, test_rmse = neural_network_model.evaluate(x_test, y_test)\n",
    "        nn_test_accuracy.append(test_rmse)\n",
    "        nn_r2 = r2_score(y_test, neural_network_model.predict(x_test))\n",
    "        nn_r2s.append(nn_r2)\n",
    "        nn_time.append(time_used)\n",
    "        histories.append(history)\n",
    "    \n",
    "    return neural_network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b0fedb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4051066.2500 - root_mean_squared_error: 2012.1553\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4067953.7500 - root_mean_squared_error: 2015.7111\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3958864.2500 - root_mean_squared_error: 1989.1259\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3784034.7500 - root_mean_squared_error: 1944.8823\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3439235.2500 - root_mean_squared_error: 1853.7570\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3536713.7500 - root_mean_squared_error: 1878.6909\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3263235.0000 - root_mean_squared_error: 1805.7831\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3406283.2500 - root_mean_squared_error: 1844.7484\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3249044.0000 - root_mean_squared_error: 1800.5029\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3196980.7500 - root_mean_squared_error: 1787.6183\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2892193.2500 - root_mean_squared_error: 1700.1478\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3109975.5000 - root_mean_squared_error: 1761.6028\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2931852.5000 - root_mean_squared_error: 1711.8827\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2716303.5000 - root_mean_squared_error: 1647.8618\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2810594.5000 - root_mean_squared_error: 1676.2640\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2759534.5000 - root_mean_squared_error: 1661.0806\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2675081.7500 - root_mean_squared_error: 1635.2211\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2944195.2500 - root_mean_squared_error: 1715.3505\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2716520.2500 - root_mean_squared_error: 1648.0774\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2810079.7500 - root_mean_squared_error: 1675.8214\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2706263.0000 - root_mean_squared_error: 1644.6244\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2650621.0000 - root_mean_squared_error: 1627.9132\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2681924.7500 - root_mean_squared_error: 1637.1608\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2732541.5000 - root_mean_squared_error: 1652.7131\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2597927.7500 - root_mean_squared_error: 1611.6105\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2561718.2500 - root_mean_squared_error: 1596.2087\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1771718.3750 - root_mean_squared_error: 1329.6914\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1987623.2500 - root_mean_squared_error: 1408.5439\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1736069.2500 - root_mean_squared_error: 1316.7562\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1452627.0000 - root_mean_squared_error: 1204.5775\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1485596.5000 - root_mean_squared_error: 1216.7688\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1542581.1250 - root_mean_squared_error: 1240.0699\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1339833.2500 - root_mean_squared_error: 1157.3470\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1206440.7500 - root_mean_squared_error: 1095.7666\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1147299.1250 - root_mean_squared_error: 1070.7657\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1207575.2500 - root_mean_squared_error: 1096.9681\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1099820.3750 - root_mean_squared_error: 1048.5426\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1063038.8750 - root_mean_squared_error: 1030.5702\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 953550.8750 - root_mean_squared_error: 974.6916\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 985306.4375 - root_mean_squared_error: 992.0284\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 862331.6250 - root_mean_squared_error: 928.1980\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 910355.8750 - root_mean_squared_error: 951.2057\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 901368.6875 - root_mean_squared_error: 946.6122\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 774005.3125 - root_mean_squared_error: 878.0969\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 771008.5000 - root_mean_squared_error: 877.1341\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 691502.8750 - root_mean_squared_error: 829.7099\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 755366.0000 - root_mean_squared_error: 867.8286\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 709578.8125 - root_mean_squared_error: 840.9287\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 647013.4375 - root_mean_squared_error: 803.5468\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 666444.4375 - root_mean_squared_error: 815.5593\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 686574.6875 - root_mean_squared_error: 828.1819\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 663339.6875 - root_mean_squared_error: 813.6204\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 618200.3125 - root_mean_squared_error: 784.8295\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 635685.8125 - root_mean_squared_error: 796.8558\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 727517.8750 - root_mean_squared_error: 852.1801\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 690056.3125 - root_mean_squared_error: 827.9282\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593650.7500 - root_mean_squared_error: 769.9395\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 581812.9375 - root_mean_squared_error: 761.2153\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 604659.1875 - root_mean_squared_error: 777.2531\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 601695.3750 - root_mean_squared_error: 774.4077\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535308.2500 - root_mean_squared_error: 729.5137\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 599994.9375 - root_mean_squared_error: 773.9368\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548449.0000 - root_mean_squared_error: 739.5929\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533971.0000 - root_mean_squared_error: 730.2043\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589196.6250 - root_mean_squared_error: 766.3038\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 551581.4375 - root_mean_squared_error: 742.4325\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 568982.5000 - root_mean_squared_error: 753.1772\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527837.0625 - root_mean_squared_error: 725.6836\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 574575.7500 - root_mean_squared_error: 756.1324\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489232.3438 - root_mean_squared_error: 698.3149\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 457734.2812 - root_mean_squared_error: 675.0427\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 559632.3750 - root_mean_squared_error: 746.9507\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 569740.0625 - root_mean_squared_error: 753.3757\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555467.7500 - root_mean_squared_error: 743.2461\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 476977.4062 - root_mean_squared_error: 689.2590\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524965.1875 - root_mean_squared_error: 723.7252\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 559587.4375 - root_mean_squared_error: 747.2040\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 466014.3438 - root_mean_squared_error: 680.6104\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 432980.4062 - root_mean_squared_error: 655.6607\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538551.8125 - root_mean_squared_error: 732.9308\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 485885.0625 - root_mean_squared_error: 696.3094\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541557.8125 - root_mean_squared_error: 734.3099\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496876.5938 - root_mean_squared_error: 699.6845\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525689.8750 - root_mean_squared_error: 721.9766\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519615.0938 - root_mean_squared_error: 718.5822\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555913.4375 - root_mean_squared_error: 743.3353\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535001.4375 - root_mean_squared_error: 729.0150\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 467784.9375 - root_mean_squared_error: 682.8818\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508641.2812 - root_mean_squared_error: 712.2208\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502865.4062 - root_mean_squared_error: 707.8939\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497573.7500 - root_mean_squared_error: 704.1363\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 487347.8438 - root_mean_squared_error: 696.5452\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499699.1562 - root_mean_squared_error: 705.6753\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586497.8125 - root_mean_squared_error: 765.0225\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490013.3125 - root_mean_squared_error: 699.0121\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506386.2812 - root_mean_squared_error: 706.7902\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520018.3750 - root_mean_squared_error: 719.9022\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458127.9062 - root_mean_squared_error: 675.1404\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614345.3125 - root_mean_squared_error: 782.1213\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568671.3125 - root_mean_squared_error: 752.6416\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496185.9062 - root_mean_squared_error: 702.4023\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 542253.3125 - root_mean_squared_error: 732.6107\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560644.0000 - root_mean_squared_error: 745.5128\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 397458.9062 - root_mean_squared_error: 628.7419\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561239.6875 - root_mean_squared_error: 744.9659\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 552376.5000 - root_mean_squared_error: 739.1565\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550258.6875 - root_mean_squared_error: 740.7556\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527322.3750 - root_mean_squared_error: 724.2974\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 514553.8438 - root_mean_squared_error: 715.9333\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 470336.7500 - root_mean_squared_error: 681.2915\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541571.7500 - root_mean_squared_error: 735.0442\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495971.8438 - root_mean_squared_error: 702.5385\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517304.3125 - root_mean_squared_error: 718.4944\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501016.5312 - root_mean_squared_error: 706.8962\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614263.1250 - root_mean_squared_error: 779.1702\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 468666.1875 - root_mean_squared_error: 682.9561\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 514281.6875 - root_mean_squared_error: 715.4125\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 576597.3750 - root_mean_squared_error: 757.7494\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504553.3750 - root_mean_squared_error: 709.4916\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516990.9062 - root_mean_squared_error: 718.3171\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512247.0000 - root_mean_squared_error: 711.4301\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 651965.5625 - root_mean_squared_error: 799.7664\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463071.4375 - root_mean_squared_error: 676.6606\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 572038.4375 - root_mean_squared_error: 754.8082\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 647428.3750 - root_mean_squared_error: 802.5176\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 476375.4375 - root_mean_squared_error: 688.8843\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 618122.1875 - root_mean_squared_error: 784.2648\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 555190.1875 - root_mean_squared_error: 744.5085\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603905.9375 - root_mean_squared_error: 772.7105\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546979.0000 - root_mean_squared_error: 736.4398\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 607118.0625 - root_mean_squared_error: 777.2424\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 495833.2500 - root_mean_squared_error: 702.5615\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527961.2500 - root_mean_squared_error: 726.0482\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532806.3750 - root_mean_squared_error: 729.5527\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 545698.5000 - root_mean_squared_error: 737.7626\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573159.6875 - root_mean_squared_error: 755.7978\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 577455.5000 - root_mean_squared_error: 756.4403\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484938.2812 - root_mean_squared_error: 694.5676\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 548257.8750 - root_mean_squared_error: 739.9219\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542812.1875 - root_mean_squared_error: 735.8397\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 613813.3750 - root_mean_squared_error: 782.1041\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 569010.6875 - root_mean_squared_error: 752.6250\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485482.5938 - root_mean_squared_error: 693.6050\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 580495.1250 - root_mean_squared_error: 757.8723\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593474.4375 - root_mean_squared_error: 769.4972\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 491072.6562 - root_mean_squared_error: 698.3904\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522799.2500 - root_mean_squared_error: 721.1516\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605592.6875 - root_mean_squared_error: 776.6842\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 471954.6250 - root_mean_squared_error: 685.3873\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528942.3750 - root_mean_squared_error: 726.5026\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 568788.0625 - root_mean_squared_error: 752.2729\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546261.6250 - root_mean_squared_error: 737.5106\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527003.0625 - root_mean_squared_error: 724.6797\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616664.5000 - root_mean_squared_error: 783.4674\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494916.0938 - root_mean_squared_error: 702.7820\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 607628.4375 - root_mean_squared_error: 778.5223\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494264.5625 - root_mean_squared_error: 702.2560\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594205.9375 - root_mean_squared_error: 767.4260\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488913.8750 - root_mean_squared_error: 697.7281\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533063.5625 - root_mean_squared_error: 729.5334\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586790.3125 - root_mean_squared_error: 761.3380\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 556315.5625 - root_mean_squared_error: 743.4424\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479379.0312 - root_mean_squared_error: 691.0367\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586516.7500 - root_mean_squared_error: 761.8534\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 665949.1250 - root_mean_squared_error: 806.5449\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 657516.3125 - root_mean_squared_error: 804.2662\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458414.0312 - root_mean_squared_error: 675.2981\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519330.9688 - root_mean_squared_error: 717.5969\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496671.1875 - root_mean_squared_error: 704.3722\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509376.5938 - root_mean_squared_error: 711.6277\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514997.1875 - root_mean_squared_error: 716.3465\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505327.6875 - root_mean_squared_error: 708.5647\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473114.6562 - root_mean_squared_error: 683.0607\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527918.5000 - root_mean_squared_error: 725.9447\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488321.2812 - root_mean_squared_error: 697.7086\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 580815.3125 - root_mean_squared_error: 761.3795\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594316.8750 - root_mean_squared_error: 765.8570\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 468060.7500 - root_mean_squared_error: 682.7117\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559525.7500 - root_mean_squared_error: 746.3849\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559061.8125 - root_mean_squared_error: 746.1955\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 481576.7812 - root_mean_squared_error: 692.4651\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548982.1250 - root_mean_squared_error: 739.8350\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569708.3125 - root_mean_squared_error: 752.2673\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501206.3438 - root_mean_squared_error: 707.2990\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475513.2500 - root_mean_squared_error: 688.2341\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 598746.2500 - root_mean_squared_error: 771.1072\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483907.3750 - root_mean_squared_error: 692.5424\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541013.8125 - root_mean_squared_error: 734.9211\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489519.2812 - root_mean_squared_error: 696.6670\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458922.6250 - root_mean_squared_error: 675.6377\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524884.5000 - root_mean_squared_error: 723.0560\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537815.7500 - root_mean_squared_error: 730.1599\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489518.9375 - root_mean_squared_error: 699.3392\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 437115.0938 - root_mean_squared_error: 657.8694\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 447965.6875 - root_mean_squared_error: 665.4735\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550152.8750 - root_mean_squared_error: 741.4999\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493594.5000 - root_mean_squared_error: 701.1522\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 412692.0625 - root_mean_squared_error: 635.9284\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585934.6250 - root_mean_squared_error: 761.9493\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513394.5625 - root_mean_squared_error: 715.7404\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462712.6562 - root_mean_squared_error: 678.0013\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525653.1250 - root_mean_squared_error: 713.3981\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4097695.0000 - root_mean_squared_error: 2023.8684\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3988803.0000 - root_mean_squared_error: 1996.6355\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3829689.5000 - root_mean_squared_error: 1956.4342\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3425903.2500 - root_mean_squared_error: 1849.0533\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3606002.7500 - root_mean_squared_error: 1898.4771\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3411905.0000 - root_mean_squared_error: 1846.5061\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3419392.0000 - root_mean_squared_error: 1848.9415\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3242583.5000 - root_mean_squared_error: 1800.3075\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3336589.2500 - root_mean_squared_error: 1825.5557\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2910823.2500 - root_mean_squared_error: 1705.2567\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3148437.7500 - root_mean_squared_error: 1773.8063\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2971128.7500 - root_mean_squared_error: 1721.4875\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2917139.7500 - root_mean_squared_error: 1706.6622\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2804927.2500 - root_mean_squared_error: 1674.4801\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2854322.7500 - root_mean_squared_error: 1687.3933\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2711115.2500 - root_mean_squared_error: 1645.9573\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2602833.0000 - root_mean_squared_error: 1612.6136\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2299953.2500 - root_mean_squared_error: 1515.4535\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1967372.2500 - root_mean_squared_error: 1401.1603\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1961896.8750 - root_mean_squared_error: 1400.3121\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1895646.5000 - root_mean_squared_error: 1375.6368\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1797719.0000 - root_mean_squared_error: 1340.6150\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1702851.5000 - root_mean_squared_error: 1304.1150\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1622228.3750 - root_mean_squared_error: 1273.0729\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1435579.7500 - root_mean_squared_error: 1197.1991\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1575869.8750 - root_mean_squared_error: 1254.5568\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1380803.5000 - root_mean_squared_error: 1174.1742\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1440434.3750 - root_mean_squared_error: 1199.0110\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1352634.2500 - root_mean_squared_error: 1160.8414\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1243213.2500 - root_mean_squared_error: 1114.3906\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1158600.3750 - root_mean_squared_error: 1074.4489\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1139221.2500 - root_mean_squared_error: 1066.8301\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1074099.8750 - root_mean_squared_error: 1035.9971\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1071234.3750 - root_mean_squared_error: 1034.5857\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 910417.5000 - root_mean_squared_error: 951.6867\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1005469.3125 - root_mean_squared_error: 1001.6476\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 876726.0625 - root_mean_squared_error: 935.7734\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 797336.3750 - root_mean_squared_error: 890.6719\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 855532.2500 - root_mean_squared_error: 924.0738\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 902401.8125 - root_mean_squared_error: 949.0950\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 779093.5625 - root_mean_squared_error: 881.5928\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 779642.4375 - root_mean_squared_error: 881.9322\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 858272.0000 - root_mean_squared_error: 925.5975\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 841475.3125 - root_mean_squared_error: 913.8529\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628003.6875 - root_mean_squared_error: 791.3922\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 691443.2500 - root_mean_squared_error: 829.9507\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 718179.8125 - root_mean_squared_error: 847.0737\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 644037.3750 - root_mean_squared_error: 801.1912\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 689581.8125 - root_mean_squared_error: 830.1340\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 665602.1875 - root_mean_squared_error: 815.4686\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617537.6250 - root_mean_squared_error: 782.7743\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 622960.5625 - root_mean_squared_error: 786.8860\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 649421.1250 - root_mean_squared_error: 802.4806\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559917.8125 - root_mean_squared_error: 746.7499\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577479.7500 - root_mean_squared_error: 758.3104\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 552463.6875 - root_mean_squared_error: 741.8192\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614208.8750 - root_mean_squared_error: 782.8641\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 633293.5000 - root_mean_squared_error: 792.0509\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617036.0625 - root_mean_squared_error: 784.6569\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 680029.1250 - root_mean_squared_error: 822.2214\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546729.2500 - root_mean_squared_error: 736.7858\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515563.5625 - root_mean_squared_error: 717.3563\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566715.5625 - root_mean_squared_error: 752.1294\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547970.0625 - root_mean_squared_error: 738.8576\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492670.3125 - root_mean_squared_error: 700.2721\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 461451.2188 - root_mean_squared_error: 677.9487\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583837.2500 - root_mean_squared_error: 761.3248\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569124.9375 - root_mean_squared_error: 752.7887\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579278.3750 - root_mean_squared_error: 759.6591\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533515.3125 - root_mean_squared_error: 729.3533\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473758.2500 - root_mean_squared_error: 686.8467\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 569201.1250 - root_mean_squared_error: 753.3655\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 534379.3750 - root_mean_squared_error: 727.7203\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532158.7500 - root_mean_squared_error: 727.9188\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 545841.3125 - root_mean_squared_error: 738.5065\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 538597.6875 - root_mean_squared_error: 732.9625\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516967.5000 - root_mean_squared_error: 718.3231\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 536077.1250 - root_mean_squared_error: 732.0175\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520811.8750 - root_mean_squared_error: 717.9791\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486813.8750 - root_mean_squared_error: 697.4335\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 453303.4062 - root_mean_squared_error: 672.0771\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490982.1875 - root_mean_squared_error: 699.3470\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 530796.2500 - root_mean_squared_error: 726.7283\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509397.6875 - root_mean_squared_error: 711.0259\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539099.0000 - root_mean_squared_error: 733.5350\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553594.0625 - root_mean_squared_error: 743.0831\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 468985.0938 - root_mean_squared_error: 684.5688\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504577.0625 - root_mean_squared_error: 708.8497\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 480933.0938 - root_mean_squared_error: 689.2352\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495746.1250 - root_mean_squared_error: 702.5444\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566143.1250 - root_mean_squared_error: 752.0789\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508220.2500 - root_mean_squared_error: 711.9016\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522459.8125 - root_mean_squared_error: 721.8934\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502565.6875 - root_mean_squared_error: 708.1513\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489391.5000 - root_mean_squared_error: 698.6381\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492899.1250 - root_mean_squared_error: 700.6064\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 456571.6562 - root_mean_squared_error: 673.6758\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540268.0000 - root_mean_squared_error: 732.9997\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485567.5938 - root_mean_squared_error: 695.8422\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510497.2812 - root_mean_squared_error: 712.9198\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520209.3125 - root_mean_squared_error: 717.0919\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537183.5625 - root_mean_squared_error: 732.1849\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497863.5000 - root_mean_squared_error: 704.6830\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511727.1562 - root_mean_squared_error: 713.6929\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 528167.5625 - root_mean_squared_error: 726.1934\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506661.4062 - root_mean_squared_error: 711.2568\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564096.9375 - root_mean_squared_error: 750.6093\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 437443.6875 - root_mean_squared_error: 659.2418\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533373.6875 - root_mean_squared_error: 728.2228\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527977.4375 - root_mean_squared_error: 725.8712\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536528.1250 - root_mean_squared_error: 730.2344\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 428771.1875 - root_mean_squared_error: 653.2791\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 544893.6875 - root_mean_squared_error: 735.4360\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526813.3750 - root_mean_squared_error: 723.9501\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 576398.3750 - root_mean_squared_error: 758.3172\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500758.7188 - root_mean_squared_error: 706.6277\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 529012.9375 - root_mean_squared_error: 726.3802\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 423647.7812 - root_mean_squared_error: 649.6871\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512796.3750 - root_mean_squared_error: 714.2186\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506104.2500 - root_mean_squared_error: 711.1012\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 418170.2812 - root_mean_squared_error: 644.6163\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502654.3125 - root_mean_squared_error: 708.5300\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 480247.7812 - root_mean_squared_error: 692.0344\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 495180.3438 - root_mean_squared_error: 702.2588\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 556470.1250 - root_mean_squared_error: 742.9520\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463880.6562 - root_mean_squared_error: 680.2969\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543385.6250 - root_mean_squared_error: 735.2068\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520222.1250 - root_mean_squared_error: 720.6925\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504588.5312 - root_mean_squared_error: 709.7880\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536002.6875 - root_mean_squared_error: 730.9335\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540745.6250 - root_mean_squared_error: 731.9708\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516933.3125 - root_mean_squared_error: 717.8769\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 542722.5000 - root_mean_squared_error: 732.2432\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 449590.2812 - root_mean_squared_error: 668.2146\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508240.2188 - root_mean_squared_error: 711.3729\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520640.5625 - root_mean_squared_error: 715.7343\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463347.9688 - root_mean_squared_error: 678.9226\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482398.6562 - root_mean_squared_error: 692.5895\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 530722.8750 - root_mean_squared_error: 726.4530\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495610.9375 - root_mean_squared_error: 702.1545\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 478508.4375 - root_mean_squared_error: 691.0378\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464201.4688 - root_mean_squared_error: 679.2358\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 456358.8750 - root_mean_squared_error: 674.3588\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451153.5000 - root_mean_squared_error: 670.1708\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491158.5312 - root_mean_squared_error: 699.4378\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 450791.9688 - root_mean_squared_error: 666.4174\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555328.9375 - root_mean_squared_error: 743.8582\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523108.2188 - root_mean_squared_error: 721.3956\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 546110.7500 - root_mean_squared_error: 738.1577\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561549.8125 - root_mean_squared_error: 748.2652\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520713.2812 - root_mean_squared_error: 720.3079\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 449887.6250 - root_mean_squared_error: 668.7368\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535690.2500 - root_mean_squared_error: 731.5386\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 449296.5312 - root_mean_squared_error: 667.6964\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 444666.5938 - root_mean_squared_error: 661.9169\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 544983.2500 - root_mean_squared_error: 732.7665\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 453958.7500 - root_mean_squared_error: 671.5810\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533079.3750 - root_mean_squared_error: 729.6213\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547839.5000 - root_mean_squared_error: 735.3329\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545759.6250 - root_mean_squared_error: 737.1253\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527802.1250 - root_mean_squared_error: 726.0591\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545828.4375 - root_mean_squared_error: 737.8709\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433201.2500 - root_mean_squared_error: 656.8002\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522347.6875 - root_mean_squared_error: 722.2076\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482017.9688 - root_mean_squared_error: 693.0229\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490865.0625 - root_mean_squared_error: 698.8433\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 572914.8750 - root_mean_squared_error: 747.3987\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490741.0938 - root_mean_squared_error: 699.9309\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 439858.6562 - root_mean_squared_error: 661.7745\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 564389.1875 - root_mean_squared_error: 747.9434\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594856.6875 - root_mean_squared_error: 768.6901\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 447623.0000 - root_mean_squared_error: 668.1262\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 522286.5938 - root_mean_squared_error: 721.8568\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541341.4375 - root_mean_squared_error: 734.8155\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507778.4062 - root_mean_squared_error: 710.8806\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573661.4375 - root_mean_squared_error: 752.6146\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529434.4375 - root_mean_squared_error: 727.0381\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539747.8750 - root_mean_squared_error: 732.7879\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492501.8125 - root_mean_squared_error: 699.6130\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 432325.0625 - root_mean_squared_error: 655.4037\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515684.5938 - root_mean_squared_error: 717.6879\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 597293.8125 - root_mean_squared_error: 768.7971\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448853.2812 - root_mean_squared_error: 664.8745\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 492521.2812 - root_mean_squared_error: 700.4014\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544513.2500 - root_mean_squared_error: 735.2740\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496233.0625 - root_mean_squared_error: 703.1466\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 457562.3438 - root_mean_squared_error: 673.0043\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533783.3125 - root_mean_squared_error: 726.4581\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 488107.7188 - root_mean_squared_error: 694.6021\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 429859.0312 - root_mean_squared_error: 652.4313\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 486104.0312 - root_mean_squared_error: 696.3560\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522100.8750 - root_mean_squared_error: 719.2775\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 449833.0312 - root_mean_squared_error: 668.9695\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 541307.8750 - root_mean_squared_error: 734.8480\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499975.8750 - root_mean_squared_error: 703.1907\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560387.6250 - root_mean_squared_error: 746.8685\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 420055.8438 - root_mean_squared_error: 646.0202\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573067.3125 - root_mean_squared_error: 755.2516\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 427698.4375 - root_mean_squared_error: 644.4934\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 446620.4375 - root_mean_squared_error: 667.6878\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453197.7500 - root_mean_squared_error: 671.6912\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493849.5938 - root_mean_squared_error: 691.3566\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4141181.2500 - root_mean_squared_error: 2034.3185\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3948058.5000 - root_mean_squared_error: 1986.1405\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3801927.5000 - root_mean_squared_error: 1949.5251\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3854250.2500 - root_mean_squared_error: 1962.6021\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3544509.2500 - root_mean_squared_error: 1882.1552\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3326259.7500 - root_mean_squared_error: 1823.2958\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3139474.7500 - root_mean_squared_error: 1771.6049\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3292483.0000 - root_mean_squared_error: 1812.6006\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3042188.2500 - root_mean_squared_error: 1743.8234\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2980154.5000 - root_mean_squared_error: 1723.1476\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2820721.2500 - root_mean_squared_error: 1676.9681\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2584360.5000 - root_mean_squared_error: 1607.3027\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2372242.7500 - root_mean_squared_error: 1539.0265\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2251888.7500 - root_mean_squared_error: 1499.3394\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2199395.0000 - root_mean_squared_error: 1482.5096\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2369174.7500 - root_mean_squared_error: 1537.1256\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2145101.7500 - root_mean_squared_error: 1462.8031\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1869372.3750 - root_mean_squared_error: 1366.6124\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1936185.2500 - root_mean_squared_error: 1390.6436\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1888047.7500 - root_mean_squared_error: 1371.6693\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1778354.7500 - root_mean_squared_error: 1333.0249\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1745338.1250 - root_mean_squared_error: 1319.4653\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1610967.7500 - root_mean_squared_error: 1268.6115\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1500717.5000 - root_mean_squared_error: 1224.4840\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1461741.0000 - root_mean_squared_error: 1208.1416\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1367598.3750 - root_mean_squared_error: 1167.9681\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1456877.5000 - root_mean_squared_error: 1203.2581\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1338368.7500 - root_mean_squared_error: 1155.8341\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1225187.8750 - root_mean_squared_error: 1106.0862\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1241721.0000 - root_mean_squared_error: 1114.1799\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1138985.3750 - root_mean_squared_error: 1066.8547\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1137555.7500 - root_mean_squared_error: 1065.6069\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1004083.4375 - root_mean_squared_error: 1001.3694\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1029549.8125 - root_mean_squared_error: 1014.0607\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 955996.8750 - root_mean_squared_error: 976.6028\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 903882.9375 - root_mean_squared_error: 947.3764\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 934300.0000 - root_mean_squared_error: 964.8839\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 890789.6875 - root_mean_squared_error: 942.7229\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 867939.1875 - root_mean_squared_error: 929.5453\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 860785.8125 - root_mean_squared_error: 926.8981\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 772477.6250 - root_mean_squared_error: 876.9464\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 809708.1250 - root_mean_squared_error: 899.4706\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 786736.3750 - root_mean_squared_error: 885.9374\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 716319.7500 - root_mean_squared_error: 845.4361\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 625530.4375 - root_mean_squared_error: 787.9338\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 798521.0625 - root_mean_squared_error: 891.8278\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 636125.5625 - root_mean_squared_error: 795.0283\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 684601.1875 - root_mean_squared_error: 827.0664\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605436.5625 - root_mean_squared_error: 776.8189\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 657954.4375 - root_mean_squared_error: 810.8032\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610941.2500 - root_mean_squared_error: 781.0065\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 661417.6875 - root_mean_squared_error: 812.6999\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603813.0000 - root_mean_squared_error: 776.7408\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 597117.7500 - root_mean_squared_error: 771.2341\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 621468.1875 - root_mean_squared_error: 787.3950\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540850.7500 - root_mean_squared_error: 732.5728\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 636042.3750 - root_mean_squared_error: 795.6826\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586404.5000 - root_mean_squared_error: 764.9894\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512692.9062 - root_mean_squared_error: 714.2021\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 646853.0000 - root_mean_squared_error: 802.1902\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539508.4375 - root_mean_squared_error: 733.3211\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577560.9375 - root_mean_squared_error: 759.7404\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463603.2500 - root_mean_squared_error: 678.7396\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524802.3125 - root_mean_squared_error: 723.1995\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 578845.8125 - root_mean_squared_error: 759.2879\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 646264.2500 - root_mean_squared_error: 798.8690\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577104.8750 - root_mean_squared_error: 756.7428\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540973.1875 - root_mean_squared_error: 733.8944\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 620328.4375 - root_mean_squared_error: 785.3255\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555020.6250 - root_mean_squared_error: 743.8239\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486478.3438 - root_mean_squared_error: 696.8167\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 582724.0625 - root_mean_squared_error: 760.0590\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508873.6875 - root_mean_squared_error: 712.6353\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519356.9375 - root_mean_squared_error: 719.4551\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 478960.5312 - root_mean_squared_error: 689.7626\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 471491.0938 - root_mean_squared_error: 684.9514\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500814.3125 - root_mean_squared_error: 705.6333\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464561.5000 - root_mean_squared_error: 679.2058\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473133.1250 - root_mean_squared_error: 686.9921\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570024.8750 - root_mean_squared_error: 751.8809\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509857.3438 - root_mean_squared_error: 713.1789\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489317.6562 - root_mean_squared_error: 697.0340\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 564417.9375 - root_mean_squared_error: 749.0825\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570320.7500 - root_mean_squared_error: 754.5272\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563575.2500 - root_mean_squared_error: 749.4831\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553231.6250 - root_mean_squared_error: 741.5646\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 624711.3750 - root_mean_squared_error: 783.8233\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511607.0625 - root_mean_squared_error: 714.6540\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 485989.9062 - root_mean_squared_error: 695.9143\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 573207.8125 - root_mean_squared_error: 755.9297\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 581137.3125 - root_mean_squared_error: 760.2789\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521380.4375 - root_mean_squared_error: 721.0336\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 487254.1875 - root_mean_squared_error: 697.2266\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 576300.3750 - root_mean_squared_error: 758.1483\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562597.2500 - root_mean_squared_error: 749.0932\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 618852.4375 - root_mean_squared_error: 784.5389\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520159.0312 - root_mean_squared_error: 718.8198\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 438767.8125 - root_mean_squared_error: 658.6285\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 587101.1250 - root_mean_squared_error: 763.0273\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 569505.9375 - root_mean_squared_error: 753.1443\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502604.0312 - root_mean_squared_error: 707.9710\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500387.6250 - root_mean_squared_error: 706.4119\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550303.9375 - root_mean_squared_error: 741.3680\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520644.3750 - root_mean_squared_error: 720.3967\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533577.4375 - root_mean_squared_error: 726.7606\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 437882.6875 - root_mean_squared_error: 659.7778\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 602926.9375 - root_mean_squared_error: 774.5891\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505661.1250 - root_mean_squared_error: 710.6216\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480986.0625 - root_mean_squared_error: 692.4274\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 470811.0312 - root_mean_squared_error: 685.1033\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561771.3750 - root_mean_squared_error: 746.4797\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 461870.0000 - root_mean_squared_error: 677.9802\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563944.4375 - root_mean_squared_error: 749.0179\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522121.4062 - root_mean_squared_error: 721.1913\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510567.2188 - root_mean_squared_error: 712.9363\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559059.9375 - root_mean_squared_error: 745.5984\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 576845.5000 - root_mean_squared_error: 757.7961\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 531987.6250 - root_mean_squared_error: 727.8551\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540356.0000 - root_mean_squared_error: 729.5288\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509463.1562 - root_mean_squared_error: 709.4457\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546415.0000 - root_mean_squared_error: 738.5291\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540044.4375 - root_mean_squared_error: 732.7280\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 459312.1562 - root_mean_squared_error: 676.7584\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 549715.4375 - root_mean_squared_error: 739.7549\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 596177.8125 - root_mean_squared_error: 768.8655\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522307.9062 - root_mean_squared_error: 720.1535\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603821.6875 - root_mean_squared_error: 768.0791\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516982.9688 - root_mean_squared_error: 718.4077\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 409270.0938 - root_mean_squared_error: 636.0696\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 438328.1562 - root_mean_squared_error: 659.4202\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536387.8750 - root_mean_squared_error: 730.3179\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 532654.5625 - root_mean_squared_error: 728.4096\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540351.8125 - root_mean_squared_error: 734.1465\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497138.6250 - root_mean_squared_error: 702.0618\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485690.4688 - root_mean_squared_error: 695.5964\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 502361.0000 - root_mean_squared_error: 708.4313\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536149.5000 - root_mean_squared_error: 730.7858\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460006.7500 - root_mean_squared_error: 676.9556\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511104.7188 - root_mean_squared_error: 712.9763\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501422.7500 - root_mean_squared_error: 707.4194\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511110.0625 - root_mean_squared_error: 712.1559\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500850.5312 - root_mean_squared_error: 706.5416\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472946.7812 - root_mean_squared_error: 686.4857\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 459348.9688 - root_mean_squared_error: 677.1037\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464579.6875 - root_mean_squared_error: 678.3086\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507579.3125 - root_mean_squared_error: 711.9984\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570312.5625 - root_mean_squared_error: 750.4568\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 431269.5000 - root_mean_squared_error: 653.3775\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521472.2188 - root_mean_squared_error: 721.4330\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584455.0000 - root_mean_squared_error: 762.0011\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 582166.6250 - root_mean_squared_error: 762.1384\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 552029.0625 - root_mean_squared_error: 741.8125\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 571543.6250 - root_mean_squared_error: 751.3209\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490201.3125 - root_mean_squared_error: 698.6902\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494274.1250 - root_mean_squared_error: 701.5670\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 510045.4688 - root_mean_squared_error: 711.7811\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 614718.1250 - root_mean_squared_error: 779.0731\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 470383.5625 - root_mean_squared_error: 683.6825\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547790.5625 - root_mean_squared_error: 738.6456\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 463552.4688 - root_mean_squared_error: 679.8177\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523016.3438 - root_mean_squared_error: 721.3448\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 537766.2500 - root_mean_squared_error: 732.7548\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535350.8125 - root_mean_squared_error: 731.1354\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494921.5000 - root_mean_squared_error: 702.4642\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562822.2500 - root_mean_squared_error: 748.4652\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545847.6250 - root_mean_squared_error: 737.6873\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515424.7812 - root_mean_squared_error: 715.3734\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482717.9062 - root_mean_squared_error: 693.9249\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504682.4062 - root_mean_squared_error: 710.0168\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 575538.5000 - root_mean_squared_error: 758.2341\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550014.3125 - root_mean_squared_error: 736.9232\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473099.4375 - root_mean_squared_error: 684.2921\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 612005.0625 - root_mean_squared_error: 772.3107\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527273.5000 - root_mean_squared_error: 722.8884\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488771.4688 - root_mean_squared_error: 697.4116\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 598101.6875 - root_mean_squared_error: 771.5710\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 596345.1875 - root_mean_squared_error: 771.2977\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 453702.7500 - root_mean_squared_error: 669.8808\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 613700.2500 - root_mean_squared_error: 778.9728\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465624.0312 - root_mean_squared_error: 679.8406\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 484583.3125 - root_mean_squared_error: 694.4796\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 543980.5625 - root_mean_squared_error: 736.5453\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561753.5625 - root_mean_squared_error: 747.3158\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 513725.4062 - root_mean_squared_error: 716.2329\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556750.1250 - root_mean_squared_error: 744.7932\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540313.0000 - root_mean_squared_error: 732.3091\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465020.7188 - root_mean_squared_error: 679.6500\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533645.5000 - root_mean_squared_error: 729.6262\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 444806.5625 - root_mean_squared_error: 664.4681\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490215.9062 - root_mean_squared_error: 699.5548\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490314.8438 - root_mean_squared_error: 697.9995\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 579327.0625 - root_mean_squared_error: 756.7982\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 484354.0625 - root_mean_squared_error: 692.7829\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 449611.2812 - root_mean_squared_error: 666.0988\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539617.9375 - root_mean_squared_error: 732.2369\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 623064.0000 - root_mean_squared_error: 784.6505\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531606.6875 - root_mean_squared_error: 726.2647\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537449.8750 - root_mean_squared_error: 730.6302\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 586663.0625 - root_mean_squared_error: 762.9578\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512189.1875 - root_mean_squared_error: 714.5154\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483040.3750 - root_mean_squared_error: 692.6326\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509429.6250 - root_mean_squared_error: 701.4785\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step \n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3977791.0000 - root_mean_squared_error: 1993.2769\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4013785.5000 - root_mean_squared_error: 2002.5005\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3976376.7500 - root_mean_squared_error: 1993.8451\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3676018.7500 - root_mean_squared_error: 1915.3757\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3620816.7500 - root_mean_squared_error: 1901.6427\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3079384.7500 - root_mean_squared_error: 1752.1682\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3070367.0000 - root_mean_squared_error: 1751.9790\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3347861.2500 - root_mean_squared_error: 1828.0789\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3050223.0000 - root_mean_squared_error: 1746.0325\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2877568.5000 - root_mean_squared_error: 1695.6663\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2858737.7500 - root_mean_squared_error: 1690.3663\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2702314.0000 - root_mean_squared_error: 1643.2089\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2511500.0000 - root_mean_squared_error: 1584.0176\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2541286.7500 - root_mean_squared_error: 1593.4695\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2173030.2500 - root_mean_squared_error: 1473.4830\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2280144.7500 - root_mean_squared_error: 1509.1718\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2072761.8750 - root_mean_squared_error: 1439.1904\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1977012.5000 - root_mean_squared_error: 1405.1016\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1998098.5000 - root_mean_squared_error: 1412.4980\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1754577.5000 - root_mean_squared_error: 1323.2736\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1670137.7500 - root_mean_squared_error: 1290.4816\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1636121.0000 - root_mean_squared_error: 1278.5361\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1496130.6250 - root_mean_squared_error: 1220.5173\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1430995.6250 - root_mean_squared_error: 1195.3308\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1520914.2500 - root_mean_squared_error: 1232.8818\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1414790.1250 - root_mean_squared_error: 1188.6938\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1397799.8750 - root_mean_squared_error: 1181.9724\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1291053.1250 - root_mean_squared_error: 1134.3738\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1264769.1250 - root_mean_squared_error: 1123.8435\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1130301.0000 - root_mean_squared_error: 1062.8699\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1073976.5000 - root_mean_squared_error: 1034.9137\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1155724.8750 - root_mean_squared_error: 1074.5542\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1188900.6250 - root_mean_squared_error: 1088.6804\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 973534.0625 - root_mean_squared_error: 982.7925\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 908419.7500 - root_mean_squared_error: 951.7915\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 959444.4375 - root_mean_squared_error: 978.8547\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 962720.4375 - root_mean_squared_error: 979.9816\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 832266.1250 - root_mean_squared_error: 909.7408\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 867345.8125 - root_mean_squared_error: 930.8110\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 872823.5000 - root_mean_squared_error: 933.7359\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 722681.7500 - root_mean_squared_error: 848.7283\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 817004.7500 - root_mean_squared_error: 901.8902\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 717641.6250 - root_mean_squared_error: 845.4029\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 771402.6250 - root_mean_squared_error: 876.0071\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 824567.1875 - root_mean_squared_error: 901.9965\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 710557.5625 - root_mean_squared_error: 842.2240\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 739524.2500 - root_mean_squared_error: 859.3665\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 649369.1250 - root_mean_squared_error: 805.5031\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 670182.8125 - root_mean_squared_error: 817.2080\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 629369.9375 - root_mean_squared_error: 792.8669\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 661494.1250 - root_mean_squared_error: 812.4344\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573939.3125 - root_mean_squared_error: 755.6744\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 609916.8750 - root_mean_squared_error: 780.3690\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 595966.0000 - root_mean_squared_error: 771.3367\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501322.2500 - root_mean_squared_error: 704.3342\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 611617.6250 - root_mean_squared_error: 779.0131\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590024.2500 - root_mean_squared_error: 767.5081\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550135.5625 - root_mean_squared_error: 741.1564\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583258.5625 - root_mean_squared_error: 762.3295\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 612893.6250 - root_mean_squared_error: 781.9647\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 593438.7500 - root_mean_squared_error: 769.4617\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 575578.3750 - root_mean_squared_error: 755.6582\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 573644.5000 - root_mean_squared_error: 755.7054\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565062.8750 - root_mean_squared_error: 750.8777\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 648371.9375 - root_mean_squared_error: 802.1066\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593543.6875 - root_mean_squared_error: 769.8444\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543729.6875 - root_mean_squared_error: 736.8615\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555061.0625 - root_mean_squared_error: 744.4329\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543838.6875 - root_mean_squared_error: 736.5334\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 612725.1875 - root_mean_squared_error: 782.0835\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 599574.4375 - root_mean_squared_error: 773.0869\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547383.0625 - root_mean_squared_error: 738.9944\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538773.8750 - root_mean_squared_error: 732.3241\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508355.5625 - root_mean_squared_error: 711.6735\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566319.1875 - root_mean_squared_error: 752.2914\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501660.4062 - root_mean_squared_error: 705.7715\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 532931.3125 - root_mean_squared_error: 728.2750\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561365.4375 - root_mean_squared_error: 747.1039\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521362.5312 - root_mean_squared_error: 720.1107\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495425.0312 - root_mean_squared_error: 702.9293\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499260.8750 - root_mean_squared_error: 704.3564\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476228.6562 - root_mean_squared_error: 686.7651\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 493730.9375 - root_mean_squared_error: 701.8151\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 469850.4688 - root_mean_squared_error: 684.8729\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504226.8438 - root_mean_squared_error: 709.3799\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498347.5625 - root_mean_squared_error: 703.9951\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549469.6250 - root_mean_squared_error: 740.2149\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 555275.6875 - root_mean_squared_error: 743.8343\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 583976.2500 - root_mean_squared_error: 762.4348\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 615024.6250 - root_mean_squared_error: 779.7249\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475362.9688 - root_mean_squared_error: 683.9150\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 467936.2188 - root_mean_squared_error: 681.8235\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 590818.3125 - root_mean_squared_error: 766.3353\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475414.4375 - root_mean_squared_error: 684.9884\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 552543.9375 - root_mean_squared_error: 742.2417\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 535277.6250 - root_mean_squared_error: 730.9109\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504999.6250 - root_mean_squared_error: 709.0193\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521563.9688 - root_mean_squared_error: 721.0961\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 600916.0625 - root_mean_squared_error: 773.6389\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511384.6562 - root_mean_squared_error: 712.2291\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561235.6250 - root_mean_squared_error: 748.0671\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503871.4062 - root_mean_squared_error: 707.5682\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 645505.8750 - root_mean_squared_error: 793.5247\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 477217.2500 - root_mean_squared_error: 688.9817\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 537107.3750 - root_mean_squared_error: 730.5405\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556530.5625 - root_mean_squared_error: 745.1661\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 591138.2500 - root_mean_squared_error: 766.9157\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570706.5000 - root_mean_squared_error: 754.5363\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539956.6250 - root_mean_squared_error: 733.1058\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 572104.1250 - root_mean_squared_error: 754.3945\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515606.1875 - root_mean_squared_error: 716.5993\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547841.8125 - root_mean_squared_error: 738.8093\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492578.4688 - root_mean_squared_error: 700.6399\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 571059.4375 - root_mean_squared_error: 754.9975\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 471009.6562 - root_mean_squared_error: 680.4086\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590812.9375 - root_mean_squared_error: 762.0993\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579384.6250 - root_mean_squared_error: 760.0095\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502395.0938 - root_mean_squared_error: 708.2776\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579388.7500 - root_mean_squared_error: 758.5518\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510387.0312 - root_mean_squared_error: 713.3019\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 575688.5000 - root_mean_squared_error: 757.9384\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 545699.9375 - root_mean_squared_error: 737.0120\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 470136.2812 - root_mean_squared_error: 684.4760\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 520376.5000 - root_mean_squared_error: 720.6149\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474288.2500 - root_mean_squared_error: 687.4389\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512495.1562 - root_mean_squared_error: 715.2514\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499505.4375 - root_mean_squared_error: 705.1917\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 552321.5625 - root_mean_squared_error: 741.6307\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448268.7500 - root_mean_squared_error: 665.9097\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551598.2500 - root_mean_squared_error: 740.9110\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 531270.8750 - root_mean_squared_error: 726.7911\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531080.3125 - root_mean_squared_error: 726.6378\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548755.1875 - root_mean_squared_error: 739.3100\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 538005.2500 - root_mean_squared_error: 732.6970\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492968.0312 - root_mean_squared_error: 701.3677\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497478.5938 - root_mean_squared_error: 702.8132\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492602.2500 - root_mean_squared_error: 700.3558\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570656.3750 - root_mean_squared_error: 752.1487\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485964.9062 - root_mean_squared_error: 695.9048\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533916.5625 - root_mean_squared_error: 726.9889\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 502282.6875 - root_mean_squared_error: 706.6506\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489033.5938 - root_mean_squared_error: 698.5660\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535773.1250 - root_mean_squared_error: 731.1909\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522837.8750 - root_mean_squared_error: 722.6970\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 557227.8125 - root_mean_squared_error: 741.9197\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499217.0938 - root_mean_squared_error: 703.8900\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 662227.4375 - root_mean_squared_error: 808.8811\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 433605.6250 - root_mean_squared_error: 656.7186\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 505017.1562 - root_mean_squared_error: 706.7038\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 510465.5312 - root_mean_squared_error: 712.2847\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509185.9375 - root_mean_squared_error: 710.9758\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563503.2500 - root_mean_squared_error: 749.8967\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521276.7188 - root_mean_squared_error: 720.9272\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 481465.5938 - root_mean_squared_error: 691.4953\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 503337.6875 - root_mean_squared_error: 707.3817\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 580685.0625 - root_mean_squared_error: 754.2828\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 664780.8750 - root_mean_squared_error: 812.7142\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536885.0625 - root_mean_squared_error: 730.7248\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460009.2188 - root_mean_squared_error: 676.7205\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 571213.3125 - root_mean_squared_error: 753.7410\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 599289.2500 - root_mean_squared_error: 771.5977\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 431800.4375 - root_mean_squared_error: 649.6241\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506633.9062 - root_mean_squared_error: 710.5502\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489564.3125 - root_mean_squared_error: 698.0471\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561285.5625 - root_mean_squared_error: 748.5399\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 486646.1562 - root_mean_squared_error: 694.4281\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 433422.0625 - root_mean_squared_error: 652.1088\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513571.0938 - root_mean_squared_error: 715.9679\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 618602.3125 - root_mean_squared_error: 784.3989\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539258.5625 - root_mean_squared_error: 730.6697\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508592.8750 - root_mean_squared_error: 711.4147\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505543.3438 - root_mean_squared_error: 709.7043\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544812.5000 - root_mean_squared_error: 736.8005\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594072.4375 - root_mean_squared_error: 768.2029\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 424766.6250 - root_mean_squared_error: 649.9985\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466222.6250 - root_mean_squared_error: 681.5687\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 398927.3438 - root_mean_squared_error: 627.3486\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531325.1250 - root_mean_squared_error: 725.7949\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494253.4062 - root_mean_squared_error: 699.3813\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 601972.3750 - root_mean_squared_error: 774.7165\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562698.1875 - root_mean_squared_error: 747.6510\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524863.0000 - root_mean_squared_error: 722.6917\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496249.6562 - root_mean_squared_error: 703.0582\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 541546.1875 - root_mean_squared_error: 727.6837\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 528402.2500 - root_mean_squared_error: 726.3894\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 574841.8750 - root_mean_squared_error: 757.1481\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 568423.6875 - root_mean_squared_error: 753.3288\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 578631.3750 - root_mean_squared_error: 759.6718\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 566362.3125 - root_mean_squared_error: 751.4746\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532914.6875 - root_mean_squared_error: 729.0882\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532620.8750 - root_mean_squared_error: 726.6867\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548800.5000 - root_mean_squared_error: 740.3017\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529299.6250 - root_mean_squared_error: 726.6035\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512101.6875 - root_mean_squared_error: 714.3420\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 563325.8750 - root_mean_squared_error: 748.7515\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 513915.8125 - root_mean_squared_error: 716.1888\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 548823.1250 - root_mean_squared_error: 736.9659\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 579391.8125 - root_mean_squared_error: 758.9706\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548748.0625 - root_mean_squared_error: 738.5928\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500002.3750 - root_mean_squared_error: 705.8362\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 487178.5000 - root_mean_squared_error: 695.4677\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 531433.5625 - root_mean_squared_error: 717.0165\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4293270.0000 - root_mean_squared_error: 2070.2136\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4031050.0000 - root_mean_squared_error: 2006.8918\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3581777.5000 - root_mean_squared_error: 1892.3013\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3752020.2500 - root_mean_squared_error: 1936.5341\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3695571.5000 - root_mean_squared_error: 1921.8983\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3369414.7500 - root_mean_squared_error: 1835.1519\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3212492.0000 - root_mean_squared_error: 1791.1025\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2851028.2500 - root_mean_squared_error: 1687.3773\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2865631.2500 - root_mean_squared_error: 1692.4321\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2783083.2500 - root_mean_squared_error: 1667.8710\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2664545.7500 - root_mean_squared_error: 1631.9447\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2606411.5000 - root_mean_squared_error: 1614.1656\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2528909.0000 - root_mean_squared_error: 1589.4032\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2266581.0000 - root_mean_squared_error: 1502.0815\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2375810.5000 - root_mean_squared_error: 1535.8577\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2087329.6250 - root_mean_squared_error: 1444.4607\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2078950.8750 - root_mean_squared_error: 1441.7455\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1922493.2500 - root_mean_squared_error: 1385.9993\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1700802.7500 - root_mean_squared_error: 1302.8021\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1964561.1250 - root_mean_squared_error: 1400.6843\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1641315.7500 - root_mean_squared_error: 1280.2964\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1760200.7500 - root_mean_squared_error: 1326.1643\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1607475.3750 - root_mean_squared_error: 1267.7354\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1424749.8750 - root_mean_squared_error: 1193.0342\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1494317.0000 - root_mean_squared_error: 1221.7891\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1520553.5000 - root_mean_squared_error: 1231.5463\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1288283.3750 - root_mean_squared_error: 1134.7766\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1272088.0000 - root_mean_squared_error: 1126.7010\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1113838.6250 - root_mean_squared_error: 1054.7335\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1337392.7500 - root_mean_squared_error: 1152.3315\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1221882.5000 - root_mean_squared_error: 1104.8109\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1054522.0000 - root_mean_squared_error: 1026.2172\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1006965.6250 - root_mean_squared_error: 1002.9767\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1025081.4375 - root_mean_squared_error: 1011.9940\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 985091.4375 - root_mean_squared_error: 991.6620\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 862899.3750 - root_mean_squared_error: 928.4891\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 926284.8125 - root_mean_squared_error: 962.0303\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 882123.6250 - root_mean_squared_error: 938.7742\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 847815.1250 - root_mean_squared_error: 919.3352\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 785513.5625 - root_mean_squared_error: 885.3552\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 812656.6875 - root_mean_squared_error: 898.1364\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 815380.8750 - root_mean_squared_error: 899.7230\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 846544.5000 - root_mean_squared_error: 916.6111\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 749807.1875 - root_mean_squared_error: 865.4412\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 665095.1875 - root_mean_squared_error: 813.8405\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 747535.8125 - root_mean_squared_error: 863.9189\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 667984.3125 - root_mean_squared_error: 816.8489\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 694484.7500 - root_mean_squared_error: 833.0303\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 706175.1875 - root_mean_squared_error: 836.9968\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 718576.3125 - root_mean_squared_error: 846.1460\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 692571.0000 - root_mean_squared_error: 828.3549\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 597115.5625 - root_mean_squared_error: 772.1981\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 618250.7500 - root_mean_squared_error: 783.6584\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 648244.8750 - root_mean_squared_error: 804.6118\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535249.8125 - root_mean_squared_error: 728.8668\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610641.0000 - root_mean_squared_error: 778.7758\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603363.5625 - root_mean_squared_error: 776.4451\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584389.4375 - root_mean_squared_error: 763.7166\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 594270.1250 - root_mean_squared_error: 769.6359\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 567752.6875 - root_mean_squared_error: 752.6169\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512961.9688 - root_mean_squared_error: 714.9248\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522244.6250 - root_mean_squared_error: 720.6009\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 560963.9375 - root_mean_squared_error: 744.9354\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606218.6250 - root_mean_squared_error: 775.9434\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 543467.4375 - root_mean_squared_error: 736.4919\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 465661.0938 - root_mean_squared_error: 681.5995\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518172.8125 - root_mean_squared_error: 718.7455\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 598222.3125 - root_mean_squared_error: 771.4260\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479389.0625 - root_mean_squared_error: 689.0418\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491281.0938 - root_mean_squared_error: 699.7047\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519455.5312 - root_mean_squared_error: 719.8748\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 582101.8750 - root_mean_squared_error: 761.7567\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 549669.7500 - root_mean_squared_error: 740.6466\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527597.8125 - root_mean_squared_error: 724.1760\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517261.7500 - root_mean_squared_error: 714.7056\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566976.9375 - root_mean_squared_error: 752.4994\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516149.1250 - root_mean_squared_error: 717.3212\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500518.0312 - root_mean_squared_error: 706.4885\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543348.8125 - root_mean_squared_error: 736.4578\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 564643.0625 - root_mean_squared_error: 748.0123\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 505466.6875 - root_mean_squared_error: 709.5605\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482407.4688 - root_mean_squared_error: 693.1315\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 555155.5000 - root_mean_squared_error: 742.8646\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512057.5938 - root_mean_squared_error: 714.7130\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 424412.4375 - root_mean_squared_error: 647.1821\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509891.0625 - root_mean_squared_error: 713.3367\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508076.1250 - root_mean_squared_error: 711.6094\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 569347.0625 - root_mean_squared_error: 752.6907\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544503.7500 - root_mean_squared_error: 736.5350\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 530666.3125 - root_mean_squared_error: 727.6157\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 493979.4062 - root_mean_squared_error: 702.0076\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567391.0625 - root_mean_squared_error: 752.6407\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550290.0000 - root_mean_squared_error: 740.7238\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 620247.5000 - root_mean_squared_error: 786.0474\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500136.0000 - root_mean_squared_error: 705.9324\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504136.0625 - root_mean_squared_error: 708.6663\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550225.8750 - root_mean_squared_error: 740.3840\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465611.3750 - root_mean_squared_error: 679.0602\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560346.8750 - root_mean_squared_error: 747.0427\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 522823.5000 - root_mean_squared_error: 722.5058\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516676.8750 - root_mean_squared_error: 716.4833\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 575855.7500 - root_mean_squared_error: 758.1600\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 608655.6875 - root_mean_squared_error: 774.6127\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 466288.2188 - root_mean_squared_error: 680.0474\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 450768.2188 - root_mean_squared_error: 668.4410\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 442586.3750 - root_mean_squared_error: 662.3822\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505622.2188 - root_mean_squared_error: 710.2784\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 471404.3750 - root_mean_squared_error: 685.6242\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495650.2812 - root_mean_squared_error: 703.4885\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542051.5625 - root_mean_squared_error: 734.8921\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513470.2812 - root_mean_squared_error: 715.5112\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550733.2500 - root_mean_squared_error: 740.9829\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489000.9688 - root_mean_squared_error: 697.3773\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 484141.5625 - root_mean_squared_error: 693.8514\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501618.5000 - root_mean_squared_error: 706.1288\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 585484.5625 - root_mean_squared_error: 761.2779\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 466763.4375 - root_mean_squared_error: 681.9077\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 552572.0000 - root_mean_squared_error: 739.2666\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 455991.2812 - root_mean_squared_error: 674.0027\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 562781.3750 - root_mean_squared_error: 745.3762\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464362.5312 - root_mean_squared_error: 680.2450\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 557407.1875 - root_mean_squared_error: 740.3325\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506682.7500 - root_mean_squared_error: 711.5535\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535546.6875 - root_mean_squared_error: 729.4037\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483473.9062 - root_mean_squared_error: 693.2625\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535369.6250 - root_mean_squared_error: 728.9910\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 525779.6875 - root_mean_squared_error: 723.7011\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463180.2812 - root_mean_squared_error: 677.3657\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556324.7500 - root_mean_squared_error: 744.2888\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 503443.9375 - root_mean_squared_error: 709.1406\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546365.0625 - root_mean_squared_error: 737.0866\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527017.8125 - root_mean_squared_error: 724.3568\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508950.8750 - root_mean_squared_error: 710.5159\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 560710.0625 - root_mean_squared_error: 747.6042\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488252.1250 - root_mean_squared_error: 697.8165\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494095.2500 - root_mean_squared_error: 702.5942\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 545295.9375 - root_mean_squared_error: 736.3537\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 530967.8750 - root_mean_squared_error: 726.7964\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496563.4375 - root_mean_squared_error: 703.2435\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563025.5000 - root_mean_squared_error: 748.2332\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561613.4375 - root_mean_squared_error: 748.1896\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503108.3438 - root_mean_squared_error: 707.9208\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 436555.6250 - root_mean_squared_error: 656.1420\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 566118.3750 - root_mean_squared_error: 751.1636\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512638.1875 - root_mean_squared_error: 715.6208\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 483723.2500 - root_mean_squared_error: 695.0685\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 510292.0000 - root_mean_squared_error: 713.3012\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 467794.0625 - root_mean_squared_error: 682.7453\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463068.2812 - root_mean_squared_error: 679.4204\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 502137.4375 - root_mean_squared_error: 707.8823\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 462632.7188 - root_mean_squared_error: 679.6924\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 430595.8438 - root_mean_squared_error: 654.3307\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494695.4375 - root_mean_squared_error: 699.9044\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460727.5625 - root_mean_squared_error: 677.3837\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 470996.8125 - root_mean_squared_error: 685.2350\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 513200.5000 - root_mean_squared_error: 715.1829\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496513.6562 - root_mean_squared_error: 703.4543\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489794.8125 - root_mean_squared_error: 699.3123\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 518532.5312 - root_mean_squared_error: 717.4105\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498600.2812 - root_mean_squared_error: 704.6686\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 534339.4375 - root_mean_squared_error: 728.5378\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521822.5312 - root_mean_squared_error: 719.5265\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500685.0000 - root_mean_squared_error: 707.0070\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539244.8125 - root_mean_squared_error: 726.9602\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 619258.1875 - root_mean_squared_error: 784.4722\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505558.3750 - root_mean_squared_error: 710.0198\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492898.5625 - root_mean_squared_error: 701.3804\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509686.1562 - root_mean_squared_error: 712.1360\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590388.8750 - root_mean_squared_error: 765.2833\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 583745.1875 - root_mean_squared_error: 762.7899\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519333.6875 - root_mean_squared_error: 718.9737\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474113.3125 - root_mean_squared_error: 687.2722\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491330.2500 - root_mean_squared_error: 699.0945\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 537477.5625 - root_mean_squared_error: 732.1344\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507759.8438 - root_mean_squared_error: 712.1914\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460697.0312 - root_mean_squared_error: 677.0293\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483817.5938 - root_mean_squared_error: 695.1110\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 477300.7812 - root_mean_squared_error: 689.3299\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474898.9062 - root_mean_squared_error: 687.7542\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 610091.5000 - root_mean_squared_error: 778.4633\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517466.1562 - root_mean_squared_error: 717.7800\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508930.4062 - root_mean_squared_error: 713.0062\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488668.1250 - root_mean_squared_error: 697.7848\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501790.8750 - root_mean_squared_error: 706.9227\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523493.1250 - root_mean_squared_error: 722.4217\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524672.6875 - root_mean_squared_error: 723.3549\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542343.3125 - root_mean_squared_error: 734.4873\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 485366.3438 - root_mean_squared_error: 695.1952\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523558.9375 - root_mean_squared_error: 722.8210\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539557.8125 - root_mean_squared_error: 733.4590\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531244.3750 - root_mean_squared_error: 728.0038\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 438454.7188 - root_mean_squared_error: 659.2462\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 438949.0625 - root_mean_squared_error: 659.2188\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496136.9375 - root_mean_squared_error: 703.9950\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 541524.6875 - root_mean_squared_error: 734.7038\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490701.0312 - root_mean_squared_error: 699.8058\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 612441.8125 - root_mean_squared_error: 778.8101\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521144.7812 - root_mean_squared_error: 721.6028\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547719.1250 - root_mean_squared_error: 738.3635\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 541911.1875 - root_mean_squared_error: 735.0980\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493141.0625 - root_mean_squared_error: 700.8488\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 556275.5000 - root_mean_squared_error: 735.3669\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4311084.0000 - root_mean_squared_error: 2075.4385\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3970179.7500 - root_mean_squared_error: 1991.1510\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3717217.0000 - root_mean_squared_error: 1927.4620\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3677367.0000 - root_mean_squared_error: 1917.1227\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3522267.5000 - root_mean_squared_error: 1875.9292\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3272866.0000 - root_mean_squared_error: 1808.7019\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3184693.0000 - root_mean_squared_error: 1784.3823\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3065520.0000 - root_mean_squared_error: 1750.3627\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3138612.7500 - root_mean_squared_error: 1771.3396\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2964595.5000 - root_mean_squared_error: 1721.4438\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2643313.5000 - root_mean_squared_error: 1624.7211\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2828681.7500 - root_mean_squared_error: 1681.5240\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2677660.0000 - root_mean_squared_error: 1635.7909\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2297096.5000 - root_mean_squared_error: 1514.9857\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2260845.5000 - root_mean_squared_error: 1501.4581\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2256811.2500 - root_mean_squared_error: 1502.0201\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2247941.7500 - root_mean_squared_error: 1498.4740\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1928552.1250 - root_mean_squared_error: 1387.4646\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2218482.7500 - root_mean_squared_error: 1484.9705\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1835909.2500 - root_mean_squared_error: 1354.4792\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1982046.2500 - root_mean_squared_error: 1404.7308\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1829473.0000 - root_mean_squared_error: 1350.2102\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1628624.5000 - root_mean_squared_error: 1275.2206\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1545154.0000 - root_mean_squared_error: 1242.8457\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1424523.2500 - root_mean_squared_error: 1193.1897\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1475101.7500 - root_mean_squared_error: 1213.0276\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1389035.8750 - root_mean_squared_error: 1177.5044\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1291454.8750 - root_mean_squared_error: 1135.9904\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1308828.7500 - root_mean_squared_error: 1143.0181\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1240153.5000 - root_mean_squared_error: 1113.2185\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1133121.0000 - root_mean_squared_error: 1063.6840\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1149486.1250 - root_mean_squared_error: 1071.3889\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1242236.3750 - root_mean_squared_error: 1108.1914\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1137184.1250 - root_mean_squared_error: 1065.6368\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1013767.9375 - root_mean_squared_error: 1006.4159\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 980087.7500 - root_mean_squared_error: 989.3261\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 934098.9375 - root_mean_squared_error: 966.1262\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 886575.0625 - root_mean_squared_error: 939.4982\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 863288.8750 - root_mean_squared_error: 927.8309\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 798692.4375 - root_mean_squared_error: 892.2214\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 883967.0000 - root_mean_squared_error: 934.7336\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 875798.6875 - root_mean_squared_error: 933.1693\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 765101.3125 - root_mean_squared_error: 874.4008\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 720872.7500 - root_mean_squared_error: 848.1486\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 702648.0625 - root_mean_squared_error: 836.3271\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 734882.5625 - root_mean_squared_error: 856.6973\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 691813.5000 - root_mean_squared_error: 830.0060\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 718435.4375 - root_mean_squared_error: 846.2402\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 688585.8125 - root_mean_squared_error: 828.8397\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 687944.0625 - root_mean_squared_error: 827.0772\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 693020.6875 - root_mean_squared_error: 831.3209\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 673773.3750 - root_mean_squared_error: 819.0809\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 629008.2500 - root_mean_squared_error: 792.5939\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567910.6250 - root_mean_squared_error: 752.4972\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 552853.3125 - root_mean_squared_error: 742.4446\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554813.5000 - root_mean_squared_error: 744.4600\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595906.9375 - root_mean_squared_error: 771.3130\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526753.4375 - root_mean_squared_error: 723.6312\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 499783.6250 - root_mean_squared_error: 705.7631\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551882.2500 - root_mean_squared_error: 742.4249\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 559914.1875 - root_mean_squared_error: 746.7015\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 590438.3750 - root_mean_squared_error: 768.1750\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547656.6250 - root_mean_squared_error: 739.8024\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482544.7812 - root_mean_squared_error: 691.9075\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584016.0625 - root_mean_squared_error: 761.9524\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540454.1250 - root_mean_squared_error: 734.7358\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527762.3125 - root_mean_squared_error: 725.5089\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 598478.6250 - root_mean_squared_error: 771.7874\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583866.0625 - root_mean_squared_error: 759.7534\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511132.8438 - root_mean_squared_error: 714.6033\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 551758.8750 - root_mean_squared_error: 742.4388\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529739.9375 - root_mean_squared_error: 726.9564\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547150.1250 - root_mean_squared_error: 739.0076\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472102.2812 - root_mean_squared_error: 684.7410\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525077.5625 - root_mean_squared_error: 723.1479\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 532292.3125 - root_mean_squared_error: 728.0751\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547069.2500 - root_mean_squared_error: 739.2972\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 431558.4688 - root_mean_squared_error: 654.9243\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 562611.1250 - root_mean_squared_error: 746.5304\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 627070.6250 - root_mean_squared_error: 789.3112\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 469525.1250 - root_mean_squared_error: 684.6227\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603642.0625 - root_mean_squared_error: 774.4021\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567193.2500 - root_mean_squared_error: 751.1757\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 521496.3438 - root_mean_squared_error: 718.1744\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 479663.3125 - root_mean_squared_error: 691.7646\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 477372.1562 - root_mean_squared_error: 690.0115\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460251.0312 - root_mean_squared_error: 677.3435\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 538683.1875 - root_mean_squared_error: 731.0776\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 492998.3125 - root_mean_squared_error: 698.4695\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 575738.0625 - root_mean_squared_error: 756.9723\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524712.2500 - root_mean_squared_error: 721.0544\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 549946.0625 - root_mean_squared_error: 738.6258\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 582391.5625 - root_mean_squared_error: 761.6295\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 531693.7500 - root_mean_squared_error: 728.0512\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511015.0312 - root_mean_squared_error: 713.7939\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 554701.3125 - root_mean_squared_error: 742.7987\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583126.1250 - root_mean_squared_error: 762.4122\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 534752.5625 - root_mean_squared_error: 730.0143\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482257.1250 - root_mean_squared_error: 692.8173\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488651.1875 - root_mean_squared_error: 696.4194\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501089.2812 - root_mean_squared_error: 706.6265\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494757.6875 - root_mean_squared_error: 701.7522\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494167.5312 - root_mean_squared_error: 701.4622\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533331.8750 - root_mean_squared_error: 728.3605\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 467832.1250 - root_mean_squared_error: 681.4326\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514822.8438 - root_mean_squared_error: 715.9666\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498387.5938 - root_mean_squared_error: 704.1121\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 560345.4375 - root_mean_squared_error: 747.2365\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560928.6250 - root_mean_squared_error: 748.2742\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 577740.1250 - root_mean_squared_error: 757.6666\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 598918.6875 - root_mean_squared_error: 772.1332\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500726.2188 - root_mean_squared_error: 706.6995\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504532.8438 - root_mean_squared_error: 709.4680\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491886.0938 - root_mean_squared_error: 699.5376\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497350.8750 - root_mean_squared_error: 704.8037\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465795.4375 - root_mean_squared_error: 681.9556\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511134.3125 - root_mean_squared_error: 714.1849\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473618.7812 - root_mean_squared_error: 685.6624\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495810.5625 - root_mean_squared_error: 702.8006\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488412.8125 - root_mean_squared_error: 696.5878\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567251.0625 - root_mean_squared_error: 750.7711\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 428769.4688 - root_mean_squared_error: 650.7090\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 499668.2812 - root_mean_squared_error: 702.1117\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460841.6875 - root_mean_squared_error: 677.2076\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533838.1875 - root_mean_squared_error: 726.6994\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508956.4688 - root_mean_squared_error: 711.2266\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490435.7500 - root_mean_squared_error: 697.2433\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483376.2500 - root_mean_squared_error: 692.8468\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 560243.2500 - root_mean_squared_error: 747.6151\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 463950.2812 - root_mean_squared_error: 679.2161\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547088.0000 - root_mean_squared_error: 737.0552\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 485447.9688 - root_mean_squared_error: 695.6917\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516098.1250 - root_mean_squared_error: 716.5144\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500604.5312 - root_mean_squared_error: 706.9011\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 556171.6250 - root_mean_squared_error: 739.7963\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560086.6250 - root_mean_squared_error: 746.1799\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550975.2500 - root_mean_squared_error: 739.8419\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497104.0000 - root_mean_squared_error: 703.9465\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522336.6562 - root_mean_squared_error: 719.5742\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488854.7812 - root_mean_squared_error: 697.8149\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 487965.8750 - root_mean_squared_error: 697.6132\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508146.0938 - root_mean_squared_error: 707.4362\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 470534.7188 - root_mean_squared_error: 684.5106\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475161.1250 - root_mean_squared_error: 686.2195\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489583.4688 - root_mean_squared_error: 698.4970\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 581730.3125 - root_mean_squared_error: 762.2545\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540184.8750 - root_mean_squared_error: 734.0242\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567158.1875 - root_mean_squared_error: 750.6047\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 586183.5625 - root_mean_squared_error: 763.9357\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 608065.2500 - root_mean_squared_error: 775.3365\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524390.7500 - root_mean_squared_error: 722.0250\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 551155.3750 - root_mean_squared_error: 741.7541\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 447323.6250 - root_mean_squared_error: 666.8206\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 530814.8750 - root_mean_squared_error: 728.0469\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 649658.2500 - root_mean_squared_error: 801.8884\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549773.1250 - root_mean_squared_error: 739.4399\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516905.0312 - root_mean_squared_error: 717.4691\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500982.9062 - root_mean_squared_error: 707.5709\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 483132.3750 - root_mean_squared_error: 692.1476\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480249.7188 - root_mean_squared_error: 692.3776\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490611.6250 - root_mean_squared_error: 699.1212\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 548259.1875 - root_mean_squared_error: 738.0952\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 441689.4375 - root_mean_squared_error: 663.7828\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 461574.1875 - root_mean_squared_error: 678.5470\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584059.1875 - root_mean_squared_error: 762.1747\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 507875.5000 - root_mean_squared_error: 709.6360\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521148.9688 - root_mean_squared_error: 721.2482\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491449.0625 - root_mean_squared_error: 700.2517\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570152.6875 - root_mean_squared_error: 751.6326\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 484172.4062 - root_mean_squared_error: 694.5297\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 439512.9062 - root_mean_squared_error: 661.3368\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492098.8125 - root_mean_squared_error: 699.4242\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 488786.2188 - root_mean_squared_error: 698.6454\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496538.3438 - root_mean_squared_error: 702.3630\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 578117.0000 - root_mean_squared_error: 757.7828\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539624.8750 - root_mean_squared_error: 733.4214\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 565151.9375 - root_mean_squared_error: 749.9005\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 485893.6875 - root_mean_squared_error: 693.3656\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542428.5625 - root_mean_squared_error: 733.0662\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490781.3125 - root_mean_squared_error: 697.5154\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556486.0000 - root_mean_squared_error: 743.6789\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 510531.7188 - root_mean_squared_error: 713.9534\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 465453.7500 - root_mean_squared_error: 680.9618\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473700.6875 - root_mean_squared_error: 686.3559\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512839.2812 - root_mean_squared_error: 714.7327\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549688.7500 - root_mean_squared_error: 733.6082\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529137.1250 - root_mean_squared_error: 726.1957\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514237.7500 - root_mean_squared_error: 716.6870\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550310.6250 - root_mean_squared_error: 739.8940\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 557236.3750 - root_mean_squared_error: 746.1648\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 512728.9688 - root_mean_squared_error: 715.0855\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 580324.4375 - root_mean_squared_error: 758.8378\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489447.2188 - root_mean_squared_error: 698.0255\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509947.2500 - root_mean_squared_error: 713.2991\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498179.3750 - root_mean_squared_error: 704.4971\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 612596.7500 - root_mean_squared_error: 779.6922\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506737.4062 - root_mean_squared_error: 711.0776\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483075.8438 - root_mean_squared_error: 692.5709\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 599141.5000 - root_mean_squared_error: 770.6545\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616910.7500 - root_mean_squared_error: 782.3387\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 459966.4688 - root_mean_squared_error: 675.9947\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496817.4688 - root_mean_squared_error: 693.1564\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4270027.5000 - root_mean_squared_error: 2065.9395\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3964276.7500 - root_mean_squared_error: 1989.7352\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3755670.0000 - root_mean_squared_error: 1936.9230\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3607588.5000 - root_mean_squared_error: 1899.0509\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3670645.2500 - root_mean_squared_error: 1912.9647\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3321938.2500 - root_mean_squared_error: 1822.3401\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3042954.5000 - root_mean_squared_error: 1742.5797\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3092364.7500 - root_mean_squared_error: 1758.0670\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2870942.0000 - root_mean_squared_error: 1692.3719\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2711740.0000 - root_mean_squared_error: 1645.2655\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2688252.7500 - root_mean_squared_error: 1639.0118\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2689675.7500 - root_mean_squared_error: 1638.9208\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2485995.5000 - root_mean_squared_error: 1576.4402\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2182881.5000 - root_mean_squared_error: 1475.7183\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2457173.2500 - root_mean_squared_error: 1565.4797\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2233344.5000 - root_mean_squared_error: 1493.0917\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2046215.8750 - root_mean_squared_error: 1429.3979\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1988608.6250 - root_mean_squared_error: 1409.5609\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1784226.7500 - root_mean_squared_error: 1333.0931\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1864003.6250 - root_mean_squared_error: 1362.9982\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1663072.1250 - root_mean_squared_error: 1288.8479\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1761952.6250 - root_mean_squared_error: 1325.6732\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1528411.2500 - root_mean_squared_error: 1235.7928\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1459179.7500 - root_mean_squared_error: 1207.8026\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1406006.7500 - root_mean_squared_error: 1184.9210\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1273450.6250 - root_mean_squared_error: 1127.6665\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1432182.5000 - root_mean_squared_error: 1192.7271\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1253889.2500 - root_mean_squared_error: 1118.2441\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1187357.7500 - root_mean_squared_error: 1088.6201\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1242691.5000 - root_mean_squared_error: 1113.8807\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1121242.2500 - root_mean_squared_error: 1057.4995\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1089571.1250 - root_mean_squared_error: 1043.4412\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1034556.2500 - root_mean_squared_error: 1016.6552\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1076742.1250 - root_mean_squared_error: 1037.1006\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 983495.5625 - root_mean_squared_error: 990.8893\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 908241.6875 - root_mean_squared_error: 951.4930\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 772214.1250 - root_mean_squared_error: 876.6448\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 892604.1875 - root_mean_squared_error: 943.1932\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 840256.1875 - root_mean_squared_error: 915.8517\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 990100.3125 - root_mean_squared_error: 985.8230 \n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 853104.0000 - root_mean_squared_error: 922.5559\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 732956.3125 - root_mean_squared_error: 853.9462\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 816944.1875 - root_mean_squared_error: 901.1752\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 642953.8125 - root_mean_squared_error: 798.8490\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 720450.1250 - root_mean_squared_error: 848.2350\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 752992.0000 - root_mean_squared_error: 865.7542\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 747178.1875 - root_mean_squared_error: 860.9011\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 651444.8125 - root_mean_squared_error: 805.7566\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 647684.4375 - root_mean_squared_error: 804.3137\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 660609.5000 - root_mean_squared_error: 811.9603\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 599963.1250 - root_mean_squared_error: 772.9067\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 636956.7500 - root_mean_squared_error: 797.2823\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 567797.5625 - root_mean_squared_error: 752.0009\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547088.5625 - root_mean_squared_error: 738.5293\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 620312.0625 - root_mean_squared_error: 786.8724\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570977.9375 - root_mean_squared_error: 755.0309\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565733.6250 - root_mean_squared_error: 749.5830\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553070.2500 - root_mean_squared_error: 742.5128\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551689.3750 - root_mean_squared_error: 740.9210\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 698321.2500 - root_mean_squared_error: 827.9212\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 489883.0625 - root_mean_squared_error: 697.5692\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521127.0625 - root_mean_squared_error: 721.6223\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 609121.8125 - root_mean_squared_error: 777.3719\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524325.6875 - root_mean_squared_error: 723.1169\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 622291.1250 - root_mean_squared_error: 782.1598\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 695903.9375 - root_mean_squared_error: 824.9107\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 530474.6250 - root_mean_squared_error: 728.0302\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 548241.8125 - root_mean_squared_error: 739.9426\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 639181.2500 - root_mean_squared_error: 797.0905\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 448330.8438 - root_mean_squared_error: 667.0909\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589162.3750 - root_mean_squared_error: 758.9967\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515784.9375 - root_mean_squared_error: 717.3684\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543522.0625 - root_mean_squared_error: 734.5699\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 517067.3438 - root_mean_squared_error: 718.6797\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554508.0625 - root_mean_squared_error: 743.2539\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508932.0000 - root_mean_squared_error: 712.3178\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474976.2500 - root_mean_squared_error: 687.2893\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472383.3438 - root_mean_squared_error: 684.6812\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479760.8125 - root_mean_squared_error: 692.1911\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 444852.5625 - root_mean_squared_error: 664.7858\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 586813.0000 - root_mean_squared_error: 764.7419\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 577231.3125 - root_mean_squared_error: 758.3189\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 439903.2812 - root_mean_squared_error: 660.9286\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509494.7812 - root_mean_squared_error: 713.0608\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494180.4688 - root_mean_squared_error: 701.8945\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491859.5000 - root_mean_squared_error: 700.1438\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 462798.2812 - root_mean_squared_error: 678.4950\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 546776.1250 - root_mean_squared_error: 738.5333\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 533772.3125 - root_mean_squared_error: 728.4539\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 525412.6875 - root_mean_squared_error: 724.4484\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 487736.0938 - root_mean_squared_error: 698.2532\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 488303.6562 - root_mean_squared_error: 697.4227\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511143.1562 - root_mean_squared_error: 714.2616\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584690.2500 - root_mean_squared_error: 763.3422\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486295.0625 - root_mean_squared_error: 696.2031\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524935.5625 - root_mean_squared_error: 723.5736\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507332.4062 - root_mean_squared_error: 710.7572\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 467817.9688 - root_mean_squared_error: 681.5663\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522221.1875 - root_mean_squared_error: 720.2599\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 474562.0000 - root_mean_squared_error: 685.6188\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561970.9375 - root_mean_squared_error: 748.8333\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 476034.4062 - root_mean_squared_error: 689.2078\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 461678.8750 - root_mean_squared_error: 677.7674\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 481169.2500 - root_mean_squared_error: 691.1909\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500466.1562 - root_mean_squared_error: 706.3101\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480261.3438 - root_mean_squared_error: 690.8795\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 479712.5938 - root_mean_squared_error: 692.0048\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553752.5000 - root_mean_squared_error: 742.9829\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504899.9375 - root_mean_squared_error: 709.1606\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 488259.5938 - root_mean_squared_error: 694.5612\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 449955.5312 - root_mean_squared_error: 669.4659\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 444896.3438 - root_mean_squared_error: 661.8918\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 418558.5312 - root_mean_squared_error: 643.0195\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498159.1875 - root_mean_squared_error: 704.9576\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 610657.2500 - root_mean_squared_error: 780.0668\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538831.5625 - root_mean_squared_error: 733.5306\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584532.5625 - root_mean_squared_error: 762.4711\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 530975.2500 - root_mean_squared_error: 728.3048\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490169.0938 - root_mean_squared_error: 697.8162\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 467956.1250 - root_mean_squared_error: 683.5963\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532962.8750 - root_mean_squared_error: 728.9041\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 523900.4688 - root_mean_squared_error: 720.5438\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482295.2188 - root_mean_squared_error: 689.9495\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 499295.9688 - root_mean_squared_error: 703.7351\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 536119.1250 - root_mean_squared_error: 731.1481\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527124.3125 - root_mean_squared_error: 722.1973\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501332.4688 - root_mean_squared_error: 704.5242\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458292.0938 - root_mean_squared_error: 675.4659\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 462217.3125 - root_mean_squared_error: 674.9467\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 526862.5625 - root_mean_squared_error: 723.9200\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 520946.7500 - root_mean_squared_error: 718.4894\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577553.6250 - root_mean_squared_error: 758.7745\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491499.0625 - root_mean_squared_error: 697.6347\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519828.0938 - root_mean_squared_error: 719.3524\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509871.4688 - root_mean_squared_error: 713.1487\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 551490.8125 - root_mean_squared_error: 741.7292\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543760.2500 - root_mean_squared_error: 737.1360\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544425.6250 - root_mean_squared_error: 734.6141\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511380.2500 - root_mean_squared_error: 713.0309\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486896.2812 - root_mean_squared_error: 697.4175\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515606.3438 - root_mean_squared_error: 717.6815\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 436697.5938 - root_mean_squared_error: 656.8271\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543663.1875 - root_mean_squared_error: 736.1254\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 458696.3125 - root_mean_squared_error: 676.4362\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 422535.0625 - root_mean_squared_error: 648.4337\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 469982.3438 - root_mean_squared_error: 684.5865\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 601510.5625 - root_mean_squared_error: 772.7065\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 520822.5000 - root_mean_squared_error: 720.3673\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 510101.8125 - root_mean_squared_error: 713.2118\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 437877.3750 - root_mean_squared_error: 659.5860\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 492325.3125 - root_mean_squared_error: 699.5920\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 450772.3750 - root_mean_squared_error: 668.0875\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 518691.7812 - root_mean_squared_error: 719.0899\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514940.8125 - root_mean_squared_error: 716.6789\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 507877.4688 - root_mean_squared_error: 712.1690\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539114.3750 - root_mean_squared_error: 732.8655\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 493826.1875 - root_mean_squared_error: 702.0310\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 493982.9062 - root_mean_squared_error: 701.2119\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 507796.2188 - root_mean_squared_error: 712.4197\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523795.5312 - root_mean_squared_error: 723.3038\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513848.2812 - root_mean_squared_error: 715.9908\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 491994.5312 - root_mean_squared_error: 700.3906\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504816.2500 - root_mean_squared_error: 709.4852\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483804.7812 - root_mean_squared_error: 693.0978\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 554602.4375 - root_mean_squared_error: 741.3864\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 505173.8438 - root_mean_squared_error: 709.0356\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 546175.8125 - root_mean_squared_error: 737.9307\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526720.8125 - root_mean_squared_error: 724.0833\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 532269.8750 - root_mean_squared_error: 728.7453\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 453128.9062 - root_mean_squared_error: 670.1700\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528904.0000 - root_mean_squared_error: 724.1872\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 463812.1562 - root_mean_squared_error: 678.9996\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476364.5938 - root_mean_squared_error: 688.0757\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472606.7812 - root_mean_squared_error: 686.9060\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482159.9688 - root_mean_squared_error: 692.7863\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 443106.2188 - root_mean_squared_error: 663.5301\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 499107.5625 - root_mean_squared_error: 704.3404\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 466867.3750 - root_mean_squared_error: 682.7706\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521595.7188 - root_mean_squared_error: 721.3125\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 594204.1250 - root_mean_squared_error: 768.3291\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460558.9688 - root_mean_squared_error: 677.7318\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 537739.7500 - root_mean_squared_error: 732.4072\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 492160.9688 - root_mean_squared_error: 700.9483\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506714.3750 - root_mean_squared_error: 711.2698\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 451031.4375 - root_mean_squared_error: 670.0480\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549685.3125 - root_mean_squared_error: 740.4370\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 438235.3750 - root_mean_squared_error: 659.5414\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 530629.1875 - root_mean_squared_error: 727.2308\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 467319.3125 - root_mean_squared_error: 682.0739\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 618163.5000 - root_mean_squared_error: 783.0496\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 620395.8750 - root_mean_squared_error: 777.9591\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476951.3438 - root_mean_squared_error: 689.0883\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 421056.8125 - root_mean_squared_error: 645.2750\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 532161.2500 - root_mean_squared_error: 727.5848\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 524191.1250 - root_mean_squared_error: 721.6616\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 488871.0625 - root_mean_squared_error: 698.5486\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561655.0625 - root_mean_squared_error: 748.3652\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499499.2188 - root_mean_squared_error: 706.4254\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 471176.1875 - root_mean_squared_error: 686.0173\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 469615.4375 - root_mean_squared_error: 683.6697\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 469989.6562 - root_mean_squared_error: 683.2670\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 529311.9375 - root_mean_squared_error: 714.4870\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3985201.0000 - root_mean_squared_error: 1994.6847\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3991949.7500 - root_mean_squared_error: 1995.3146\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3704152.5000 - root_mean_squared_error: 1922.5323\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3446070.5000 - root_mean_squared_error: 1855.8480\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3439025.2500 - root_mean_squared_error: 1853.2761\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3106433.5000 - root_mean_squared_error: 1758.9563\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3240069.2500 - root_mean_squared_error: 1798.7227\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3160634.2500 - root_mean_squared_error: 1777.6761\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2811027.5000 - root_mean_squared_error: 1673.4073\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2715016.5000 - root_mean_squared_error: 1647.3950\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2528645.2500 - root_mean_squared_error: 1588.6719\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2350880.0000 - root_mean_squared_error: 1532.3765\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2511883.5000 - root_mean_squared_error: 1584.3579\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2267401.7500 - root_mean_squared_error: 1503.9835\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2114142.7500 - root_mean_squared_error: 1453.7516\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2229386.0000 - root_mean_squared_error: 1492.6031\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2084734.0000 - root_mean_squared_error: 1443.4000\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1999378.6250 - root_mean_squared_error: 1413.1584\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1669379.3750 - root_mean_squared_error: 1291.2826\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1743558.8750 - root_mean_squared_error: 1319.5447\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1694126.5000 - root_mean_squared_error: 1300.5624\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1720303.0000 - root_mean_squared_error: 1310.4673\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1607318.0000 - root_mean_squared_error: 1265.9231\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1613525.3750 - root_mean_squared_error: 1269.6940\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1373895.3750 - root_mean_squared_error: 1171.0380\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1479252.1250 - root_mean_squared_error: 1215.1118\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1331127.3750 - root_mean_squared_error: 1153.3542\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1427852.1250 - root_mean_squared_error: 1193.6057\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1229331.7500 - root_mean_squared_error: 1107.8324\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1238109.7500 - root_mean_squared_error: 1111.9235\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1111515.1250 - root_mean_squared_error: 1052.9977\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1016973.3125 - root_mean_squared_error: 1007.1125\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1234533.8750 - root_mean_squared_error: 1107.4946\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1075830.1250 - root_mean_squared_error: 1036.4833\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1047576.3125 - root_mean_squared_error: 1021.9401\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 941127.1875 - root_mean_squared_error: 969.7151\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 955011.1250 - root_mean_squared_error: 976.1428\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 916529.6250 - root_mean_squared_error: 956.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 876136.0000 - root_mean_squared_error: 935.3775\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 842028.3125 - root_mean_squared_error: 916.3025\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 789872.3125 - root_mean_squared_error: 888.4675\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 708549.1875 - root_mean_squared_error: 840.2640\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 700167.1250 - root_mean_squared_error: 835.6951\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 792581.3125 - root_mean_squared_error: 889.9182\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 787386.6875 - root_mean_squared_error: 885.6819\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 662130.0625 - root_mean_squared_error: 812.6727\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 712093.7500 - root_mean_squared_error: 841.3760\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 717353.4375 - root_mean_squared_error: 845.8502\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595985.1250 - root_mean_squared_error: 770.3634\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 662818.1250 - root_mean_squared_error: 812.8245\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 668270.7500 - root_mean_squared_error: 814.7493\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 638870.6250 - root_mean_squared_error: 798.3931\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 651491.7500 - root_mean_squared_error: 806.4586\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 625021.4375 - root_mean_squared_error: 788.2606\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549718.1250 - root_mean_squared_error: 740.5579\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606915.6250 - root_mean_squared_error: 777.5961\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 631081.6875 - root_mean_squared_error: 793.6097\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573376.3750 - root_mean_squared_error: 756.8199\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 554631.1250 - root_mean_squared_error: 744.2412\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 549524.5000 - root_mean_squared_error: 738.3143\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 576987.0625 - root_mean_squared_error: 758.2048\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527126.5625 - root_mean_squared_error: 724.1946\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539760.4375 - root_mean_squared_error: 733.8896\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494067.2500 - root_mean_squared_error: 701.4491\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 523338.4062 - root_mean_squared_error: 722.0016\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482068.4062 - root_mean_squared_error: 690.6052\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574906.4375 - root_mean_squared_error: 757.6659\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 493113.7500 - root_mean_squared_error: 701.5745\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 611368.3125 - root_mean_squared_error: 781.3346\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 542883.6250 - root_mean_squared_error: 733.6732\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 573033.0000 - root_mean_squared_error: 754.7909\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527347.1875 - root_mean_squared_error: 722.8115\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518643.9688 - root_mean_squared_error: 718.4912\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508431.7188 - root_mean_squared_error: 712.0992\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 544669.0625 - root_mean_squared_error: 736.6594\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556838.4375 - root_mean_squared_error: 745.4557\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569515.6250 - root_mean_squared_error: 752.5925\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 576286.4375 - root_mean_squared_error: 757.5252\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 537057.1875 - root_mean_squared_error: 730.7531\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 492210.1875 - root_mean_squared_error: 700.4850\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 545982.3125 - root_mean_squared_error: 738.2139\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 529768.6875 - root_mean_squared_error: 725.9771\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 461137.5312 - root_mean_squared_error: 671.0401\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 581902.5000 - root_mean_squared_error: 759.3808\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527762.2500 - root_mean_squared_error: 725.6508\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476148.0625 - root_mean_squared_error: 686.6639\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 456166.4688 - root_mean_squared_error: 673.6220\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 487345.5938 - root_mean_squared_error: 695.8973\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 507321.0000 - root_mean_squared_error: 711.3122\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529143.5000 - root_mean_squared_error: 725.4739\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 534821.5625 - root_mean_squared_error: 730.5464\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 536738.3125 - root_mean_squared_error: 731.7006\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563085.8750 - root_mean_squared_error: 749.4310\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 463827.3750 - root_mean_squared_error: 679.7733\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475307.6875 - root_mean_squared_error: 689.0132\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 499343.3750 - root_mean_squared_error: 704.5192\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 518853.4688 - root_mean_squared_error: 719.8037\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 457370.4375 - root_mean_squared_error: 673.9028\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509129.7812 - root_mean_squared_error: 712.5901\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 484703.4375 - root_mean_squared_error: 695.3897\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 415291.5938 - root_mean_squared_error: 641.5035\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595920.9375 - root_mean_squared_error: 769.1960\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 505854.8125 - root_mean_squared_error: 709.7104\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 501869.5312 - root_mean_squared_error: 706.8030\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503759.9375 - root_mean_squared_error: 708.4875\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482267.1875 - root_mean_squared_error: 691.9370\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 618261.8125 - root_mean_squared_error: 780.6673\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 505483.5312 - root_mean_squared_error: 709.3928\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 448120.7812 - root_mean_squared_error: 667.5012\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 497798.0938 - root_mean_squared_error: 704.4423\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508319.4375 - root_mean_squared_error: 712.5781\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528915.4375 - root_mean_squared_error: 726.8433\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563236.9375 - root_mean_squared_error: 747.3395\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 571327.2500 - root_mean_squared_error: 754.7603\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 536387.8125 - root_mean_squared_error: 731.4562\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 439547.0000 - root_mean_squared_error: 657.1653\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 630431.9375 - root_mean_squared_error: 779.8334\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 441073.9688 - root_mean_squared_error: 660.9888\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507791.6250 - root_mean_squared_error: 712.0610\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490929.2188 - root_mean_squared_error: 700.3474\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 662243.1875 - root_mean_squared_error: 810.9426\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574262.9375 - root_mean_squared_error: 756.2207\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 495339.8125 - root_mean_squared_error: 703.5779\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460078.9688 - root_mean_squared_error: 675.7223\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 482669.5938 - root_mean_squared_error: 693.6725\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491178.5625 - root_mean_squared_error: 700.1890\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 566057.2500 - root_mean_squared_error: 749.6077\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 449872.4688 - root_mean_squared_error: 666.4305\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 548206.8750 - root_mean_squared_error: 737.6790\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511950.0312 - root_mean_squared_error: 713.9863\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516081.4062 - root_mean_squared_error: 714.0983\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491718.6250 - root_mean_squared_error: 700.6979\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 513985.9688 - root_mean_squared_error: 716.1270\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550993.6875 - root_mean_squared_error: 741.6137\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 514539.5938 - root_mean_squared_error: 715.9092\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533311.9375 - root_mean_squared_error: 728.7457\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 462656.6250 - root_mean_squared_error: 678.8461\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 477505.5625 - root_mean_squared_error: 689.1135\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 547670.5000 - root_mean_squared_error: 738.6353\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 444549.2812 - root_mean_squared_error: 662.3608\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523389.3750 - root_mean_squared_error: 720.1654\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585270.5625 - root_mean_squared_error: 764.1636\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 455609.2188 - root_mean_squared_error: 673.5524\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464834.9062 - root_mean_squared_error: 680.8472\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 620155.5625 - root_mean_squared_error: 781.8099\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506831.4062 - root_mean_squared_error: 709.6700\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486514.1875 - root_mean_squared_error: 696.8723\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 557118.7500 - root_mean_squared_error: 745.9437\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570430.6250 - root_mean_squared_error: 753.8678\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617225.2500 - root_mean_squared_error: 783.1052\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 534968.5000 - root_mean_squared_error: 726.3990\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 563857.9375 - root_mean_squared_error: 750.4994\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550839.4375 - root_mean_squared_error: 738.5758\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517092.8750 - root_mean_squared_error: 717.4553\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 503331.5625 - root_mean_squared_error: 708.7004\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514424.5938 - root_mean_squared_error: 715.1213\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561947.1875 - root_mean_squared_error: 746.6229\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 593501.4375 - root_mean_squared_error: 769.8351\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 638386.8125 - root_mean_squared_error: 796.6424\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 513687.9375 - root_mean_squared_error: 716.1711\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490483.6250 - root_mean_squared_error: 698.6171\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 531338.6250 - root_mean_squared_error: 728.2972\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508797.8438 - root_mean_squared_error: 712.2852\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553334.3750 - root_mean_squared_error: 743.2570\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617069.5625 - root_mean_squared_error: 782.8793\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551806.8750 - root_mean_squared_error: 742.2159\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561226.6250 - root_mean_squared_error: 746.2421\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524703.0000 - root_mean_squared_error: 723.5156\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514094.2812 - root_mean_squared_error: 715.5311\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 512649.3750 - root_mean_squared_error: 714.0511\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583815.6250 - root_mean_squared_error: 762.5894\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 538629.8125 - root_mean_squared_error: 727.6656\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585326.4375 - root_mean_squared_error: 764.0569\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 535894.4375 - root_mean_squared_error: 728.8128\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 542187.8750 - root_mean_squared_error: 733.3754\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515972.0312 - root_mean_squared_error: 718.1277\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509881.3438 - root_mean_squared_error: 711.2676\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508662.6875 - root_mean_squared_error: 712.2883\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 518741.6250 - root_mean_squared_error: 718.8323\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 570976.3750 - root_mean_squared_error: 754.6210\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 443767.0312 - root_mean_squared_error: 662.5222\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540720.6875 - root_mean_squared_error: 731.7659\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 515553.4062 - root_mean_squared_error: 716.7017\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518894.7500 - root_mean_squared_error: 717.7332\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498357.7812 - root_mean_squared_error: 705.2871\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 565868.3125 - root_mean_squared_error: 749.7803\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527746.6250 - root_mean_squared_error: 724.6033\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 477732.5625 - root_mean_squared_error: 688.1888\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533460.9375 - root_mean_squared_error: 729.5638\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 598276.4375 - root_mean_squared_error: 769.8115\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475614.8438 - root_mean_squared_error: 688.2856\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498358.6250 - root_mean_squared_error: 703.7098\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 550928.5625 - root_mean_squared_error: 741.3318\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553588.5000 - root_mean_squared_error: 743.1658\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494177.9688 - root_mean_squared_error: 701.7178\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 460765.4375 - root_mean_squared_error: 674.8213\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 575238.2500 - root_mean_squared_error: 757.6991\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 464080.7812 - root_mean_squared_error: 680.4393\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511434.2188 - root_mean_squared_error: 712.8804\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 488012.9062 - root_mean_squared_error: 696.5082\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 487550.3750 - root_mean_squared_error: 695.6925\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 513357.1250 - root_mean_squared_error: 702.9766\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4293838.0000 - root_mean_squared_error: 2071.1707\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4094809.0000 - root_mean_squared_error: 2021.9941\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3777304.7500 - root_mean_squared_error: 1943.2567\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3821834.2500 - root_mean_squared_error: 1954.0571\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3294615.2500 - root_mean_squared_error: 1813.2483\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3310813.2500 - root_mean_squared_error: 1819.2638\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3130067.7500 - root_mean_squared_error: 1767.1764\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3111357.2500 - root_mean_squared_error: 1763.6614\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3077836.0000 - root_mean_squared_error: 1752.9752\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2860174.7500 - root_mean_squared_error: 1690.6838\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2829631.5000 - root_mean_squared_error: 1681.1801\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2515579.7500 - root_mean_squared_error: 1584.1512\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2502714.0000 - root_mean_squared_error: 1578.9812\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2475663.7500 - root_mean_squared_error: 1571.9144\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2481207.0000 - root_mean_squared_error: 1573.8607\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2286929.5000 - root_mean_squared_error: 1511.9673\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2066414.1250 - root_mean_squared_error: 1436.6063\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2047701.5000 - root_mean_squared_error: 1430.2786\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1960650.7500 - root_mean_squared_error: 1399.7252\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1918169.8750 - root_mean_squared_error: 1383.7625\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1945303.8750 - root_mean_squared_error: 1393.5262\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1683220.1250 - root_mean_squared_error: 1297.0192\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1644063.1250 - root_mean_squared_error: 1281.6873\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1456736.7500 - root_mean_squared_error: 1205.7731\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1486513.7500 - root_mean_squared_error: 1217.7885\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1430292.5000 - root_mean_squared_error: 1195.6838\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1244821.7500 - root_mean_squared_error: 1114.9077\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1275292.1250 - root_mean_squared_error: 1128.9232\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1134265.6250 - root_mean_squared_error: 1063.5609\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1173418.1250 - root_mean_squared_error: 1081.9913\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1216328.3750 - root_mean_squared_error: 1102.2590\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1042513.6875 - root_mean_squared_error: 1019.2518\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1010599.7500 - root_mean_squared_error: 1003.9808\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 894837.5625 - root_mean_squared_error: 943.9733\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 992538.5625 - root_mean_squared_error: 996.0949\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 913676.2500 - root_mean_squared_error: 954.3882\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 880711.6250 - root_mean_squared_error: 937.7395\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 869139.8125 - root_mean_squared_error: 931.6581\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 782569.4375 - root_mean_squared_error: 880.6067\n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 882911.7500 - root_mean_squared_error: 938.3336\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 815477.8125 - root_mean_squared_error: 901.2037\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 731775.8125 - root_mean_squared_error: 854.9244\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 757913.1875 - root_mean_squared_error: 870.0546\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 690910.5625 - root_mean_squared_error: 830.3344\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 721808.8125 - root_mean_squared_error: 847.6104\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 856558.8125 - root_mean_squared_error: 918.0618\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 661547.5000 - root_mean_squared_error: 812.6791\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 623846.8750 - root_mean_squared_error: 788.9894\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 655888.0625 - root_mean_squared_error: 808.9497\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595526.1875 - root_mean_squared_error: 770.3706\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 591687.2500 - root_mean_squared_error: 768.6367\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 662532.2500 - root_mean_squared_error: 812.6786\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 656745.3750 - root_mean_squared_error: 808.9591\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 660833.3125 - root_mean_squared_error: 812.0925\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 701491.1250 - root_mean_squared_error: 832.0175\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579117.1875 - root_mean_squared_error: 760.8224\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 537624.1250 - root_mean_squared_error: 731.7394\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538554.0625 - root_mean_squared_error: 732.1850\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526605.0000 - root_mean_squared_error: 723.8456\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490552.8125 - root_mean_squared_error: 697.0755\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603025.7500 - root_mean_squared_error: 775.8795\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 534079.8125 - root_mean_squared_error: 730.3613\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 573075.0625 - root_mean_squared_error: 753.6846\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526133.0000 - root_mean_squared_error: 721.4289\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 611725.5625 - root_mean_squared_error: 780.2192\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 630020.6250 - root_mean_squared_error: 788.3207\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515257.0938 - root_mean_squared_error: 717.2022\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 607263.7500 - root_mean_squared_error: 776.5796\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 451418.1562 - root_mean_squared_error: 669.4650\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 659775.0000 - root_mean_squared_error: 808.8904\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 577932.3125 - root_mean_squared_error: 758.4116\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543176.1250 - root_mean_squared_error: 736.1321\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472340.4062 - root_mean_squared_error: 686.0164\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 543830.0625 - root_mean_squared_error: 735.4159\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533822.3750 - root_mean_squared_error: 730.0751\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 497426.5625 - root_mean_squared_error: 702.9028\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 543521.4375 - root_mean_squared_error: 733.6124\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 443536.7188 - root_mean_squared_error: 664.0067\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 519351.2500 - root_mean_squared_error: 719.8760\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 525857.4375 - root_mean_squared_error: 722.3959\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549808.8750 - root_mean_squared_error: 738.6612\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 504299.0625 - root_mean_squared_error: 709.7683\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 452946.4062 - root_mean_squared_error: 670.6593\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 556387.4375 - root_mean_squared_error: 744.9287\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 474973.2812 - root_mean_squared_error: 688.2203\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496106.8750 - root_mean_squared_error: 702.7249\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 632614.3750 - root_mean_squared_error: 790.1132\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 629788.8125 - root_mean_squared_error: 793.0266\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 699012.6875 - root_mean_squared_error: 834.1301\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544873.2500 - root_mean_squared_error: 736.7917\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 555985.8750 - root_mean_squared_error: 743.0560\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519957.3750 - root_mean_squared_error: 718.7314\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517701.9062 - root_mean_squared_error: 718.4637\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 479069.5625 - root_mean_squared_error: 690.5531\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 515566.4375 - root_mean_squared_error: 717.0047\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 539528.1875 - root_mean_squared_error: 733.5900\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561629.3125 - root_mean_squared_error: 748.5071\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 592860.5000 - root_mean_squared_error: 768.2314\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531988.9375 - root_mean_squared_error: 728.9013\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519485.6875 - root_mean_squared_error: 719.8195\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570747.4375 - root_mean_squared_error: 751.3018\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 595549.0625 - root_mean_squared_error: 770.0760\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 509852.0000 - root_mean_squared_error: 711.1036\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 605920.8125 - root_mean_squared_error: 775.2413\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 546716.3125 - root_mean_squared_error: 738.7909\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522039.8750 - root_mean_squared_error: 718.2783\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 521241.8750 - root_mean_squared_error: 721.8070\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539798.0625 - root_mean_squared_error: 733.8899\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 523383.2500 - root_mean_squared_error: 722.0897\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473877.8438 - root_mean_squared_error: 687.2663\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527352.5000 - root_mean_squared_error: 725.2343\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540829.3125 - root_mean_squared_error: 732.8090\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509753.5000 - root_mean_squared_error: 711.9262\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565563.6250 - root_mean_squared_error: 748.6970\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540405.7500 - root_mean_squared_error: 733.4603\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 596204.3125 - root_mean_squared_error: 770.7600\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501058.8125 - root_mean_squared_error: 705.3481\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 538071.0625 - root_mean_squared_error: 732.2212\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518939.8750 - root_mean_squared_error: 719.7884\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473183.5938 - root_mean_squared_error: 686.7983\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491657.5625 - root_mean_squared_error: 700.2643\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 496142.1562 - root_mean_squared_error: 702.7916\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 508727.7812 - root_mean_squared_error: 712.0237\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514106.7500 - root_mean_squared_error: 715.2415\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565963.0000 - root_mean_squared_error: 750.6832\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475237.4688 - root_mean_squared_error: 688.0976\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475057.9688 - root_mean_squared_error: 688.3778\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 445329.5000 - root_mean_squared_error: 665.4105\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 511235.9375 - root_mean_squared_error: 712.3784\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567673.4375 - root_mean_squared_error: 750.0431\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522366.2812 - root_mean_squared_error: 714.9597\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516931.1875 - root_mean_squared_error: 717.3110\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 588550.0625 - root_mean_squared_error: 764.3796\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504642.8750 - root_mean_squared_error: 708.9888\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 515636.7188 - root_mean_squared_error: 717.3786\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 528814.3750 - root_mean_squared_error: 726.2560\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 483098.7500 - root_mean_squared_error: 693.8563\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 445607.2188 - root_mean_squared_error: 666.2755\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472163.0938 - root_mean_squared_error: 685.5391\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 582173.1250 - root_mean_squared_error: 760.0059\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 522525.1562 - root_mean_squared_error: 722.2368\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 464530.7812 - root_mean_squared_error: 679.8904\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 499772.7812 - root_mean_squared_error: 706.4760\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 472235.8750 - root_mean_squared_error: 686.2734\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 463684.8125 - root_mean_squared_error: 678.7941\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 480099.2500 - root_mean_squared_error: 690.2010\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 575045.5000 - root_mean_squared_error: 755.9573\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514925.7812 - root_mean_squared_error: 714.5759\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490919.5000 - root_mean_squared_error: 699.7454\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511972.4062 - root_mean_squared_error: 714.9150\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 488950.2812 - root_mean_squared_error: 698.3302\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 449079.5938 - root_mean_squared_error: 669.4324\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498022.5625 - root_mean_squared_error: 705.3889\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501907.0625 - root_mean_squared_error: 705.8761\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 451284.9375 - root_mean_squared_error: 668.7537\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 557554.7500 - root_mean_squared_error: 744.9677\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514323.5625 - root_mean_squared_error: 714.3398\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 528772.6875 - root_mean_squared_error: 724.6472\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 479808.6562 - root_mean_squared_error: 691.0732\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 395299.0625 - root_mean_squared_error: 623.9768\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 568165.2500 - root_mean_squared_error: 750.3317\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 469852.3125 - root_mean_squared_error: 683.8605\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 526458.6250 - root_mean_squared_error: 724.8738\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 557468.7500 - root_mean_squared_error: 745.5894\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 474732.8750 - root_mean_squared_error: 688.4971\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506730.4062 - root_mean_squared_error: 710.3348\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503404.3125 - root_mean_squared_error: 708.8315\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 519267.0000 - root_mean_squared_error: 718.6283\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 540340.6875 - root_mean_squared_error: 732.1473\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517096.5312 - root_mean_squared_error: 717.8254\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 584474.5625 - root_mean_squared_error: 759.9469\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 554324.7500 - root_mean_squared_error: 743.9777\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 509480.6875 - root_mean_squared_error: 712.3511\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547365.1250 - root_mean_squared_error: 738.0214\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 498349.8438 - root_mean_squared_error: 704.4410\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 474035.8125 - root_mean_squared_error: 687.7424\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 470843.7188 - root_mean_squared_error: 683.5027\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542970.0625 - root_mean_squared_error: 736.4795\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 471962.5312 - root_mean_squared_error: 686.0248\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531832.5000 - root_mean_squared_error: 728.5588\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 560820.0000 - root_mean_squared_error: 747.8308\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 495122.4375 - root_mean_squared_error: 702.4759\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506265.7188 - root_mean_squared_error: 709.9573\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553442.6250 - root_mean_squared_error: 742.0666\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 531740.3750 - root_mean_squared_error: 728.8652\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 447899.9688 - root_mean_squared_error: 666.9252\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 464402.8438 - root_mean_squared_error: 677.2257\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 441168.1875 - root_mean_squared_error: 662.1328\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 483706.0625 - root_mean_squared_error: 694.2254\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 583204.9375 - root_mean_squared_error: 759.8638\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 561017.2500 - root_mean_squared_error: 747.3491\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 539029.9375 - root_mean_squared_error: 732.8959\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 565095.4375 - root_mean_squared_error: 748.5935\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533554.5000 - root_mean_squared_error: 726.7973\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 443457.0625 - root_mean_squared_error: 662.5372\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 460450.2812 - root_mean_squared_error: 674.7119\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 583772.8125 - root_mean_squared_error: 762.0784\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574751.6875 - root_mean_squared_error: 753.6426\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 596376.3750 - root_mean_squared_error: 766.4495\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 491621.1875 - root_mean_squared_error: 700.5211\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 460549.2500 - root_mean_squared_error: 676.6487\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 519220.9375 - root_mean_squared_error: 709.4487\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4184844.2500 - root_mean_squared_error: 2045.2166\n",
      "Epoch 2/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4306644.0000 - root_mean_squared_error: 2072.9529\n",
      "Epoch 3/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3902599.0000 - root_mean_squared_error: 1974.9792\n",
      "Epoch 4/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3659545.2500 - root_mean_squared_error: 1911.9230\n",
      "Epoch 5/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3511822.5000 - root_mean_squared_error: 1873.6160\n",
      "Epoch 6/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3286511.0000 - root_mean_squared_error: 1812.4835\n",
      "Epoch 7/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3289972.0000 - root_mean_squared_error: 1813.2042\n",
      "Epoch 8/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2917554.0000 - root_mean_squared_error: 1707.3124\n",
      "Epoch 9/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2800764.0000 - root_mean_squared_error: 1668.7007\n",
      "Epoch 10/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2783614.0000 - root_mean_squared_error: 1667.9365\n",
      "Epoch 11/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2742189.7500 - root_mean_squared_error: 1655.4587\n",
      "Epoch 12/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2491984.2500 - root_mean_squared_error: 1577.5323\n",
      "Epoch 13/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2354697.5000 - root_mean_squared_error: 1534.3495\n",
      "Epoch 14/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2342030.7500 - root_mean_squared_error: 1529.4403\n",
      "Epoch 15/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2182280.2500 - root_mean_squared_error: 1474.5302\n",
      "Epoch 16/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2052283.5000 - root_mean_squared_error: 1429.7828\n",
      "Epoch 17/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2030316.7500 - root_mean_squared_error: 1424.6812\n",
      "Epoch 18/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2142607.5000 - root_mean_squared_error: 1461.5708\n",
      "Epoch 19/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1873242.0000 - root_mean_squared_error: 1368.0802\n",
      "Epoch 20/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1928698.2500 - root_mean_squared_error: 1387.9888\n",
      "Epoch 21/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1879908.5000 - root_mean_squared_error: 1369.7705\n",
      "Epoch 22/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1557632.6250 - root_mean_squared_error: 1247.6873\n",
      "Epoch 23/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1467341.5000 - root_mean_squared_error: 1209.6892\n",
      "Epoch 24/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1474375.8750 - root_mean_squared_error: 1213.3611\n",
      "Epoch 25/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1441040.0000 - root_mean_squared_error: 1199.2806\n",
      "Epoch 26/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1372262.0000 - root_mean_squared_error: 1170.0924\n",
      "Epoch 27/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1316022.1250 - root_mean_squared_error: 1146.1296\n",
      "Epoch 28/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1227327.7500 - root_mean_squared_error: 1107.1067\n",
      "Epoch 29/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1306554.3750 - root_mean_squared_error: 1141.8638\n",
      "Epoch 30/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1237278.8750 - root_mean_squared_error: 1112.0654\n",
      "Epoch 31/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1038715.0000 - root_mean_squared_error: 1014.8003\n",
      "Epoch 32/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1045710.2500 - root_mean_squared_error: 1020.1722\n",
      "Epoch 33/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1134058.8750 - root_mean_squared_error: 1064.6108\n",
      "Epoch 34/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1029581.5625 - root_mean_squared_error: 1014.4674\n",
      "Epoch 35/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 975966.1875 - root_mean_squared_error: 987.6527\n",
      "Epoch 36/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1022255.3750 - root_mean_squared_error: 1007.3657\n",
      "Epoch 37/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 925638.6250 - root_mean_squared_error: 961.2031\n",
      "Epoch 38/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 785191.6875 - root_mean_squared_error: 884.7906\n",
      "Epoch 39/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 977938.0000 - root_mean_squared_error: 984.9586 \n",
      "Epoch 40/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 821320.6875 - root_mean_squared_error: 905.6332\n",
      "Epoch 41/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 801254.1250 - root_mean_squared_error: 894.6761\n",
      "Epoch 42/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 791570.3125 - root_mean_squared_error: 889.3557\n",
      "Epoch 43/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 799586.0625 - root_mean_squared_error: 893.9595\n",
      "Epoch 44/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 675266.6250 - root_mean_squared_error: 820.4943\n",
      "Epoch 45/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 813790.1250 - root_mean_squared_error: 900.8472\n",
      "Epoch 46/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 748519.8750 - root_mean_squared_error: 864.6142\n",
      "Epoch 47/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 638283.0625 - root_mean_squared_error: 797.5366\n",
      "Epoch 48/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 619970.0000 - root_mean_squared_error: 786.8931\n",
      "Epoch 49/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 658138.3125 - root_mean_squared_error: 809.4221\n",
      "Epoch 50/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 790677.4375 - root_mean_squared_error: 880.1500\n",
      "Epoch 51/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 614606.2500 - root_mean_squared_error: 780.9157\n",
      "Epoch 52/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 636641.9375 - root_mean_squared_error: 796.1607\n",
      "Epoch 53/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 653632.1250 - root_mean_squared_error: 806.6658\n",
      "Epoch 54/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 606944.3750 - root_mean_squared_error: 775.9968\n",
      "Epoch 55/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 598446.2500 - root_mean_squared_error: 771.7610\n",
      "Epoch 56/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 583104.1875 - root_mean_squared_error: 762.1953\n",
      "Epoch 57/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516780.5312 - root_mean_squared_error: 718.1104\n",
      "Epoch 58/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 524669.2500 - root_mean_squared_error: 723.6660\n",
      "Epoch 59/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 585530.3750 - root_mean_squared_error: 764.2183\n",
      "Epoch 60/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628035.0625 - root_mean_squared_error: 791.2142\n",
      "Epoch 61/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 533584.8750 - root_mean_squared_error: 729.3705\n",
      "Epoch 62/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 526568.6875 - root_mean_squared_error: 723.2209\n",
      "Epoch 63/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617429.5625 - root_mean_squared_error: 782.7976\n",
      "Epoch 64/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544427.9375 - root_mean_squared_error: 737.6881\n",
      "Epoch 65/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 667277.3750 - root_mean_squared_error: 810.5475\n",
      "Epoch 66/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570281.8750 - root_mean_squared_error: 751.1337\n",
      "Epoch 67/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 489894.3125 - root_mean_squared_error: 698.2280\n",
      "Epoch 68/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504830.0000 - root_mean_squared_error: 709.0573\n",
      "Epoch 69/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 454798.7500 - root_mean_squared_error: 670.3416\n",
      "Epoch 70/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 628414.3750 - root_mean_squared_error: 790.6863\n",
      "Epoch 71/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 534630.4375 - root_mean_squared_error: 729.6791\n",
      "Epoch 72/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 455730.1562 - root_mean_squared_error: 673.9705\n",
      "Epoch 73/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 551751.1875 - root_mean_squared_error: 741.6413\n",
      "Epoch 74/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494748.9688 - root_mean_squared_error: 702.7585\n",
      "Epoch 75/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 506846.7188 - root_mean_squared_error: 710.3876\n",
      "Epoch 76/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 550444.7500 - root_mean_squared_error: 738.8124\n",
      "Epoch 77/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 502140.6562 - root_mean_squared_error: 706.6754\n",
      "Epoch 78/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 544130.0000 - root_mean_squared_error: 735.4393\n",
      "Epoch 79/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 473231.7812 - root_mean_squared_error: 686.7758\n",
      "Epoch 80/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516951.8750 - root_mean_squared_error: 718.2430\n",
      "Epoch 81/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 508404.2812 - root_mean_squared_error: 712.4409\n",
      "Epoch 82/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 474886.7500 - root_mean_squared_error: 687.6676\n",
      "Epoch 83/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 500461.3438 - root_mean_squared_error: 706.8253\n",
      "Epoch 84/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494703.4062 - root_mean_squared_error: 702.8209\n",
      "Epoch 85/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 590656.1250 - root_mean_squared_error: 767.5303\n",
      "Epoch 86/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 477681.6250 - root_mean_squared_error: 688.3699\n",
      "Epoch 87/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 466804.6250 - root_mean_squared_error: 682.1031\n",
      "Epoch 88/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 566983.7500 - root_mean_squared_error: 751.9617\n",
      "Epoch 89/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486856.6250 - root_mean_squared_error: 695.3416\n",
      "Epoch 90/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 528571.4375 - root_mean_squared_error: 726.1610\n",
      "Epoch 91/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 536292.7500 - root_mean_squared_error: 730.2254\n",
      "Epoch 92/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 472310.3125 - root_mean_squared_error: 686.2278\n",
      "Epoch 93/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 547254.9375 - root_mean_squared_error: 738.6998\n",
      "Epoch 94/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523331.1250 - root_mean_squared_error: 722.0747\n",
      "Epoch 95/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 487726.4375 - root_mean_squared_error: 696.8038\n",
      "Epoch 96/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 503833.0000 - root_mean_squared_error: 708.2172\n",
      "Epoch 97/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476865.4688 - root_mean_squared_error: 687.9749\n",
      "Epoch 98/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 425539.1250 - root_mean_squared_error: 648.9673\n",
      "Epoch 99/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 565425.8125 - root_mean_squared_error: 745.8909\n",
      "Epoch 100/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 454411.9375 - root_mean_squared_error: 670.6979\n",
      "Epoch 101/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 437096.7500 - root_mean_squared_error: 660.2762\n",
      "Epoch 102/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 424435.6875 - root_mean_squared_error: 650.3641\n",
      "Epoch 103/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 461301.0312 - root_mean_squared_error: 677.9938\n",
      "Epoch 104/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 589987.4375 - root_mean_squared_error: 766.3440\n",
      "Epoch 105/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 637505.3125 - root_mean_squared_error: 788.7636\n",
      "Epoch 106/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 425484.0938 - root_mean_squared_error: 651.6426\n",
      "Epoch 107/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 514281.9688 - root_mean_squared_error: 716.6022\n",
      "Epoch 108/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 541117.5000 - root_mean_squared_error: 734.7807\n",
      "Epoch 109/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 587220.4375 - root_mean_squared_error: 762.3111\n",
      "Epoch 110/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 471456.7188 - root_mean_squared_error: 681.2358\n",
      "Epoch 111/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 558004.3125 - root_mean_squared_error: 746.5818\n",
      "Epoch 112/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 553063.8750 - root_mean_squared_error: 742.1147\n",
      "Epoch 113/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 546501.1875 - root_mean_squared_error: 736.4439\n",
      "Epoch 114/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 531631.6250 - root_mean_squared_error: 728.3769\n",
      "Epoch 115/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 462732.7812 - root_mean_squared_error: 676.0187\n",
      "Epoch 116/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 549994.0000 - root_mean_squared_error: 739.2186\n",
      "Epoch 117/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 559994.5625 - root_mean_squared_error: 746.8428\n",
      "Epoch 118/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 518380.2500 - root_mean_squared_error: 718.8469\n",
      "Epoch 119/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 579670.6875 - root_mean_squared_error: 756.6339\n",
      "Epoch 120/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 464585.5312 - root_mean_squared_error: 680.7600\n",
      "Epoch 121/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 596905.7500 - root_mean_squared_error: 769.0185\n",
      "Epoch 122/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 500416.2188 - root_mean_squared_error: 707.0191\n",
      "Epoch 123/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 546886.5625 - root_mean_squared_error: 738.8111\n",
      "Epoch 124/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 533967.5000 - root_mean_squared_error: 729.0415\n",
      "Epoch 125/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 545703.6875 - root_mean_squared_error: 737.8353\n",
      "Epoch 126/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 494083.6875 - root_mean_squared_error: 701.4635\n",
      "Epoch 127/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 461782.1250 - root_mean_squared_error: 676.8464\n",
      "Epoch 128/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476568.5000 - root_mean_squared_error: 689.3837\n",
      "Epoch 129/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521147.6250 - root_mean_squared_error: 721.0479\n",
      "Epoch 130/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 506855.7500 - root_mean_squared_error: 710.6601\n",
      "Epoch 131/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 538400.8750 - root_mean_squared_error: 731.8327\n",
      "Epoch 132/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 584491.8750 - root_mean_squared_error: 758.8624\n",
      "Epoch 133/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 558619.8125 - root_mean_squared_error: 746.3486\n",
      "Epoch 134/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 497904.8125 - root_mean_squared_error: 704.1646\n",
      "Epoch 135/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 516367.5938 - root_mean_squared_error: 716.8998\n",
      "Epoch 136/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 507601.9375 - root_mean_squared_error: 711.2701\n",
      "Epoch 137/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 557440.1875 - root_mean_squared_error: 745.7344\n",
      "Epoch 138/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 555706.3750 - root_mean_squared_error: 744.3597\n",
      "Epoch 139/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 433813.0312 - root_mean_squared_error: 657.4096\n",
      "Epoch 140/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 534496.1875 - root_mean_squared_error: 729.8597\n",
      "Epoch 141/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 516721.2812 - root_mean_squared_error: 717.2498\n",
      "Epoch 142/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486220.6875 - root_mean_squared_error: 696.7137\n",
      "Epoch 143/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 520561.1875 - root_mean_squared_error: 720.8444\n",
      "Epoch 144/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 567431.1250 - root_mean_squared_error: 752.0197\n",
      "Epoch 145/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 527320.3750 - root_mean_squared_error: 724.5180\n",
      "Epoch 146/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 598696.1875 - root_mean_squared_error: 771.8152\n",
      "Epoch 147/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 474098.5625 - root_mean_squared_error: 687.6507\n",
      "Epoch 148/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 475336.2500 - root_mean_squared_error: 688.4737\n",
      "Epoch 149/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 490575.4688 - root_mean_squared_error: 698.8124\n",
      "Epoch 150/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 496388.9062 - root_mean_squared_error: 703.3141\n",
      "Epoch 151/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 476207.7812 - root_mean_squared_error: 687.5299\n",
      "Epoch 152/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 486273.5312 - root_mean_squared_error: 696.9362\n",
      "Epoch 153/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 521952.1562 - root_mean_squared_error: 721.4495\n",
      "Epoch 154/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 482100.3750 - root_mean_squared_error: 692.2214\n",
      "Epoch 155/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 526118.3750 - root_mean_squared_error: 724.7486\n",
      "Epoch 156/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 523870.0312 - root_mean_squared_error: 722.7468\n",
      "Epoch 157/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 452804.5312 - root_mean_squared_error: 671.2793\n",
      "Epoch 158/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 566792.6250 - root_mean_squared_error: 750.9657\n",
      "Epoch 159/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 531547.6875 - root_mean_squared_error: 727.5444\n",
      "Epoch 160/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 570542.7500 - root_mean_squared_error: 753.7039\n",
      "Epoch 161/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 472107.6562 - root_mean_squared_error: 685.3410\n",
      "Epoch 162/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 435393.3125 - root_mean_squared_error: 656.9633\n",
      "Epoch 163/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 544818.5000 - root_mean_squared_error: 736.9638\n",
      "Epoch 164/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 569039.8750 - root_mean_squared_error: 752.1685\n",
      "Epoch 165/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 542511.3750 - root_mean_squared_error: 735.0182\n",
      "Epoch 166/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 504543.9375 - root_mean_squared_error: 709.5731\n",
      "Epoch 167/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535212.3125 - root_mean_squared_error: 730.8113\n",
      "Epoch 168/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 435206.5000 - root_mean_squared_error: 656.3866\n",
      "Epoch 169/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 603344.6875 - root_mean_squared_error: 774.0486\n",
      "Epoch 170/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 498496.3438 - root_mean_squared_error: 705.4391\n",
      "Epoch 171/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 481236.5000 - root_mean_squared_error: 692.6401\n",
      "Epoch 172/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 490058.5938 - root_mean_squared_error: 698.1608\n",
      "Epoch 173/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 475593.1562 - root_mean_squared_error: 689.2513\n",
      "Epoch 174/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 593902.1875 - root_mean_squared_error: 767.9727\n",
      "Epoch 175/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 514882.5938 - root_mean_squared_error: 716.8660\n",
      "Epoch 176/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 505833.8750 - root_mean_squared_error: 710.7866\n",
      "Epoch 177/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 626787.1250 - root_mean_squared_error: 789.5032\n",
      "Epoch 178/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 527348.5625 - root_mean_squared_error: 720.8278\n",
      "Epoch 179/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 502422.7500 - root_mean_squared_error: 707.5851\n",
      "Epoch 180/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 461183.7812 - root_mean_squared_error: 677.8109\n",
      "Epoch 181/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 583400.8750 - root_mean_squared_error: 757.5824\n",
      "Epoch 182/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 517742.0312 - root_mean_squared_error: 718.9106\n",
      "Epoch 183/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 594686.2500 - root_mean_squared_error: 765.2086\n",
      "Epoch 184/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 535472.1250 - root_mean_squared_error: 730.9206\n",
      "Epoch 185/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 481700.1875 - root_mean_squared_error: 692.7059\n",
      "Epoch 186/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 560044.5625 - root_mean_squared_error: 745.8172\n",
      "Epoch 187/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 603373.5625 - root_mean_squared_error: 775.8212\n",
      "Epoch 188/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 529943.5000 - root_mean_squared_error: 726.5146\n",
      "Epoch 189/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 494359.5000 - root_mean_squared_error: 702.6254\n",
      "Epoch 190/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 477730.9062 - root_mean_squared_error: 690.2446\n",
      "Epoch 191/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 602590.8125 - root_mean_squared_error: 774.5026\n",
      "Epoch 192/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 473554.3438 - root_mean_squared_error: 685.0563\n",
      "Epoch 193/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 458459.1562 - root_mean_squared_error: 675.7966\n",
      "Epoch 194/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492169.3438 - root_mean_squared_error: 699.4238\n",
      "Epoch 195/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 501285.8438 - root_mean_squared_error: 707.4543\n",
      "Epoch 196/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 511996.0000 - root_mean_squared_error: 714.2047\n",
      "Epoch 197/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 525076.0625 - root_mean_squared_error: 723.9547\n",
      "Epoch 198/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 487450.3125 - root_mean_squared_error: 696.3899\n",
      "Epoch 199/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 596304.6250 - root_mean_squared_error: 769.6336\n",
      "Epoch 200/200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 466912.4375 - root_mean_squared_error: 682.2715\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459127.3125 - root_mean_squared_error: 675.6237\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 507112.9062 - root_mean_squared_error: 700.3168\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n"
     ]
    }
   ],
   "source": [
    "nn_model = do_nn_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25993f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_model.save('solar2_filtered_nn.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31484f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18a9e3abb10>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(histories[0].history['root_mean_squared_error'], label='Training RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "82ff3421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Train RMSE: 715.947 ± 7.732\n",
      "NN Test RMSE: 803.581 ± 10.897\n",
      "NN R2: 0.762 ± 0.006\n",
      "NN Time: 65.133 ± 2.005\n"
     ]
    }
   ],
   "source": [
    "nn_train_accuracy_mean = np.round(np.mean(nn_train_accuracy), 3)\n",
    "nn_train_accuracy_std = np.round(np.std(nn_train_accuracy), 3)\n",
    "nn_test_accuracy_mean = np.round(np.mean(nn_test_accuracy), 3)\n",
    "nn_test_accuracy_std = np.round(np.std(nn_test_accuracy),3)\n",
    "nn_r2_mean = np.round(np.mean(nn_r2s),3)\n",
    "nn_r2_std = np.round(np.std(nn_r2s),3)\n",
    "nn_time_mean = np.round(np.mean(nn_time),3)\n",
    "nn_time_std = np.round(np.std(nn_time),3)\n",
    "\n",
    "print(f\"NN Train RMSE: {nn_train_accuracy_mean} ± {nn_train_accuracy_std}\")\n",
    "print(f\"NN Test RMSE: {nn_test_accuracy_mean} ± {nn_test_accuracy_std}\")\n",
    "print(f\"NN R2: {nn_r2_mean} ± {nn_r2_std}\")\n",
    "print(f\"NN Time: {nn_time_mean} ± {nn_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67852cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsl_model(x_train, y_train, number_of_rules):\n",
    "    tsl_model = TsModel.TsModel(number_of_rules, fuzzification_coefficient=1.2)\n",
    "    tsl_model.fit(x_train, y_train)\n",
    "    return tsl_model\n",
    "\n",
    "def get_tsc_model(x_train, y_train, number_of_rules):\n",
    "    tsc_model = TsModel_constant.TsModel_constant(number_of_rules, fuzzification_coefficient=1.2)\n",
    "    tsc_model.fit(x_train, y_train)\n",
    "    return tsc_model\n",
    "\n",
    "# TS model\n",
    "# Linear conclusion\n",
    "\n",
    "def ts_relu_wrapper(pred):\n",
    "    return np.maximum(0, pred)\n",
    "\n",
    "number_of_rules_array = [2,3,4,5,8,10,15,20,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a6514e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 727.3484534820018\n",
      "FCM training RMSE: 731.3454663278844\n",
      "FCM training RMSE: 738.0961590697921\n",
      "FCM training RMSE: 729.8200494982676\n",
      "FCM training RMSE: 742.0874658911796\n",
      "FCM training RMSE: 721.5910089695541\n",
      "FCM training RMSE: 723.7218603004033\n",
      "FCM training RMSE: 727.720251037819\n",
      "FCM training RMSE: 715.3299006898262\n",
      "FCM training RMSE: 711.9013271786125\n",
      "FCM training RMSE: 711.9532147829837\n",
      "FCM training RMSE: 715.8074329707265\n",
      "FCM training RMSE: 720.7073008636149\n",
      "FCM training RMSE: 714.463678689294\n",
      "FCM training RMSE: 725.759941000947\n",
      "FCM training RMSE: 703.5140436469582\n",
      "FCM training RMSE: 708.7212684962449\n",
      "FCM training RMSE: 709.904590833444\n",
      "FCM training RMSE: 695.9398295470186\n",
      "FCM training RMSE: 694.648472734029\n",
      "FCM training RMSE: 696.1271543863827\n",
      "FCM training RMSE: 715.110747855347\n",
      "FCM training RMSE: 720.0943923629649\n",
      "FCM training RMSE: 713.7887813270031\n",
      "FCM training RMSE: 714.615895735258\n",
      "FCM training RMSE: 708.9199247463586\n",
      "FCM training RMSE: 705.1086137213997\n",
      "FCM training RMSE: 693.1540096174314\n",
      "FCM training RMSE: 676.8753865955446\n",
      "FCM training RMSE: 681.0252736686882\n",
      "FCM training RMSE: 695.0792391574157\n",
      "FCM training RMSE: 700.1997740739862\n",
      "FCM training RMSE: 705.1068222284025\n",
      "FCM training RMSE: 717.9078961037495\n",
      "FCM training RMSE: 710.8283418097574\n",
      "FCM training RMSE: 687.351330552558\n",
      "FCM training RMSE: 704.8784925617631\n",
      "FCM training RMSE: 695.4645448457246\n",
      "FCM training RMSE: 676.384842314905\n",
      "FCM training RMSE: 682.9687271940238\n",
      "FCM training RMSE: 684.9705743393606\n",
      "FCM training RMSE: 693.5559662968542\n",
      "FCM training RMSE: 698.197276317098\n",
      "FCM training RMSE: 694.3635451581458\n",
      "FCM training RMSE: 707.6101449808989\n",
      "FCM training RMSE: 689.8982972565726\n",
      "FCM training RMSE: 695.4301429703569\n",
      "FCM training RMSE: 688.5598901303593\n",
      "FCM training RMSE: 669.9882952740984\n",
      "FCM training RMSE: 678.3864608435116\n",
      "FCM training RMSE: 683.9074665662257\n",
      "FCM training RMSE: 692.0768380142761\n",
      "FCM training RMSE: 693.8759459274478\n",
      "FCM training RMSE: 687.7965724763411\n",
      "FCM training RMSE: 704.8437932341154\n",
      "FCM training RMSE: 681.4648069740865\n",
      "FCM training RMSE: 685.6983558738043\n",
      "FCM training RMSE: 683.0163437638718\n",
      "FCM training RMSE: 659.0010246885824\n",
      "FCM training RMSE: 668.7913011599435\n",
      "FCM training RMSE: 677.6705523410474\n",
      "FCM training RMSE: 674.8097184610135\n",
      "FCM training RMSE: 681.8380649813871\n",
      "FCM training RMSE: 679.2357091370055\n",
      "FCM training RMSE: 691.9242453487684\n",
      "FCM training RMSE: 672.5814392353384\n",
      "FCM training RMSE: 676.5931518521098\n",
      "FCM training RMSE: 678.9257243248048\n",
      "FCM training RMSE: 652.9368960421751\n",
      "FCM training RMSE: 656.3920285011685\n",
      "FCM training RMSE: 659.3177887291349\n",
      "FCM training RMSE: 674.1810814877402\n",
      "FCM training RMSE: 677.4427014849806\n",
      "FCM training RMSE: 667.8073657967624\n",
      "FCM training RMSE: 689.8193727111369\n",
      "FCM training RMSE: 661.9670841275894\n",
      "FCM training RMSE: 667.9957234950824\n",
      "FCM training RMSE: 669.5769109824763\n",
      "FCM training RMSE: 646.6920811867835\n",
      "FCM training RMSE: 651.3190040587344\n",
      "FCM training RMSE: 660.4075315078996\n",
      "FCM training RMSE: 658.562560491722\n",
      "FCM training RMSE: 669.7094122373092\n",
      "FCM training RMSE: 660.2404448505439\n",
      "FCM training RMSE: 681.3324437345964\n",
      "FCM training RMSE: 653.5571179658532\n",
      "FCM training RMSE: 661.98708678181\n",
      "FCM training RMSE: 664.6173480644657\n",
      "FCM training RMSE: 640.5449143410021\n",
      "FCM training RMSE: 650.3480558403586\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAKhCAYAAAC2B607AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC7k0lEQVR4nOzddZxU9f7H8deZ2U5YdqklZemWzgVBvCAGioCAhIJYCIrx45r3GlwRC7BQFEUQA8FOSrpEuqUWpGG7Z35/HBl22c6z8X4+HvPgzDnfOfMZJd77nW8YTqfTiYiIiIhIGWezugARERERkeKg4CsiIiIi5YKCr4iIiIiUCwq+IiIiIlIuKPiKiIiISLmg4CsiIiIi5YKCr4iIiIiUC25WF1DSORwOTpw4gb+/P4ZhWF2OiIiIiFzB6XQSHR1N9erVsdmy7tdV8M3BiRMnqFmzptVliIiIiEgOjh07Ro0aNbK8ruCbA39/f8D8DxkQEGBxNSIiIiJypaioKGrWrOnKbVnJc/Dt0aMHK1asyNNrli1bRo8ePVzPd+/ezZIlS9i4cSPbt2/n9OnTnD17FrvdTpUqVWjXrh1Dhw7lxhtvzNXwgpSUFN5//33mzZvHnj17iImJoXr16vTu3ZsHH3yQpk2b5vVjulx6/4CAAAVfERERkRIsp9xoOJ1OZ15umNfga7PZOHr0KKGhoa5zw4cPZ968eTm+Njw8nIULF1KpUqUs25w9e5Z+/fqxcePGTK97enoyc+ZMxowZk+ua04qKiiIwMJDIyEgFXxEREZESKLd5Lc89vh9++CGxsbHZttm1axeDBw8GoFevXulCL4CbmxsdOnSgS5cuNG/enKpVqxISEsKFCxfYs2cP7777Ljt27GDFihXccMMNrFq1KtOByqmpqQwYMMAVem+55RbGjh1LUFAQ69ev5/nnn+f06dOMGzeO0NBQ+vbtm9ePKyIiIiJlRJ57fHPj8ccfZ+rUqQDMnTuX4cOHp7uekpKCm1vWmTs1NZVBgwbx1VdfAfD1119z4403Zmj3wQcfcNdddwFw33338eabb6a7fuDAAdq0aUNUVBRhYWHs3r072/fNjHp8RUREREq23Oa1Ql/H1+FwuIYx+Pn5ccstt2Rok1P4tNvtPProo67nK1euzLTdtGnTAAgKCuLll1/OcD0sLIzJkycDZghetGhR7j6EiIiIiJQ5hR58lyxZwvHjxwEYOHAgPj4++bpP2ll5CQkJGa7v27eP3bt3AzBo0KAs32fUqFGuYwVfERERkfKr0IPvxx9/7DoeMWJEvu+zYMEC13GjRo0yXF+1apXrODw8PMv7VK1alQYNGgCwevXqfNcjIiIiIqVboQbfmJgYV69q7dq10y1hlhtnz55l7dq13HXXXbzwwgsABAcHM2zYsAxtd+3a5TrOLBinden6sWPHcpyYJyIiIiJlU6FuYLFw4UJXsBw+fHiu1uDNbnm04OBgFi1aRIUKFTJci4iIcB1nt0MH4Np5zel0EhERQcOGDbNsm5iYSGJiout5VFRUtvcWERERkdKhUHt8C2uYA8CDDz7I7t276dq1a6bXo6OjXcd+fn7Z3svX19d1HBMTk23bKVOmEBgY6Hpou2IRERGRsqHQgm9ERATLly8HoGPHjq5xtTn58MMP2b59O9u2beP333/n1VdfpX79+sycOZPRo0dz6tSpTF+XdsKbh4dHtu/h6enpOo6Pj8+27eTJk4mMjHQ9jh07lqvPISIiIiIlW6ENdfjkk09wOBwAjBw5Mtevq1u3brrn3bp149577+W2227ju+++o127dqxZsybDcAYvLy/XcVJSUrrnV0o7dMHb2zvbejw9PdMFZREREREpGwqtx3fu3LmAGRwv7dqWX15eXnz44Yf4+Phw7NgxHnvssQxt0i53ltPwhbQT2nIaFiEiIiIiZVOhBN9Nmza5Vlno378/FStWLPA9g4OD6dKlC2Du3JacnJzuetoe4LQT3TJzabiCYRg5ToQTERERkbKpUIJv2klteRnmkJOQkBAA4uLiOHv2bLprTZo0cR3v2bMn2/tcul6zZs10E91EREREpPwocPBNTk52bTYREhJC3759C1zUJZd2gIOMQxTSrvaQ1XJoACdPnmTfvn0Arh5kERERESl/Chx8f/zxR86cOQPA0KFDcXMrnPlyERERrF27FjA3w0g7phegQYMGNG7cGIDPP/+cuLi4TO8zZ84c1/GAAQMKpTYRERERKX0KHHzzunbvvn37WLp0abZtIiMjGTp0KElJSdne95FHHgHg/PnzmU6AO3jwIFOmTAEgLCxMwVdERESkHDOcTqczvy++cOEC1apVIzExkWbNmrF9+/YcX7N8+XJ69uxJy5Ytufnmm2nTpg1Vq1bFzc2NkydPsnr1ambPns3JkycBaNasGevXr8fHxyfDvVJTUwkPD2f16tUA3HrrrYwdO5aKFSuyYcMGnnvuOU6fPo3NZuO7777L1zCMqKgoAgMDiYyMJCAgIM+vFxEREZGildu8VqBxCZ999plrjdy87tS2detWtm7dmm2b66+/3rWsWWbsdjuLFy+mX79+bNy4kYULF7Jw4cJ0bTw9PZk5c2ahjj0WERERkdKnQD2+Xbp0Yc2aNdjtdo4ePUr16tVzfE1ycjLLli3jt99+Y9OmTURERHDq1Cni4uIICAigbt26dOzYkdtvvz3Xk9FSUlJ47733mD9/Prt37yY2Npbq1avTq1cvJkyYQNOmTfP7EdXjKyIiIlLC5TavFSj4lgfFEnwjIyD2bNbXfUMgMLRo3ltERESklCuWoQ5SCFISYVZPiD2ddRu/yjBxB7hpK2URERGR/Cq0LYsln+we//TmZvW/wgYBoWY7EREREck3BV+rGQZc8yTgyKKBw7xuGMVZlYiIiEiZo+BbEtTrBdVbg2FPf96wm+fr9bKmLhEREZEyRMG3JLjU6+tMTX/emareXhEREZFCouBbUlzq9SVNyK2m3l4RERGRwqLgW1K4xvqmWV2uRlv19oqIiIgUEgXfksTV6/uPHV9BYrR19YiIiIiUIQq+JYlhQK9nILgB+FeD+HOwZqbVVYmIiIiUCQq+JU29nvDARvjX/8zna2ZA9ClraxIREREpAxR8S6omN0FoG0iOhRUvWV2NiIiISKmn4FtSGQZc+1/zePMcOHvA0nJERERESjsF35KsTleof525nu/S/1pdjYiIiEip5mZ1AQInLsZzPjYp02ueLR4hbP8vGLu+hohN5hJnIiIiIpJnCr4WS0xJ5caZqzgbk3nwBZjh3YMbnMvg16dh1Pda21dEREQkHxR8LeZht1G9gjfnYpNwOjNeNwxYVGEk/aPXYpw7CNF/Q0D14i9UREREJDuRERB7NuvrviEQGFp89WRCwddihmEwqU9DRn6wIdPrTieM7NsVw+1zqNEOPHyKuUIRERGRHKQkwqyeEHs66zZ+lWHiDnDzLL66rqDJbSVA9/rBtKgRiO2KEQw2A1rUCKR7/WC4KlyhV0REREomu8c/vblZRUsbBISa7Syk4FsCXOr1dVwx1MHhhEl9GmKkHdPrcMCOhZAcX7xFioiIiGTFMOCaJwFHFg0c5nWL5ykp+JYQl3p90/52aB76T29vWp8Ngy/vhA2zirU+ERERkWzV6wVVmoNxRbw07FC9tXndYgq+JcSlXt+0nb6d61VK39sL0PgG8AwAN69irU9EREQkWxvfhzN7wHlFr68ztUT09oKCb4lyqdf3kh93/E1y6hW/eVoMhglbocO4Yq5ORERE5AqONDmlUhg4ksHDz+zlhRLV2wsKviWKYRg8dl0jrgrxJcDLjaPn4/liU0T6RjY7+ARZU6CIiIiI0wmHV8MnA2Hpc5fPX9UD7voVbvvI7OWFEtXbCwq+JU7X+sEsndSDib0bADBj6X4SklMzNnQ6Yf+vsGJqMVcoIiIi5ZLDAXu+h9nXwpx+cOBX2PyhuZQZmOG2ZnsI62X28kKJ6u0FBd8Sa2iHWlQL9OLvyATmrT+ascGZvTBvICx7EU7tLP4CRUREpHxISYIt8+CtjrBgKERsBLsntL0Txi7NuC6vYUCvZyC4oflrCentBQXfEsvL3c6DveoD8NayA8QmpqRvULkRNB0AOOG3Z4u9PhERESnjEmNg7VswvRV8fR+c3WtOsO/6MEzcDv1fg6CrMn9tvZ7wwAbz1xJEwbcEG9imBrUr+XAuNok5aw5nbHDNU2Bzg/2/wKGVxV6fiIiIlEGx58xvlF9rCj9Phqjj4FcFrv0vPLQTej8D/lWsrjJfFHxLMHe7jYevNcf6vrviIJFxyekbVKoHbUabx78+bY77FREREcmvVa+bgXfFS5BwEYLqwQ1vwIRt0GUCeAVYXWGBKPiWcDe0qE7DKv5EJaQwa+XBjA3CHzOXDTnxB+xaXOz1iYiISCmXtuPMuyKkxEO1VubqDA9shDajwL1s7B+g4FvC2WwGD/cxe32/2/Y3KVeu6+tXGTqPN4+X/BdSr+gVFhEREclMxGaYPxj++OjyuZZDYMQ3cPdyaHqzuYxqGaLgWwr0aVKFqbe24McJ3XCzZ/K/rNMD4BsC5/+CzXOKvT4REREphY6th30/wZoZl3t93TzhqvAStRJDYVLwLQUMw2BQu5r4eLhl3sDTD8IfN49XvASJ0cVXnIiIiJR8qcnw56ew75fL564eAe3HwdDPy2zQvZKCbynjcDjZeuxixgttRpkD0GPPwJqZxV2WiIiIlERJsbDuHZjeGhbfYy6Beql319MP+k01J8uXEwq+pUh0QjL9pq/k1rfXcPhsbPqLdnfo9bR5vGYGRJ8q/gJFRESkZIg7D8v/B681g58eh8hj4FsZmg8s1/OBsvjuXEoify93qgR4cfxCPPtORVMn2Dd9gyY3QWgbOL4Zfn8Zrp9mTaEiIiJijYvHYO2b5oS15DjzXMW60OVBaDm0zKzOkF8KvqXM8zc3w9/LjQo+HhkvGoa5uPQfc83f4CIiIlI+nN4Dq9+A7Z+D45/dXqu2gK4PmR1jZWx1hvxS8C1lagb5ZN+gTlfzISIiImXfsY2w6lXY+8Plc3W7m4H3qp7lZtJabin4llJOp5MV+85QJcCLxtWy2UUlJdFcmkRERETKnp1f/RN6DWjcH7o8BDXaWF1ViaXgW0q9uewA037ZR/cGIXx8Z/uMDSIj4JcnIfYsjPxWP/GJiIiUdqkpZtANrg/VW5vnOt0PSTHQ+UHzvGRLqzqUUje2DMXNZvD7vjNsOHQ+80Z7foDDq+Dk9uItTkRERArfkv/AV2Nh+UuXzwXWgBtnKPTmkoJvKVWrkg+D2tUEYNrPe3Gm3WcbzD8I/V+De1ZCtRYWVCgiIiIFEn8BIo9ffn71SPCrAjXaXl6LV/JEwbcUG39NGB5uNjYcPs/v+89mbNB6GFRtXvyFiYiISP5FHoefnzDX4P31qcvng8PgoZ3Q/RENYcwnBd9SrFqgN3d0rA3AK79k0uub1rmDkBxfTJWJiIhInp3ZB1/fD2+0hLUzzbG75w5AStLlNnZ36+orAxR8S7l7e9TDx8POtohIft6ZxW5ty1+CN9vDhlnFW5yIiIjkLGITLBhm/lu95RNwJEPtrjBsIdy9AtwyWbtf8kXBt5QL9vPkzi51AXj1172kOjLp9a1Q01zMeuUr5haGIiIiYi2nEw78BnP6w/u9YM93gBMa9Ye7foPR30P93hrSUMgUfMuAsd2vIsDLjX2nYvh264mMDVoMhspNISHSXORaRERErJGaAtu/hHe7wSe3wuGVYHODVsPg/g0wZB7UbGd1lWWWgm8ZEOjtzrjwegC8+us+klMd6RvY7ND7WfN4/SxzH28REREpft88AAvvMpcadfeFjvfDhK1w81sQ0tDq6so8Bd8yYnSXOgT7eXD0fBxfbIrI2KD+tVCnG6QmwrIXi79AERGR8ij+orks2SUtBoN3EPR8Ah7aAf960VyCVIqFgm8Z4ePhxn09wgCYsXQ/Ccmp6RsYBlz7H/N466dwckcxVygiIlIGREbAiT+zfqRdd3fTB+aSZKunXz53VQ9zSbLwx8AnqPjqFkBbFpcpQzvUYvaqQ3SoG0R8Uipe7vb0DULbQJObYddi+O1ZGP6lBVWKiIiUUimJMKsnxJ7Ouo1fZZi4A9w8zc0mkqLh6FpzMpthmA8Pn+KrWdJR8C1DvNzt/Ppwd3w8svnf2utpc+bogV/h0O9Qt3vxFSgiIlKa2T0gMBRizwKOzNsYbmY7gAZ94Y5FcFVPrc5QQmioQxmTbegFqFQP2ow2j399RlseioiI5JZhwDVPkmXoBUiKhdRk89hmg3rXKPSWIAq+ZdRfZ2J49IutRMYlZ7wY/hh4+MGJP2DnouIvTkREpLSq1wuqtwbDnvGadxDc+ZM2nCjBFHzLIKfTyQPzt/DF5ghmrTyYsYFfZeg83jxe8t/LP5mKiIhI9gwDekwGZ2rGa7e+B1WaFH9NkmsKvmWQYRhM6F2fXo0q0695tcwbdXoAfEPMGaUxWWx1LCIiIuk5UmHrgvTnDLvZC1yvlzU1Sa5pclsZdV3TqlzXtGrWDTz9YMxvUKG2xh6JiIjkhsMBXz8AO78yw+6lXl9nqjn2V/+elnjq8S0nnJlNYqtYR39IRUREcsPphB8mwdb5Zugd+KHZywvq7S1FFHzLuFNRCTyxaDvPfrMz60aJ0bD8fxCTzbqEIiIi5ZXTCT8/YW5IgQED3oWmN0GvZyC4ofmrOpJKBQ11KOOOno9j3vqjuNkM7uxal9qVfDM2+vJO2P8LxJ6B618p/iJFRERKsguHYfMc8/jGGdDiNvO4Xk94YINVVUk+qMe3jGtXJ4jwBiGkOJy8/tv+zBt1fhCC6kHd8OItTkREpDQIqmtuRNH/dbj6DqurkQIwnJkO/pRLoqKiCAwMJDIykoCAAKvLyZftEZHcMHMVhgE/T+xOgyr+GRs5UsGWyZqEIiIi5VX8BfCuaHUVkgu5zWt57vHt0aMHhmHk6bF8+fJ094iLi+Orr77i3nvvpV27dlSsWBF3d3cqVapEp06dePbZZzl58mSua4qLi2Pq1Km0a9eOoKAgfH19adSoEZMmTeLIkSN5/YhlTvMagfyraVWcTnj1l32ZN1LoFRERuWzjbJjRBv7eanUlUojy3OPbo0cPVqxYkev2NpuNo0ePEhoaCsC2bdvo0qULMTEx2b4uICCAWbNmMXjw4GzbHThwgH79+rF/f+Zf4wcEBDBv3jz69++f65rTKgs9vgD7T0XT5/XfcTrhmwe60KJGhYyNUpJg84dwZDXc9pEG6ouISPmUmgIfXAfHN5mbVfT4P6srkhzkNq/lOfgeOnSI2NjYbNvs2rXLFVivvfZafvnlF9e1VatW0a1bNwC6dOlC//79adu2LZUqVeLMmTN89dVXvPfeezgcDux2O99++y19+/bN9H2io6Np27Yt+/aZvZhjx45lyJAheHt7s2zZMqZMmUJMTAw+Pj6sXr2aVq1a5eWjAmUn+AI8/NmffLXlON0bhPDxne0zNoiMgOlXQ2oiDP0cGlxX/EWKiIiUBAmR5kYV7e9WR1ApkNu8ludVHerWrZtjm7lz57qOR4wYke6azWZj0KBBPPPMMzRpknFbvz59+tC3b18GDBhAamoq48ePZ//+/RiZ/KZ7+eWXXaF36tSpPProo65rnTp1okePHoSHhxMXF8fEiRMzDLkobyb2bsA3W0/w+74zbDh0nvZ1g9I3CKwBHcbBmunw27MQ1ltDIEREpPy4cAQq1jaPvQLNfxOlTCn0yW0Oh4NatWpx/Phx/Pz8OHXqFD4+Pnm+z8CBA1m4cCEAmzdv5uqrr053PTk5mZCQECIjI2ncuDE7duzAZss4ZPmee+7h3XffBWDDhg20a9cuT3WUpR5fgH8v2s789UdpXyeIz8Z1zPgDRfwFeKMVJFyEm96C1sOsKFNERKR47f8NFtxu7sDWZYLV1UgeFdnktpwsWbKE48ePA2Z4zU/oBejZs6fr+ODBgxmuL1u2jMjISABGjhyZaegFGDVqlOt40aJF+aqlLBl/TRgebjY2HD7P7/vPZmzgXRG6TTKPl70AyfHFW6CIiEhxO/Q7fDYMUpPg+B/m1sRSJhV68P34449dx1cOc8iLxMRE17HdnvHr9lWrVrmOw8OzXn+2bdu2rvC9evXqfNdTVlQL9OaOjubXOK/8sjfzrYzb3w0BNSDqOGyYVcwVioiIFKOj62H+EEhJgAZ94Zb3IIvONCn9CvX/bExMjKtXtXbt2vTo0SPf90q7ckTjxo0zXN+1a5fruFGjRlnex83NjbCwMAB2796d73rKkvt61MPXw862iEhWZtbr6+4F1zxhHq98BeLOF2+BIiIixeHEFpg3EJJj4aqecNsccPOwuiopQoUafBcuXOha8WH48OGZTkjLja1bt/L9998D0Lx580yDb0REBAC+vr5UqFAh2/vVrFkTgDNnzqTrSc5MYmIiUVFR6R5lTSU/Tyb3a8w7w6+mW/3gzBu1GAyVm5qzWle9WrwFioiIFLWTO2DuAEiMgtpdYMh8s+NHyrRCDb6FMcwhMTGRMWPGkJqaCsALL7yQabvo6GgA/Pz8crynr6+v6zin9YOnTJlCYGCg63EpNJc1wzvW5l/NqmX9w4nNDr2fNY/Xz4KLx4qtNhERkSJ1Zh/Mvdmc0B3aFoZ+Bh75m5MkpUuhBd+IiAjXcmEdO3akQYMG+brPAw88wKZNmwBz0toNN9yQabuEhAQAPDxy/krC09PTdRwfn/1krcmTJxMZGel6HDtW9gNfTGIKyamZDOSvfy3U6Wau67vsxeIvTEREpLCd/ws+vhFiz0DVFjB8IXj6W12VFJNCC76ffPIJjn9mQY4cOTJf95gyZQrvv/8+AO3atePNN9/Msq2Xl/l1RFJSUo73TTu8wdvbO9u2np6eBAQEpHuUZZ9vPEb41GV8sSki40XDgN7/MY+3fgqndhZvcSIiIoXp4jH46CaI/htCGsMdi8G7gtVVSTEqtOB7adMKT0/PHLcZzsy7777Lv//9b8CcrPbDDz+kG6JwJX9/86eznIYuAOl2msvN0IjyJCYxhXOxSXy79UTmDWq0gSY3A05Y/UZxliYiIlJ4ok+aPb2RRyGoHoz4GnwrWV2VFLM879yWmU2bNrlWWejfvz8VK1bM0+s//fRT7rvvPsBcDeLXX38lODiLSVf/qFGjBuvXryc2NpaLFy9mO8Ht0nCFkJCQdMMeBIZ2qEWAtzs3taqedaNeT0OVptDp/uIrTEREpDD9tdwc5lChFoz8BvyrWF2RWKBQenzTTmrL6zCHb775hhEjRuBwOKhWrRpLliyhRo0aOb4u7XbHe/bsybJdSkqKawOMzFaHKO+83O0MbFMDd3s2vxUq1YPwx8Aj6x54ERGREq3lELj5HRjxDQTmnDOkbCpw8E1OTmbBggWA2aPat2/fXL92yZIlDBo0iJSUFCpVqsSvv/5KvXr1cvXarl27uo7Trvl7pU2bNrmGOnTp0iXXtZVHSSkOtkdEZt/I4YDI48VTkIiISEEkRJkrN1zS6nYIqmtdPWK5AgffH3/8kTNnzgAwdOhQ3NxyN3pizZo13HTTTSQmJhIYGMjPP/9M06ZNc/2+PXr0IDAwEICPPvoo8x3IgDlz5riOBwwYkOv7lzfHzsfRc9pyhr6/jsi45MwbnTsI7/WEj/pDahZtRERESoKkWJg/CD66AWIz2axJyqUCB9/8rN37559/cv311xMbG4uvry/ff/89bdq0ydP7enh48OCDDwLmjmzTpk3L0Gbt2rXMnj0bMLc1bteuXZ7eozypXsEbX0870QkpzFp5MPNGfpXNbYxjzsDJ7cVboIiISF5E/Q3nDsCFo+YqDiKA4cyqqzQXLly4QLVq1UhMTKRZs2Zs355zGDp48CCdO3fm9OnTALz22mv07t0729dUrlyZypUrZzgfHR1N27Zt2bdvHwB33303Q4YMwdvbm2XLlvHiiy8SExODt7c3a9asoVWrVnn+jFFRUQQGBhIZGVnmlzb7acdJ7vlkMz4edn5/rCfBfplMBDyyBoIbgG/2kw9FREQsd3Y/xF+Emur4Kutym9cKtKrDZ5995lojN7e9vStXrnSFXoCHHnoox9c888wzPPvssxnO+/v78/3339OvXz/279/PrFmzmDVrVro2AQEBzJs3L1+ht7y5rmkVWtQIZFtEJG8tO8jTNzTJ2Kh25+IvTEREJDdSU+DMHqjazHweXN/aeqTEKdBQh0tr99rtdoYNG1YoBeVVWFgYW7Zs4aWXXqJt27ZUqFABHx8fGjZsyEMPPcS2bdvo37+/JbWVNoZh8EifhgB8sv4If0dmv8sdB5dCzOns24iIiBQHRyosvhfe7w0HllhdjZRQBRrqUB6Up6EOAE6nk8Gz1rHh0Hlub1+LKbc0z7zhT/+GdW9CuzFw/SvFW6SIiEhaDgd8NwH++BhsbjD4E2iY+1WmpPTLbV4rtJ3bpGwwDINHrzN7fb/YdIwj52Izb3jpL5TNc8zVHkRERKzgdMJPj5uh17DBre8r9EqWFHwlg3Z1gghvEEKKw8nrv+3PvFHdblC/DzhSYMl/i7dAERERMEPvr0/DhlmAATe/DU21dKlkTcFXMnVprO/iP4+z71R05o16PwsYsGsxRGwurtJERERMK16CNdPN4/6vmbuziWRDwVcy1bxGIP9qWhWnE179ZV/mjao0hVZDzeNfnzZ/8hYRESkOq16H5VPM43/9D9qOtrQcKR0UfCVLD/dpgGHATztPZr2VcY/JYPeEI6tg/y/FW6CIiJRP69+F354xj3s9Ax3vtbYeKTUUfCVLDar4M6BVKP6ebhzKapJbhZrQYZx5/Nuz5nIyIiIiRWXzHPjxMfO4+2PQ7WFLy5HSRcuZ5aC8LWd2pdPRCbjbbFT09ci6UfwFeKMlJETCTW9Ba2vWdBYRkTJu62ewaBzghM7j4drnwDCsrkpKAC1nJoWisr9X9qEXwLsidJtkHi97AZJz2PhCREQkPw79DjjNNeQVeiUfFHwlV5xOJ7/vO8PmI+czb9B+HATUgKjj/ywrIyIiUshunAED3oW+Lyv0Sr4o+EqufLTmMCM+2MB/vt1FpqNj3L3gmifM45WvQFwWAVlERCQvTu28PH/EZjOXLLMpvkj+6HeO5MoNLasT5OtB29pBJKY4Mm/UYjBUaWZubJGaXLwFiohI2XN4NbzXC766W/+uSKFws7oAKR0q+Xmy+vFr8PawZ93IZocxv4G7d/EVJiIiZVfcOXAkQ2KU1oqXQqHgK7mWbei9RKFXREQKS5MbYeR3UL0VuOUw0VokFzTUQfJs67GLPPLFVpJTsxjyAHD+ECwcY47NEhERya3Te+DiscvPa3dSp4oUGvX4Sp4kpqRy10ebOBuTyNW1KjK0Q63MGy59DnYshIQoGPZ58RYpIiKl09kD8NEN4OYFo76FinWsrkjKGPX4Sp54utm5r0c9AGYs3U9CchY7tfV8AupfB9c8WYzViYhIqXXhMHx8I8SeBq9A8Cx/m0ZJ0VPwlTwb2qEW1QK9+DsygXnrj2beqFI9s6e3WoviLU5EREqfyOPw0Y3mWvDBDWHEYvAJsroqKYMUfCXPvNztPNirPgBvLTtAbGJKzi9KSSriqkREpFSKPmX29F48AkFXwchvwDfY6qqkjFLwlXwZ2KYGtSv5cC42iQ9XH8q6YfxF+OExeLeb1mAUEZH0Ys/BxzfBuQMQWBNGfAP+Va2uSsowBV/JF3e7jYd6NwDg3d//IjIui1Brs8POr+DMHtg8p/gKFBGRki3+Isy9Gc7sBv9qZk9vhZpWVyVlnIKv5NsNLavToIof0QkpzFp5MPNGnv4Q/rh5vOIlSIwuvgJFRKRkSoyGeQPh5DbwCTZ7eoOusroqKQcUfCXf7DaDh69tCMCHqw9zNiYx84ZtRpl/ocWegTUzi69AEREpeZLiYP5giNgI3hVhxNcQ0sDqqqScUPCVArmuaRVa1AgkLimVt5Zl0etrd4deT5vHa2ZAzOniK1BEREqO5ARYMBSOrDaXKxv+FVRtZnVVUo4o+EqBGIbBI33MXt9P1h/h78j4zBs2uRlC20ByrDnkQUREyp+UeIi/AO6+MOxLCL3a6oqknFHwlQLrVj+Y9nWDSEpxMH3JgcwbGQZc+1/zePMcOJdF77CIiJRdl4Y2jPwGanWwuhophxR8pcAMw+DR6xrSs2EIw7LawhigTleo3wccKbDkv8VXoIiIWMfhgIPLLj/3rgA12lpWjpRvCr5SKNrVCeLD0e1pFhqYfcPezwIG7FoMEZuLoTIREbGM0wnfP2QuW7b2TaurEVHwlaLhdDozv1ClKbS83Tz+9WnzL0URESm7fCoBBvhVsboSEQVfKVxnohN5avEOHlzwZ9aNev4b7J5wZBXs/7XYahMRkWJmGOaqPveshOYDra5GRMFXCtfFuCQ+WX+Eb7ee4MDpmMwbVagJHcaZxzu+LL7iRESkeGz/EpLTrPJTtbl1tYik4WZ1AVK21K/iz6PXNaR1zYqEVfbLumG3h6F6K2gyoNhqExGRYrB6Ovz6FNTpBncsMtdyFykhFHyl0N3XIyznRt4VodmtRV+MiIgUnw3vmaEX4KpwhV4pcTTUQYrUxbikrCe6XZIYA0fXFU9BIiJSNP6YCz88Yh53mwTdH7W2HpFMKPhKkZmxZD+d/7eU3/efzbrR2QMwvTXMHwRx54uvOBERKTzbv4RvxpvHHe+Ha56yth6RLCj4SpG5GJ9MXFIqr/yyN+te36C64BsC3kEQeax4CxQRkYLb9Q18dTfghLZ3wnUvmKs5iJRACr5SZO7tUQ8fDzvbIiL5eeepzBvZ7HD7p3D/BqjWsngLFBGRgtn3C3x5JzhToeVQ6PeKQq+UaAq+UmSC/Ty5s0tdAF75ZS+pjix6fSvWBjePYqxMREQK7K/l8NlwcCRD01vgpplgU6yQkk2/Q6VIje1+FQFebuw/HcM3W49n3zg12ZwRfGpX8RQnIiL5c2QtfHo7pCZCw+vhllnmN3giJZyCrxSpQG93xoXXA+C1X/eTnOrIuvHPT5gzgn97ppiqExGRLEVGwIk/Mz62fgpzb4HkOKjXC277UMuWSamhdXylyI3uUocPVx/i6Pk4vtgUwdAOtTJv2GEcbJoN+3+BQyuhbrfiLVREREwpiTCrJ8SezrqNzR1unQ1unsVXl0gBqcdXipyPh5trU4sZS/eTkJyaecNK9aDNKPP416chp/V/RUSkaNg9IDCUrGOCAVWagHeFYixKpOAUfKVYDO1Qi2qBXvwdmcC89Uezbhj+OLj7wok/YNfiYqtPRETSMAy45kkgq+FpTuj1tFZwkFJHwVeKhZe7nQd71QfgrWUHiE1MybyhX2Xo/M8i6Ev+a054ExGR4levF1RvDcYVUcGwm+fr9bKmLpECUPCVYjOwTQ1qV/LhXGwSc9Yczrph5wfMTS3O/wWb5xRXeSIiktalXl/nFb2+zlTzvHp7pRRS8JVi42638VDvBgD8vPNk1ru5efqbQx4AVrwEidHFVKGIiKTj6vX9Z6ky9fZKKafgK8XqhpbVeWNIKxbe2xkju96CNqMg6CqIPQNrZhZbfSIigjnMbNsX5vE1T5q9vKDeXin1tJyZFCu7zeCmVqG5aOgOne6H7yfB6tehVkfwrpi+jW/IP7OORUSk0Dgc8M14c73eE1vguhfMXt4TW9TbK6Wegq9YJinFwfbjF2lTOyjjxZREWP6/f44TYO7NGdv4VYaJO7SGpIhIYfrtGTP0Gna4Ktzs3e31DPz4uPmrenulFFPwFUuciU5kwFurOR2dyIpHe1At0Dt9A7sHBNaA2LNAZmOBbRAQarYTEZHCsWYGrJluHt80ExpcZx7X6wkPbLCuLpFCojG+YolgPw+qV/Am0NudQ2djMzZwrSGZ1SYWDo0zExEpTFsXwC9Pmse9/wOthlpbj0gRUI+vWMIwDF4d1JJKvp54e9gzb3RpNvHf2y5PrADz67dqLTTOTESksOz/Fb6+3zzu9AB0mWBtPSJFRD2+YpkaFX2yDr2QZg3JK7Y4dqZCnW7q7RURKQwRm+DzEeBIgRaD4drn9PerlFkKvmI5h8PJ138e58DpTNbrvXINSf75yzjuXLHVJyJSZp3ZC/MGQnIchPWGm94Em6KBlF363S2We/GH3UxY8CfTft6X8WKGXl8ntB4BXR++3ObULlj+EsSdL5Z6RUTKhMjjMPcWiL8AoW3gto/MpSRFyjAFX7Hc4HY1MQz4aedJtkVczNjgUq8vmL/eOB2Cwy5fX/UqLH8RXm8OPz8BUX8XS90iIqVW3Hn45FaIioBK9WHoF+DpZ3VVIkVOwVcsV7+KPwP+2dRi2i9Z9Pr2egaCG2a+hmSj66FKc0iKgbUz4Y0W5uLr5w4WQ/UiIqXQ8T/g3H7wrwZ3fAW+layuSKRYGE6nM6v1ogSIiooiMDCQyMhIAgICrC6nzDp6Lo5rXllOisPJ5+M60b5uJptaZMfpNGclr3oVjq41zxk2aHITdH0IqrUs/KJFREqzA0vM4FulidWViBRYbvOaenylRKhVyYdB7WoCMO3nveT55zHDgAZ94M6fYPRPUP86cDpg5yJ4t7v5ld7h1WZAFhEpj5zO9HMhwnop9Eq5o+ArJcb4a8LwcLOx4fB5ft9/Nv83qt0Jhn0O96yGZgPNnt8Dv8GcfvDBdbD3RwVgESl/lvwHZoXD2QNWVyJiGQVfKTGqBXpzR8faALzySz56fa9UtRkMnA3jN0Ob0eb2xsfWw7q3tEaliJQvCVGw6xu4eBQiNlpdjYhl8hx8e/TogWEYeXosX7483T0cDge7du1izpw53HfffbRr1w5PT88s2+ckLi6OqVOn0q5dO4KCgvD19aVRo0ZMmjSJI0eO5PUjioXu61EPXw872yIi+XnnqcK5adBVcMPrMHE7dH4Quj96+VrMGdj4PiQnFM57iYiURF4BcOfPcNNb0Op2q6sRsUyRb1lss9moX79+unNz585l1KhRhXL/AwcO0K9fP/bv35/u/N69e9m7dy/vv/8+8+bNo3///oXyflK0Kvl5cmfXusxYeoBXftnLtU2qYLcVUu+sf1Xo81z6c+vfhpWvwL5fzOERIiJlSdx58PlnsrBfCLQeZm09IhbLc/D98MMPiY2NzbbNrl27GDx4MAC9evUiNDQ03fW0X2G7u7vTvHlzkpOT2b59e55qiY6O5vrrr3eF3rFjxzJkyBC8vb1ZtmwZU6ZMISoqisGDB7N69WpatWqVp/uLNcZ0u4qP1hxm/+kYvtl6nAGtaxTdm1WsCwE14OoRl88lRps9wH4hRfe+IiJFLWIzzB0A170AV99hdTUiJUKeg2/dunVzbDN37lzX8YgRIzJcb9KkCdOnT6ddu3a0atUKLy8vnn322TwH35dffpl9+8x1X6dOncqjj17+CrtTp0706NGD8PBw4uLimDhxYp6HUIg1Ar3dGRdej5d/3strv+6nf4vquNuLaDj61XdAyyFptkQGNsyCFVPNMNx5PFSoVTTvLSJSVM7uh/m3QWIk7FgIrYZpK2IRimBym8PhYN68eQD4+flxyy23ZGjTvn17xo8fT8eOHfHy8srX+yQnJzN9+nQAGjduzKRJkzK06dy5M3fddRcAK1asYONGDegvLUZ3qUNoBW+uaVSZxBRH0b6Z3T39PwjHNkBKghmA32gFX42D07uLtgYRkcIS9be5FXHcOXO3y8FzFXpF/lHofxKWLFnC8ePHARg4cCA+Pj6F/RYALFu2jMjISABGjhyJLYs/1GnHEi9atKhIapHC5+PhxtJHwnn2xqb4eRb5UPT0bl8AI76Bq3qAMxW2LYC3OsKnQyFiU/HWIiKSF/EX4ZNbIPIoBNX7Zytif6urEikxCj1RfPzxx67jzIY5FJZVq1a5jsPDw7Ns17ZtW3x8fIiLi2P16tVFVo8UvnMxSZyPTcryeiU/D6oFehf+GxsGXBVuPo5vhlWvwe7vYO/35qNON+j2MFzVU8uiiUjJkRwPnw6B07vAr4q5FbHmKoikU6jBNyYmxtWrWrt2bXr06FGYt09n165druNGjRpl2c7NzY2wsDC2bdvG7t36urq0SExJ5caZqzgbk3XwDfHzZNX/9cTTzZ5lmwILbQODP4Eze2H1G7DtMzi80nxUa2Vuh9z4BrAVYQ0iIjlJTYEv7zS3bPcMgOFfQcU6VlclUuIU6lCHhQsXulZ8GD58OEYR9oZFREQA4OvrS4UKFbJtW7OmuRXumTNnSExMzLZtYmIiUVFR6R5S/DzsNqpX8M6yQ9UwoFoFLzyKatLblUIaws1vwYN/Qod7wM0b/v4TvhhpzpoWEbGK0wnfTYS9P4Dd0xyuVbWZ1VWJlEiFmhqKa5gDmEuZgTmBLie+vr6u45iYmGzbTpkyhcDAQNfjUmiW4mUYBpP6NMxyZ2GnEyb1aVikP1xlqkJN6PsSPLTD3AjDKxAaXHf5emoKJGW/3J+ISKFa+jxsmWtuzz7wA6jTxeqKREqsQgu+ERERruXCOnbsSIMGDQrr1plKSDB32vLw8Mixraenp+s4Pj4+27aTJ08mMjLS9Th27FjBCpV8614/mBY1Arly/wqbAS1qBNK9frA1hQH4BsM1T8LEHdD2zsvndy2G15rBurctK01EypH178LKaeZx/9egsTZrEslOoQXfTz75BIfDXHZq5MiRhXXbLF1aBi0pKesxoJekHd7g7Z39ZChPT08CAgLSPcQal3p9HVf0+jqccFfXusXf25sZrwBwT/N7asdXEH8eErP/ZkFEpMD+3go/Pm4e93wS2oyytByR0qDQgu+lTSs8PT1du7YVJX9/c3mWnIYuAOl2msvN0AgpOa7s9b0Udaf+tIcDp0tguBz0Mdw6G9qPuXxu3y/wzXg4d9C6ukSk7KnaAno/A+3vhu6PWF2NSKlQKMF306ZNrlUW+vfvT8WKFQvjttmqUcPcxjY2NpaLFy9m2/bScIWQkJB0wx6k5Luy19cJVPH35PjFBG59ew0bDp23tL4M7G7QfCB4//NnwOmE31+GPz6GmW3hi1FmL42ISEEZhrmyTN+pWlpRJJcKJfimndRWHMMcwNz2+JI9e/Zk2S4lJYWDB82etsaNGxd5XVL4LvX6gjm29/sHu9K6VgUi45MZPns932/72+IKs2EY0Oc5qH8dOB2wcxG82x0+uRUOrybL2XsiIpk5dxC+GA0JaVYcUugVybUCB9/k5GQWLFgAmD2qffv2LXBRudG1a1fX8YoVK7Jst2nTJtdQhy5dNNO1NDIMg8eua0RYZT8eu64Rwf5ezB/TkT5NqpCU4uD++X/w3u9/4SypIbJWRxj2OdyzGpoNNGdeH/gN5vSDD66DvT8qAItIzhwO+HwE7PwKfvo/q6sRKZUKHHx//PFHzpw5A8DQoUNxcyue7WV79OhBYKDZC/jRRx9lGXrmzJnjOh4wQOutllZd6wfz28PhdP1nJQdvDztvD2/DqM51AHjhh93859tdpF45E64kqdoMBs6G8ZuhzWiwe8Cx9eZOS293hm2fm8uhiYhkxmaDm2ZCzQ7Q+1mrqxEplQocfItz7d60PDw8ePDBBwHYvXs306ZNy9Bm7dq1zJ49GzC3NW7Xrl2x1SdFz24zeOaGJjzRzxzCMmfNYe6bt5mE5FSLK8tB0FVww+swcTt0mQAe/uYWo1+NhRlXw+aPrK5QREqq6q3hzp/Br7LVlYiUSoazAN8PX7hwgWrVqpGYmEizZs3Yvn17rl+bticWYPHixXz99dcAPP744+m2IQ4LC0s3tOGS6Oho2rZty759+wC4++67GTJkCN7e3ixbtowXX3yRmJgYvL29WbNmDa1atcrzZ4yKiiIwMJDIyEgtbVaCfbftBA9/tpWkVAeta1Vg9sh2BPnmvMZziRB/ETa+Z679G3cOWt9h9uqIiDhSzV3Zrh4JNdpaXY1IiZXbvFag4PvOO+9w7733AjB16lQeffTRXL82L2uwjhw5MkNQvuTAgQP069eP/fv3Z3o9ICCAefPm0b9//hb1VvAtPTYcOs/YjzcRGZ9MnUo+zBndnjrBvjm/sKRIioMtn0BYL6hUzzx3aifsWAgd7gW/EGvrE5Hi5XTCdw/B5g/NlWImbDPXDheRDHKb1wo0IPfS2r12u51hw4YV5Fb5FhYWxpYtW3jzzTf54osvOHDgAElJSdSsWZN+/foxYcIEateubUltUrza1w1i4b2dGPnBRk5GJXAhLok6lKLg6+EDHe5Of27lq7DjS7h4DG597/L5yAiIPZv1vXxDIDC0aOoUkeKx/H9m6MWAG95Q6BUpBAXq8S0P1ONb+pyOTmD/qRi6hFm4pXFh2fM9rHwF+r8O1VqY5879Be/3MneIy4pfZXM7ZTetWy1SKm18H76fZB5f/yq0u8vaekRKuGLp8RUpiSr7e1HZ38v1fHtEJFsjLjK8Yyns+W90vflIa9Vr2YdebBAQaq4aISKlz87F8P0/O7H1mKzQK1KIFHylTDsXk8joORs5G5OIh93GoHY1rS6pYJxOSI7LoZEDrnlSi9qLlEZ/rTBXeMEJbe+E8MetrkikTCmUndtESqogXw9Gda5N42oB9G1e1epyCs4wzLWA79sA3pUybxMQCgE1tSmGSGnz91ZYMAxSk6DxjdBvmn6AFSlkGuObA43xLRsSklPxcrcD4HQ6SUh24O1ht7iqAjrwm7n1cVYq1Ib610L9PnBVD433FSnJzv8Fs6+D2NNQpxsM+xLcvXJ+nYgAuc9r6vGVcuFS6AWY9ftf3DhzFREXchoyUMLV62UuZm/889mMf8b21u1hju+9eMScIPPpEEiKvfy6xGgrqhWRrMSchrkDzNBbtTkMmafQK1JEFHylXIlJTGHOmsPsPx3DLW+tYcfxSKtLyj/DMMfyOv/Zqc7pgBunw8iv4bFDcPsCc4xgk5vAJ+jy6+bdBtNbw9F11tQtIpclRJnf3Fw4DBXrwLCF4BVodVUiZZaCr5Qrfp5uLLy3Mw2r+HM6OpHB765lxb4zVpeVf5d6fcH8tV4v89jTDxr2hf6vwW1zLrdPioUTW8yvVQOqXz6//1fY8J75j6+IFB83T3Mbc98QGP4V+FexuiKRMk1jfHOgMb5lU2R8MvfM3czav85htxlMGdC89K74cHAZ/Pg49H0J6vXMuX1CFERsgLDel8/NHwz7fjKPgxuY44LrXwu1OmlssEhRc6Sam9JULIVLLoqUEMWyZXF5oOBbdiWlOHjsy60s/vMEABN61Wdi7/p52k67zFj3Nuz+1hz+cGnoBICHH9QN/2eS3LUQWMO6GkXKCqcTdn8DjW4Am754FSkMCr6FRMG3bHM6nbz8817eWn4QgNva1ODFW5rjbi+n/xjFX4S/lptDHw78CjGn0l+v3OTyShE1O4Dd3YoqRUq3FVNh2QvQYggMeEdLlokUAu3cJpILhmHw2L8aEVrRm6cW7+CLzRGcjErgrWFX4+9VDkOddwVoerP5cDjg1HbY/4sZhCM2wuld5mP1GzB4HjTub77O4VDPlUhuVagNNjcIbaPQK1LM1OObA/X4lh9L95zi/nlbiE9OpXG1AOaMbkeVAC0p5BJ3Hg4uNUPwod/hgQ3g6W9eW/Yi7PkBuk6E5gMtLVOkVDh3ECrVs7oKkTJD6/iK5NE1jarw2biOBPt5sPvvKAa+s4aE5NScX1he+ASZofaWd+HhXZdDL5i9wqe2mztOXXLxKPw531yjVKS8O7YBok9efq7QK2IJDXUQSaNFjQp8dW8XRs3ZwN3drkq38YWkceXXs8O+hANLIKzX5XO7voFfnjCPq7W6vFJEaBuw6b+rlCN/bzPX6vWuCKO+hwqldAUZkTJAQx1yoKEO5VPaLY4B4pNSS/8Wx8Xtz09h/Tvw95/pz3sHmQE57FrzV99gS8oTKRbnD8EH15kTRWt3Mdfq1a5sIoVOqzoUEgVfOReTyMB31jKobU3uCb+qfC53VhDRp+DAb+YqEQeWQmLa3fIMswe4fh+o3xuqtdYkOSk7Ys7AB33MDWOqNDN7e70rWF2VSJmk4FtIFHzlozWHeeabndSo6M0PE7oRUB5XeygsqSnm5hn7fzUfp7anv95lIlz7H0tKEylUidEw53r4eytUqAV3/gIB1ayuSqTM0nJmIoVkZOc6GAZ0rldJobeg7G5Qu7P56P0MRJ0we4P3/wIHl0Pd7pfbHl4FS/4LzW+D9mMtK1kkz1ISYcEwM/T6VILhixR6RUoIBV+RXBjRqU6650v3nKJFjQoE+2k73wIJqA5XjzAfKUlgpBnmsO8nOLYegtLMfnc4YM93ZkDO7CvjyAiIPZv1+/mGQGBooZUvkoHDAYvugUMrwN0Xhn0BwWFWVyUi/1DwFcmjNQfOcvfHm6lewZuP7mxP3WBfq0sqG9w80j/vcK8ZekMaXT53cht8fgcYdqjVEcJ6m+ODqzQ1l1Kb1RNis1k+za8yTNwBbvqBRYqA0wk/PQ47vwKbOwz5xBzDLiIlhoKvSB5VCfSiWgUvjp6P45a3VvP+yHa0qV3R6rLKnsBQaDs6/bn48xDcAM7ugyOrzceS/4B/dTMEe/hCrAFkNnXBBgGhYPfI5JpIIVj5CmyYZR4PeAfqXWNtPSKSgSa35UCT2yQzZ6ITueujjWyLiMTTzcYbQ1rzr2ZVrS6r/Lhw+PIEuUO/Q0p87l43fKEZkEUK2+aP4NsHzeN/vQQd77G2HpFyRqs6FBIFX8lKXFIK4+dvYcme0xgGPNO/CaO61LW6rPInOR4OrzaXS9v7E1w8nLGNYYdqLWDssoybb4gUVGoKvNfTHIrT9WFz4qaIFCsF30Ki4CvZSUl18Mw3O5m3/igAY7vVZXLfxthsCleW+WMufPNAxvPq7ZWiFH8RtsyFTg/ohysRC+Q2r2mleJECcLPbeP7mZjz2r4YAvLfyEOMXbCEhOdXiysqx1sOhemuzlxfMX6u3hnq9IPacOetepDAkRl8+9q4Anccr9IqUcAq+IgVkGAb39QjjjSGtcLcbfL/tb0bM3sDFuCSrSyufDAOueRKc//zw4Uw1n6cmwdybYf5tEJPNyg8iuXHhCMxsD2vfsroSEckDBV+RQnJTq1A+urM9/l5ubDh8nlvfXsOx83FWl1U+1etl9vLC5d7eE3+aq0Ec/wMc6pGXAtr5FUSfMIc3JOdycqWIWE7BV6QQda4XzJf3dKZ6oBcHz8Ty046TVpdUPhkG9HoGghuavxoG1OoAdy+H2z5Mv4tWaoplZUop1mUi9H3ZHDvu7m11NSKSS5rclgNNbpP8OBmZwMI/IrivRz0MjfkruXZ/C8tfglvfh8qNcm4v5VtKEuDUBigiJZAmt4lYqGqgF/f3DHOF3tjEFH7Y/rfFVUk6DgcseQ5ObYdZPWDTB+bOWyKZcThg8b0wf1D6SW0iUqoo+IoUsZRUB+M/3cJ98/7g7eUHrS5HLrHZYOS35u5aKfHw3UPw2XCIO291ZVLSOJ3w879hx5dweBX8vc3qikQknxR8RYqY3WbQLDQQL3cbHa4KsrocScu/CgxbCNe9CDZ32PMdvN0Z/lphdWVSkqx6Dda/bR7f/DbU6WJtPSKSbxrjmwON8ZXCcvxiPKEVLk+CcTqdGv9bkvy9Fb68C87tBwzoOhF6PgF2d6srEytt+QS+vt88vu5F6HS/tfWISKY0xlekhEkbenccj2TgO2v5O1LLIJUY1VrCuBXQZhTgNHv5ZveBcxqeUm7t/RG+edA87jJBoVekDFCPbw7U4yuFzel0csPMVew4HkXVAC/m3NmORlX1e6tE2fW1GXgSLoKHH/R7GVrerl25yqLICIg9m/H8ye3w/cPmxicth8LNb+n/v0gJltu8puCbAwVfKQoRF+IY9eFGDpyOwd/TjXfuaEOXsGCry5K0IiPgq3FwZJX5vM0ouOENS0uSQpaSCK81g9hsdvKze8Bjh8DTr/jqEpE801AHkRKsRkUfFt7TmfZ1g4hOTGHUhxv46o8Iq8uStAJrwMhv4JqnwLBDrc5WVySFze4BgaFk+09h5cbg4VtsJYlI0VLwFbFIoI87c+9qT/8W1UhOdfLw51t5c9kB9CVMCWKzQ/dH4IGN0HLw5fPnDmrHt7LAMOCaJwFH1m16Pa0hDiJliIKviIU83exMH9Kacd2vAuDln/fy70U7SEnN5h9iKX6V6l0+jj0HH/aDOddD9CnrapLCUa8XVG9t9uqnZdjM8/V6WVOXiBQJBV8Ri9lsBpP7Nea/NzXFMODTDUe5e+5mYhPVo1gind4FSbEQfwE8/a2uRgoiIcrcsOSaJ8GZmv6a02GeV2+vSJmi4CtSQozoVId3hrfB083G0j2nGTJrHWeiE60uS65UtxvcuwoGfQwePuY5h8MMw1J6bP8SXm8Oy57P2Otr2NXbK1JGKfiKlCDXNa3Kp3d3JMjXg+3HIxnw1mpORiZYXZZcqWIdqNzo8vO1M+CdbnD8D8tKkjwKqG4uV3dsAzhS0/f6OlPV2ytSRin4ipQwV9eqyMJ7O1O7kg+NqgYQ4u9pdUmSnZRE2PQhnD8Is6+FVa+bPcBScsSdhyXPwYqpl8/V7gzDv4Jxv4Pd7XKvL6i3V6QM0zq+OdA6vmKVczGJ+Hi44e1hfv2qLY5LsPgL8O0Ec+MLgLrhMOBdCKhmbV3lXexZWDMDNr4PSTHg7gsP7QCfoMzbH1wGPz4OfV+Cej2Lt1YRKRBtYFFIFHylJHA6nTy+cBsNqvgzpttVVpcjmXE6YctcMzglx4F3ENz0JjTqZ3Vl5U/MaVj9Bmz6wPx/AVC1BYQ/Dg37gU1fdoqUNbnNa27FWJOI5NPyvWf4fFMENgO6NwihQRWtJlDiGAZcPQJqdYIv74ST22DB7dD2Lujz/OWJcFJ0ov6GNdPNwJvyz9j46q3NwNvgXxqzKyLq8c2JenylJHA6nby38i/8PN0Z2qEWJy7Gcz42Kcv2lfw8qBboXYwVSjopibD0OfNrdoCQRnDrbKjazNq6yqrI47D6ddj8EaT+sxJKaFvo8X8Q1luBV6Qc0FCHQqLgKyVNYkoqXf63lLMxWQffED9PVv1fTzzd7Fm2kWJwcCksugdiToHdE679L3QYpyBWWC4eg1WvmUNMUv/581Czg9nDW+8a/XcWKUdym9c00EmklPGw26js75XldcOAahW88LDrj7fl6l0D964xv2ZPTYSfHofvHrK6qrLj8ErYNNsMvbW7wIhv4M6fIayXQq+IZEr/MoqUMoZhMLJz7SyvO50wqU9DrQBRUvgGw+0LoN80c1WBlrdbXVHpdf4vOLTy8vPmg6DFEBj1PYz+Aa4KV+AVkWwp+IqUQoPa1qRxtYwT3GwGtKgRSPf6wRZUJVkyDGg/1lxKq1aHy+ePrjfHA0vODi6FGW1h8b2Q8s+wBrsb3PIu1OlqbW0iUmoo+IqUQoZh8H99G2c473BCk2r+JKVqA4USKe36saf3wMc3wfu9IPacdTWVZMlpdi2s1cnsPQ9pBPHnratJREo1BV+RUqp7/WBa1AjEdsU3uws2RtDntd/5acdJNHe1BIs5Be7e4BsC3hWtrqZkObULvhgNs3qY2wmD+d/qvnUw/Evwr2ppeSJSemlVhxxoVQcpyVbsO8PIDza4nt/VtS7fbD3BmWjz6/MOdYN4qn8TmoUGWlWiZCfqb7DZwa+y+Twp1hz6kNXOYmXdyR3w+9TLO+ABjPoB6nSxriYRKRW0qoNIOXCp1xfMsb1PXt+Y5Y/0YPw1YXi62Vh/6Dw3zFzFlB92W1ypZCqg2uXQC+aub293ST+Bqzz4eyssGAbvdLkcepvcBPesUugVkUKl4CtSihmGwWPXNSKssh+PXdcIwzDw9XRjUp+GLH2kBze2rI7TCbUr+VpdquQkIRKOroXoE/DRDbDkv5CabHVVRev4HzB/CLzbHfZ8BxjQ9Ba4dy0M+hiqNre6QhEpYzTUIQca6iCl3baIizStHoj9n8HAS3afIiYxhRtbVteSZyVNYgz89H/mhgwAoW3g1vch6Cpr6ypsEZtgxUuw/xfzuWGDZgOh+yMQ0tDa2kSkVMptXnMrxppExAItalRwHSckp/L01zs5fjGe2MRUhnaoZV1hkpGnH9w009yA4dsJcHwzvNMNrn8FWg6xurqCO3cQfnjEXJoMwLBDi0HQbRIE17e2NhEpFzTUQaScub19TeqF+DKgdajrnMOhL35KlKYD4J7VUKszJMXAonGwcKw5HKI08/CFw6vNwNt6ODywEQa8o9ArIsVGQx1yoKEOUhalOpyuoQ+pDieD3l1L53qVuCe8Hr6e+iKoxHCkwspXYPn/wJkKFWqbQx9qtre6spw5nXDod/hrOfR+5vL5HQvNIRwV61hVmYiUQbnNawq+OVDwlbLu112nGPvxJgAq+3vyyHUNGXh1DWxXLhAs1jm6Hr4aAxePmr2lPSZDt4fNpdBKqsjj8HpzM7CPWQo12lhdkYiUYUW2nFmPHj0wDCNPj+XLl2d5vx9//JEBAwZQo0YNPD09qVGjBgMGDODHH3/MdU0pKSm88847dOvWjZCQELy9valXrx7jxo1j586def2IIuVK78aVeWf41dQK8uF0dCKPfbmNG99cxfq/tJtYiVGrg7m0V7NbzSC57Hn4+Qmrq0rP6YQTf15+HhgKbUZC+7shoLplZYmIpJXnHt8ePXqwYsWKXLe32WwcPXqU0NDQdOcdDgd33303s2fPzvK1Y8aM4d1338Vmyzqfnz17ln79+rFx48ZMr3t6ejJz5kzGjBmT65rTUo+vlBeJKal8tOYwM5YcIDoxBYB/Na3K5H6NtBxaSeF0wtYF5lJnd/4EFWtbXZFZ076fzFUaTvwJ962Fyo0vX9PKISJSDIpsqMOhQ4eIjY3Nts2uXbsYPHgwANdeey2//PJLhjaTJ0/mf//7HwCtW7fmscceo169ehw8eJCpU6eyZcsWV7sXX3wx0/dJTU2lR48erFq1CoBbbrmFsWPHEhQUxPr163n++ec5ffo0NpuN7777jr59++blowIKvlL+nItJ5LXf9jF//VEcTvCw2xjVpQ4PXBNGgJe71eUJmLu7uXlefr5zEdTvY04eKy4OB+z9wQy8J7eZ59y84cYZ0OK24qtDRASLx/g+/vjjTJ06FYC5c+cyfPjwdNf37dtH06ZNSUlJoW3btvz+++94e3u7rsfFxREeHs6mTZtwc3Nj9+7dhIWFZXifDz74gLvuuguA++67jzfffDPd9QMHDtCmTRuioqIICwtj9+7duLnlbeKOgq+UV3tPRvP897tYuf8sAJV8PXjo2gYMaVcTN7sWhCkxDvwGn9wKlerD3cvNJdGKksMBu7+B31+GUzvMc+6+0H4sdHoA/EKK9v1FRDJh2ZbFDoeDefPmAeDn58ctt9ySoc3rr79OSor5VeqMGTPShV4AHx8fZsyYAZjjd1977bVM32vatGkABAUF8fLLL2e4HhYWxuTJkwEzBC9atCifn0qk/GlY1Z+P72zPh6PaUS/El3OxSTy5eAc3v7WalFSH1eXJJW7e4F8drupRtKHXkWquyPB2Z/hipBl6PfzNNXgnbodr/6PQKyIlXqEH3yVLlnD8+HEABg4ciI+PT7rrTqeTr78292Jv1KgRHTt2zPQ+HTt2pGFDcwefr7/+mis7pvft28fu3bsBGDRoUIb3uWTUqFGuYwVfkbwxDIOejSrz08Tu/OfGplTwcafTVZXU41uS1OkC966GPs9dPhf1N0SfLJz7p6bAts/hrY7w5Z1wZjd4BkL44zBxG/R6GnwrFc57iYgUsUJfsPPjjz92HY8YMSLD9UOHDnHixAkAwsPDs71XeHg4e/fu5fjx4xw+fJi6deu6rl0a15vTfapWrUqDBg3Yt28fq1evzvXnEJHL3O02Rnauw82tQkk713R7RCQL/4hgQq/6VPT1sK7A8s4n6PKxIxUWjjED6k1vQcN/5f++sedg9rVw/qD53KsCdLrfXKnBu0JBKhYRsUShdtvExMS4elVr165Njx49MrTZtWuX67hRo0bZ3i/t9Uu9uwW5z7Fjx3KcmCciWQv0ccf/nwluTqeT577bxZw1h5n68x6LKxOXuHPmDm9x5+DTwfDDo5CckPvXp/12zbcS+FcF74pwzVPmkIbwxxR6RaTUKtQe34ULF7qC5fDhwzEyWcYmIiLCdVyjRo1s71ezZk3X8bFjxwp8H6fTSUREhGsIRWYSExNJTEx0PY+Kisr23iLllWEYTOhdn2m/7GX8NZe3nE1ITsXTzZbpn38pBn6VYcxvsOQ/sO4t2DALDq+C6140A2xWfILg4FJYPwtGfnt5+MJNb4JvMHj6F0/9IiJFqFCDb07DHACio6Ndx35+2U/E8PW9vDRPTExMkdznSlOmTOE///lPtm1ExNQlLJguYcHpzk36YisX45J48vomNK6mlVAs4e4F/5oC9a6BxffC6V0w9+bsX+NXGXwrw+mdsPF96PG4eT6obvavExEpRQptqENERIRrh7aOHTvSoEGDTNslJFz+ys3DI/sxgZ6el9epjI+PL5L7XGny5MlERka6Hlf2NItI1v6OjOfXXadYfeAc109fyeSvtnEmOjHnF0rRqH8t3LsG6vXKoaENAkKh97Pwr/9B5/HFUZ2ISLErtOD7ySef4HCYSxyNHDkyy3ZeXl6u46SkpGzvmXbIwZVLnhXWfa7k6elJQEBAuoeI5E61QG+WPBzO9S2q4XDCpxuO0XPact5efpCE5FSryyuf/CrDsC+hzZ3ZNHLANU+aQbnjveCR+So5IiKlXaEF37lz5wJmcLy0a1tm/P0vjxPLadhB2oloVw5nKKz7iEjhqhnkw5tDr+aLezrRokYgMYkpvPTTHnq/uoLvt/2dYWlCKQY2G/R/FUIymQhsGFC9dS56hUVESr9CCb6bNm1yrbLQv39/KlbMegJF2oloaSeoZSbtMIO0E93yex/DMHKcCCcihaNdnSAW39eFVwe1pGqAFxEX4rl//h8Menct2yIuWl1e+WMYcN0LGc87nWZvryYjikg5UCjBN+2ktuyGOQA0adLEdbxnT/ZLIKW93rhx4wLfp2bNmukmuolI0bLZDG65ugZLHwlnYu/6eLvb2Xj4AjfOXM3Dn/3J35HZj7mXQlavl9m7a9jN54Zdvb0iUq4UOPgmJyezYMECAEJCQujbt2+27evWrUv16tUBWLFiRbZtf//9dwBCQ0OpU6dOumtdu3Z1HWd3n5MnT7Jv3z4AunTpku37iUjR8PFwY2LvBix9JJxbWocC8NWW41wzbQURF+Isrq4cMQyzd9f5z3hrZ6p6e0WkXClw8P3xxx85c+YMAEOHDsXNLfsV0gzD4KabbgLMnth169Zl2m7dunWuntqbbropw5qgDRo0cPUCf/7558TFZf6P55w5c1zHAwYMyPkDiUiRqRbozauDW/H1/V1oW7sinetVokZFTaQqVpd6fUG9vSJS7hQ4+OZm7d4rTZw4Ebvd/Kpt/PjxGZYYi4+PZ/x4czkdNzc3Jk6cmOl9HnnkEQDOnz/PY489luH6wYMHmTJlCgBhYWEKviIlRMuaFfjink68PqSV69zp6ASGvreOzUfOW1dYeWAY0OsZCG5o/qreXhEpRwoUfC9cuMB3330HQLNmzbj66qtz9boGDRrw6KOPAubEuC5duvDZZ5+xadMmPvvsM7p06cKmTZsAePTRR6lfv36m9xk5cqRr+MKbb77JwIED+fnnn9mwYQMzZ86kc+fOREVFYbPZmD59eo690SJSfAzDcG1/DDB9yX7WHDzHc9/t1soPRa1eT3hgg/mriEg5UqAk+Nlnn7nWyM1tb+8lL7zwAqdPn+aDDz5gy5YtDBkyJEObu+66i+effz7Le9jtdhYvXky/fv3YuHEjCxcuZOHChenaeHp6MnPmzBzHHouItSb0akCqw8nANjVcQ5viklJwOMHPUz+0iohIwRnOAnStdOnShTVr1mC32zl69Khr0lpe/PDDD8yaNYuNGzdy9uxZgoODadeuHePGjct1WE1JSeG9995j/vz57N69m9jYWKpXr06vXr2YMGECTZs2zXNdl0RFRREYGEhkZKQ2sxApZtN+3suCjcd4pE8DbmtbE7tNX8uLiEhGuc1rBQq+5YGCr4g1Uh1Orp++kj0nowFoXC2Ap65vTOewYIsrExGRkia3ea3Qdm4TESlMdpvBNw905an+TQjwcmP331EMfX89Yz7axKGzsTnfQERE5Arq8c2BenxFrHchNonXf9vHJ+uPkupw4m43GNGpDg9eU59AH/ecbyAiImWahjoUEgVfkZLjwOloXvh+N8v2mmuHV/RxZ2LvBgztUAt3u77AEhEprxR8C4mCr0jJs2LfGZ7/bhf7T8cAUC/Elyf7N6FhFX/OxyZl+bpKfh5UC/QurjJFRKSYKPgWEgVfkZIpJdXBpxuP8dqv+1xhN8DLjaiElCxfE+Lnyar/64mnm724yhQRkWKQ27ymxTFFpFRys9u4o2NtbmxZnTeXHWDV/jPYbTZ2nIgksx/nDQOqVfDCQ0MiRETKLQVfESnVAr3d+Xe/xqSkNmT1wXOM/GBDpu2cTpjUp6FrcwwRESl/1PUhImWCm91G9/rBtKgRyJXZ1mZAixqBdK+vNYBFRMozBV8RKTMMw2BSn4YZhjo41NsrIiIo+IpIGXOp1/fS7saXenvtBuw5GWVtcSIiYikFXxEpUy71+jr+6fV1OGFQ25qMm7uZ295ey6r9Z60tUERELKPgKyJlzqVeXzB7e/s3r0az0ECiE1MY9eEGvth0zOIKRUTECgq+IlLmGIbBY9c1IqyyH49d14gKvh58fFd7bmpVnRSHk0e/3Marv+5Dy5iLiJQv2sAiB9rAQqTscDqdvPLLPmYuOwDALVeH8r9bWuDhpj4AEZHSLLd5TX/bi0i5YRgGj1zXkCm3NMduM/jqj+OM+nADkfHJVpcmIiLFQMFXRMqd29vXYvbItvh62Flz8By3vbOGiAtxVpclIiJFTMFXRMqlHg0r8/k9nagS4Mm+UzEMeGsNO45HWl2WiIgUIQVfESm3mlYPZNF9XWhU1Z8z0YkMenctS/ecsrosEREpIgq+IlKuVa/gzef3dKJb/WDiklJZvveM1SWJiEgRcbO6ABERqwV4ufPBqHbMW3eE4R1rW12OiIgUEfX4iogA7nYbo7rUxc1u/rWYnOrg7eUHSUhOtbgyEREpLAq+IiKZeOabnbz00x7unrtZG12IiJQRCr4iIpno36IaFXzcGdGxNoZhWF2OiIgUAo3xFRHJROd6wax8rCf+Xu6uc0kpDu3yJiJSiulvcBGRLKQNvcfOx3HNK8v5acdJCysSEZGCUPAVEcmF2asOEXEhnnvnbWb2qkNWlyMiIvmg4CsikgtPXt+Y4R1r4XTCc9/t4tlvdpLq0KQ3EZHSRMFXRCQX3Ow2nrupGZP7NgJgzprD3PPJZuKTtNyZiEhpoeArIpJLhmEwLrweM4e2xsPNxq+7TjFk1lrORCdaXZqIiOSCgq+ISB71b1Gd+WM6UNHHna0Rkdzy9moOnI6xuiwREcmBgq+ISD60rRPEV/d1oXYlH46dj+fWt9ew/q9zVpclIiLZUPAVEcmnusG+fHVvZ1rXqkBkfDJ3zN7A138et7osERHJgoKviEgBVPLz5NOxHenbrCpJqQ4mLPhTa/2KiJRQCr4iIgXk5W7nzaFXM6ZrXa6uVYEeDUOsLklERDKhLYtFRAqBzWbwZP8mJCSn4uVuB8DhcJKQkoqPh/6qFREpCdTjKyJSiC6FXoBpv+xl4NtrORWVYGFFIiJyiYKviEgROB+bxOebjrHr7yjWHtRqDyIiJYG+fxMRKQJBvh4suq8Ly/ae5ubWoVaXIyIiqMdXRKTI1AzyYUSnOq7nZ2MS+WbrCesKEhEp59TjKyJSDBKSU7nro01sPXaRA6djeKh3fQzDsLosEZFyRT2+IiLFwMNuo2tYJQCmL9nPpC+2kpTisLgqEZHyRcFXRKQY2GwGj17XiCm3NMduM/jqj+OM+nADkfHJVpcmIlJuKPiKiBSj29vXYvbItvh62Flz8By3vbOGiAtxVpclIlIuKPiKiBSzHg0r8/k9nagS4Mm+UzEMeGsNO45HWl2WiEiZp+ArImKBptUDWXRfFxpV9edMdCKD3l3L0j2nrC5LRKRMU/AVEbFI9QrefH5PJ7rVDyYuKZUxH23ik3VHrC5LRKTMUvAVEbFQgJc7H4xqx21tauBwwpOLdzDlx904HE6rSxMRKXMUfEVELOZutzF1YAsmXdsAgCW7TxOblGJxVSIiZY82sBARKQEMw2B8r/rUDvaldc0K+Hu5W12SiEiZox5fEZES5MaW1akZ5ON6vnBzBEfOxVpYkYhI2aHgKyJSQi3dc4pHvtzKgLfWcDIywepyRERKPQ11EBEpoZpVD6Rp9QCah1agSoCn1eWIiJR6Cr4iIiVU5QAvPh/XCQ+7DcMwAEhKceDhpi/rRETyQ397ioiUYD4ebrjZzb+qk1MdjP14E89+s5NULXcmIpJn6vEVESkl1h48x4p9Z1ix7wzHL8YzfUhrvD3sVpclIlJqqMdXRKSU6N4ghJlDW+PhZuPXXacYMmstZ6ITrS5LRKTUUPAVESlF+reozvwxHajo487WiEhueXs1B07HWF2WiEipoOArIlLKtK0TxFf3daF2JR+OnY/n1rfXsP6vc1aXJSJS4in4ioiUQnWDffnq3s60rlWByPhk7pi9ga//PG51WSIiJZqCr4hIKVXJz5NPx3akb7OqJKU6mLDgT95afgCnUys+iIhkplCC79GjR3nmmWdo27YtISEheHl5UbNmTbp168bTTz/Njh07snztoUOHeOihh2jWrBn+/v74+vpSv3597rvvPnbu3JnrGlJSUnjnnXfo1q0bISEheHt7U69ePcaNG5en+4iIlCZe7nbeHHo1Y7rWBWDqT3v596IdpKQ6LK5MRKTkMZwF7BqYMWMGkydPJjY2673kJ0yYwOuvv57h/KxZsxg/fjxJSUmZvs7Dw4NXXnmFBx54INsazp49S79+/di4cWOm1z09PZk5cyZjxozJ9j6ZiYqKIjAwkMjISAICAvL8ehGR4vLRmsP859udOJwwuG1NXhrYwuqSRESKRW7zWoHW8X3++ed56qmnAGjQoAFjx46lXbt2BAYGcu7cObZs2cKiRYuw2TJ2LC9YsIBx48YBEBgYyKRJk7jmmmvw9PRky5YtTJ06lQMHDvDggw9SuXJlBg0alGkNqampDBgwwBV6b7nlFsaOHUtQUBDr16/n+eef5/Tp04wbN47Q0FD69u1bkI8sIlJijexch+oVvHli0XZGd61jdTkiIiVOvnt8lyxZQu/evQEYMWIE77//Pu7u7pm2TUpKwsPDw/U8Li6OunXrcvr0afz8/Fi7di3NmjVL95qoqCi6du3K9u3bqVKlCgcOHMDPzy/DvT/44APuuusuAO677z7efPPNdNcPHDhAmzZtiIqKIiwsjN27d+Pmlvu8rx5fESltEpJT8XK/vLFFXFIKPh7ar0hEyq7c5rV8jfF1OBzce++9ALRs2ZLZs2dnGXqBdKEX4IcffuD06dOAOQziytALEBAQwKuvvgrAqVOnmDNnTqb3njZtGgBBQUG8/PLLGa6HhYUxefJkwAzBixYtyuHTiYiUbmlD74ZD5+n20jK+3nKcHccjs3z8HRlvYcUiIsUjX10Av/zyC/v37wfg8ccfz1MPKsCmTZtcx9kNPejRowdeXl4kJCTw5ZdfZhjru2/fPnbv3g3AoEGD8PHxyfQ+o0aNcoXfRYsWcdttt+WpXhGR0ur9lX9xLjaJRxduIykl6wlvIX6erPq/nni6aQtkESm78tXj+8UXXwBgGAb9+/d3nT9//jz79+/n/Pnz2b7+3LnLC61XqVIly3Zubm4EBQUBsHbtWlJSUtJdX7Vqles4PDw8y/tUrVqVBg0aALB69epsaxMRKUtmDG3NhF5hNKjsh2Fk3sYwoFoFLzzsWuFSRMq2fP0tt27dOgDq1KmDv78/8+fPp3nz5lSqVIkGDRpQqVIlGjZsyLRp00hMzLiPfNqxupGRkVm+j9PpJCoqCjDHCR84cCDd9V27drmOGzVqlG3Nl64fO3Ys2xUoRETKEk83Ow9d25BH/9WIrGZ0OJ0wqU9DjKySsYhIGZHn4OtwONizZw8AwcHBTJgwgWHDhmVYq3ffvn08+uijXHPNNVy8eDHdtcaNG7uOV6xYkeV7bdmyhZiYy3vQHz16NN31iIgI13GNGjWyrbtmzZqAGabTvu5KiYmJREVFpXuIiJR23esH06JGIFdGW5sBLWoE0r1+sCV1iYgUpzwH38jISBwOc5zY9u3bmT59OtWqVeOTTz7h/PnzxMXFsWLFCjp27AjAmjVruPPOO9Pdo2/fvq5xwa+++ipnz57N8D4Oh4Mnnngi3bno6Ogsn2e24kNavr6+ruO0YfpKU6ZMITAw0PW4FJhFREozwzCY1KchV3b6OtTbKyLlSJ6Db9phAgkJCfj4+LBs2TKGDRtGxYoV8fb2pnv37ixdupSWLVsC5oSy9evXu15Xs2ZN7rnnHgCOHz9Oly5d+Prrr4mKiiIhIYF169bRr18/fvrpp3QrQsTHp591nJCQ4Dq+cuWIK3l6emZ5n7QmT55MZGSk63Hs2LFs7ysiUlpc6vW1XZFxF2+JIDoh2ZqiRESKUZ6Dr5eXV7rnY8aMoWHDhhnaeXt788ILL7ief/bZZ+muT5s2jX79+gHmsIibb76ZwMBAvL296dSpEz///DNt27Z1rdEL4O/vn2UtWe3+dknascbe3t5ZtvP09CQgICDdQ0SkLLjU6+tI0+1rAIu2nKDf9JVsPnLBstpERIpDnoPvleGzT58+Wbbt1auXa0jDldsJe3p68u233/Lee+/RqlWrdF+zVa5cmSeeeIKVK1eSdn+NihUrZllLdsMXIH1PdU7DIkREyqpLvb5gju39bFxHQit4c+x8PIPeXcvrv+0jJTXrZc9EREqzPAdfT09PQkJCXM+zGwPr5eVFcLA5YeLMmTMZ39xmY8yYMWzZsoXIyEj279/P8ePH+fvvv3n++efx8vJyrRcM0KRJk3SvTzuhLbsJa4BryIJhGDlOhBMRKasMw+Cx6xoRVtmPx65rRPu6lfhxYjdublWdVIeT13/bz6B313L0XJzVpYqIFLp8LWfWtGlT13Fqamq2bS9dz2mTC39/f8LCwqhevTo2m8312j///BOAq666yhWiL0kbhC+tNJGVS9dr1qyZbqKbiEh507V+ML89HE7Xf1ZyCPBy5/UhrXl9cCv8Pd344+hF+k1fyVd/RJDPXe1FREqkfAXf7t27u47/+uuvLNtFRUW5VmwIDQ3N8/ssW7bMtdnF4MGDM1zv2rWr6zi7ZdFOnjzJvn37AOjSpUue6xARKQ9ubh3KDxO60bZ2RWISU3j1130kJGvYg4iUHfkKvrfeeqvreNGiRVm2W7Rokau3oFu3bnl6D6fTybPPPguAu7s7Y8eOzdCmQYMGrjWBP//8c+LiMv9qbs6cOa7jAQMG5KkOEZHypGaQDwvu7sikaxvw+uBWeHtoC2MRKTvyFXxbtGhB3759Afj0009ZsmRJhjYnT57kySefBMylxkaPHp3u+rlz5zLd1Q3MIQ4PPPCAa3vhyZMnU7du3UzbPvLII4C5XfJjjz2W4frBgweZMmUKAGFhYQq+IiI5cLPbGN+rPm3rBLnOzV9/lGk/7yVZE99EpBQznPkcwLVv3z46dOjAxYsX8fLyYuLEifTr1w9vb282bNjAlClTXBPOXnrppQyh9Msvv+SBBx5gyJAhhIeHU6tWLRISEti2bRuzZs1yje3t27cvixcvznKd3tTUVMLDw10h+dZbb2Xs2LFUrFiRDRs28Nxzz3H69GlsNhvfffedK7DnVlRUFIGBgURGRmppMxEpl05HJdD95WUkJDt45baW3NpGE4RFpGTJbV7Ld/AFWLVqFQMHDuTUqVOZ39wweOKJJ3juuecyXPvyyy+57bbbsi7MMBg9ejRvvfVWus0nMnP27Fn69euXYcm0Szw9PZk5cyZjxozJ9j6ZUfAVEYHvt/3NDzv+ZsaQ1tiu3AFDRMRixRJ8wRyyMGPGDBYvXsyhQ4dISkqiWrVq9OjRg/Hjx9O6detMX3fq1Cnmzp3L0qVL2bNnD6dOncJms1G9enV69uzJ6NGj6dChQ67rSElJ4b333mP+/Pns3r2b2NhYqlevTq9evZgwYUK6lSjyQsFXRCSj2MQUXv55LxN61aeib/Y7Z4qIFLViC75lnYKviEhG/160nfnrj1IlwJNXB7WiS1hwzi8SESkiuc1r+ZrcJiIi5dvt7WpxVbAvp6ISGT57PVN+2E1iSvbruouIWE3BV0RE8qx5jUC+e7ArQzvUwumEd3//i1veWsOB09FWlyYikiUFXxERyRcfDzdeHNCcWXe0oaKPOztPRNF/xio+WXdEO76JSImk4CsiIgXSp2lVfprYnW71g0lIdvDk4h2M/XgT52IyX6tdRMQqCr4iIlJgVQK8+Gh0e568vjEedhu/7T7Nda+vZPne01aXJiLiouArIiKFwmYzGNPtKhbf34X6lf04G5PIqA838uw3OzXxTURKBAVfEREpVE2qB/Dt+K6M7FQbgB3HI7Eb2vRCRKznZnUBIiJS9ni52/nPTc3o0bAyYZX9cLOb/SzJqQ7cbAaGgrCIWEA9viIiUmR6NqpMzSAf1/P//biHUR9u5HR0goVViUh5peArIiLF4lRUAvPWH2HFvjPsOB5pdTkiUg5pqIOIiBSLKgFefPNAV5btOc01japYXY6IlEPq8RURkWLToIo/48LruZ6fuBjPwLfXsPOEeoBFpOgp+IqIiGVe/GE3m45c4OY3V/Pe73/hcGjHNxEpOgq+IiJimf/e1Ixrm1QhOdXJCz/s5o4P1nMyUhPfRKRoKPiKiIhlgnw9mHVHG6bc0hxvdzurD5zjX2/8zk87TlpdmoiUQQq+IiJiKcMwuL19Lb57sCvNQwO5GJfMPZ9s5v8WbiM2McXq8kSkDFHwFRGREqFeiB8L7+3MvT3qYRiwYOMx+s9YxdZjF60uTUTKCAVfEREpMTzcbDz+r0bMH9ORaoFeHDoby61vr+HNZQdI1cQ3ESkgBV8RESlxOtWrxE8TunN982qkOJy8/PNebn9vHfFJqVaXJiKlmIKviIiUSIE+7swc2pppt7XE18NOjQreeHvYrS5LREox7dwmIiIllmEYDGxTg3Z1KhLk6+E6fyE2CTe7gb+Xu4XViUhpox5fEREp8WpX8nWFXKfTySNfbKXf9JVsi7hobWEiUqqox1dEREqVM9GJ7DkZzZmYRDzc1H8jIrmn4CsiIqVK5QAvfpzYjT+OXKBR1QDX+djEFHw99c+aiGRNPyqLiEipE+DlTo+GlV3P/zx2kS4vLeWrPyJwOrXsmYhkTsFXRERKvblrj3AxLpmHP9/Kgwv+JDI+2eqSRKQEUvAVEZFSb+rAFjzSpwF2m8G3W0/Q742VrP/rnNVliUgJo+ArIiKlnt1m8MA19fnynk7UruTD8YvxDHlvHS//vIfkVIfV5YlICaHgKyIiZUbrWhX5/sFuDGpbA6cT3lx2kIFvr+HQ2VirSxOREkDBV0REyhQ/TzemDmzJW8OuJtDbna0RkVw/fSWfbTyqiW8i5ZyCr4iIlEn9mlfjp4nd6HRVJeKSUnl84Xbu/eQPLsQmWV2aiFhEwVdERMqsaoHezBvTgcl9G+FuN/hp50n6z1hFfFKq1aWJiAW00reIiJRpNpvBuPB6dAkL5sEFW7i5VSjeHnYATlyM53w2PcCV/DyoFuhdXKWKSBFT8BURkXKhWWgg34/vhrvdACAxJZXrp6/kQlzWa/6G+Hmy6v964ulmL64yRaQIKfiKiEi5camnF8DhcGY75MEwoFoFLzzsGhUoUlboT7OIiJRLCckOwir7ZXnd6YRJfRpiGEYxViUiRUnBV0REyqWKvh58fX8XGlX1x3ZFtrUZ0KJGIN3rB1tTnIgUCQVfEREpt+x2G5P7NcZxxfK+DvX2ipRJCr4iIlKuda8fTIsagel6fb3cbVxdq4JlNYlI0VDwFRGRcs0wDCb1aZiu1zch2cH987eQnOqwrjARKXQKviIiUu5d6vUFCKvsh5ebjd/3neHJRTu0zbFIGaLgKyIi5Z5hGDx2XSPCKvvx7A1NeXPY1dgM+GzTMWYuPWB1eSJSSAynfpTNVlRUFIGBgURGRhIQEGB1OSIiUkzmrjvCU4t3APDKbS25tU0NiysSkazkNq+px1dERCQTd3SszbjwqwB4fOE2Vh84a3FFIlJQCr4iIiJZePy6RvRvUY0Uh5N75m5m78loq0sSkQJQ8BUREcmCzWYw7baWtK8TRHRiCqM+3MDJyASryxKRfFLwFRERyYaXu51ZI9pwVYgvf0cmMHrORuKTUq0uS0TyQcFXREQkBxV8PPhodHuC/Ty5vnlVvNz1z6dIaeRmdQEiIiKlQc0gH5Y8HE6gj7vVpYhIPulHVhERkVxKG3rjklL4btsJC6sRkbxSj6+IiEgeJSSnMvjddWw/HklSioNbrtYavyKlgXp8RURE8sjL3U7nepUI8vWgTrCv1eWISC5p57YcaOc2ERHJjMPh5HR0IlUDvawuRaTc085tIiIiRchmM9KF3p0nIjkVpTV+RUoyBV8REZECWnPgLLe9s5Y752wkNjHF6nJEJAsKviIiIgVUo6IP3u52dp6I4v75f5CS6rC6JBHJhIKviIhIAdWq5MPsUe3wcrexfO8Znvp6B5pCI1LyKPiKiIgUglY1KzDj9quxGfDphmO8tfyg1SWJyBUUfEVERArJtU2q8OyNTQF4+ee9LN5y3OKKRCQtBV8REZFCNKJTHcZ2qwvAo19uZc3BsxZXJCKXFErwPXr0KM888wxt27YlJCQELy8vatasSbdu3Xj66afZsWNHlq89fPgwjz/+OG3atKFChQq4u7sTFBRE586d+e9//8vp06dzVUNcXBxTp06lXbt2BAUF4evrS6NGjZg0aRJHjhwpjI8pIiKSK5P7NqZf86okpzoZN3cz+05FW12SiFAIG1jMmDGDyZMnExsbm2WbCRMm8Prrr2c4P3fuXMaNG0d8fHyWrw0KCmLBggVce+21WbY5cOAA/fr1Y//+/ZleDwgIYN68efTv3z/rD5IFbWAhIiL5kZCcyvD317PpyAVCK3iz6L7OVA7QZhciRaFYNrB4/vnnefDBB4mNjaVBgwa8/PLLLF++nC1btvDbb7/x8ssv07lzZ2y2jG+zevVqRo0aRXx8PDabjdGjR7N48WI2bNjAl19+yQ033ADA+fPnuemmm/jrr78yrSE6Oprrr7/eFXrHjh3LkiVLWLNmDS+88AJ+fn5ERUUxePBg/vzzz4J8XBERkVzzcrfz3oi21A325fjFeEZrjV8R6znz6bfffnMCTsA5YsQIZ1JSUpZtExMTM5y7/vrrXa9/8803M33dww8/7Gpz//33Z9rmqaeecrWZOnVqhuurV692urm5OQFneHh47j5cGpGRkU7AGRkZmefXioiIHD4b47z6v784az/+nXPm0v1WlyNSJuU2r+VrqIPD4aBRo0bs37+fli1bsmnTJtzc3PJ0j6CgIC5cuEClSpU4ezbzgf+RkZFUqFABgKuvvprNmzenu56cnExISAiRkZE0btyYHTt2ZNq7fM899/Duu+8CsGHDBtq1a5frOjXUQURECmrL0Qt8t+1v/t2vMXabYXU5ImVOkQ51+OWXX1xDCx5//PE8h16ApKQkAOrWrZtlm8DAQIKDg9O1T2vZsmVERkYCMHLkyExDL8CoUaNcx4sWLcpzrSIiIgXRulZFnurfRKFXxGL5Cr5ffPEFAIZhpJswdv78efbv38/58+dzvEfDhg0BOHToUJZtoqKiXL3Bl9qntWrVKtdxeHh4lvdp27YtPj4+gDm2WERExCrJqQ4e+3IrX/+pNX5Filu+gu+6desAqFOnDv7+/syfP5/mzZtTqVIlGjRoQKVKlWjYsCHTpk0jMTEx03vcc889AJw7d4533nkn0zbPPfdchvZp7dq1y3XcqFGjLOt1c3MjLCwMgN27d+fw6URERIrO55uO8fmmCB5fuI0z0Zn/GykiRSPPY3wdDgfu7u44HA7atWtHp06dmD59epbtO3fuzPfff+8aq3tJamoqd955Jx9//DE2m40777yTG2+8kWrVqnH06FHmzp3L4sWLAXjiiSd4/vnnM9y7Y8eOrF+/Hl9fX2JiYrKtu3///nz//fcAJCQk4OnpmavPqzG+IiJSmBwOJ49+uY3+LarRs1Flq8sRKRNym9fyHHwvXLhAUFAQAF5eXiQkJFCtWjVefvll+vXrh5eXFxs3buTxxx939QwPGDCAr776KtP7ffnll7z44ots2bIlw7WePXvy73//m969e2f62qZNm7Jr1y6qVKnCyZMns6178ODBfP755wCcPXuWSpUqZdouMTExXS91VFQUNWvWVPAVERERKaGKbHJb2o0qEhIS8PHxYdmyZQwbNoyKFSvi7e1N9+7dWbp0KS1btgTMCWXr16/PcK/du3fz8ccfs3379kzfa+3atcyePZvjxzMfB5WQkACAh4dHjnWn7eHNbsOMKVOmEBgY6HrUrFkzx3uLiIjk15FzsYz/dIvW+BUpBnkOvl5e6XedGTNmTKYTz7y9vXnhhRdczz/77LN011euXEmnTp349ttvCQ0NZe7cuZw8eZKkpCSOHTvGm2++iY+PDwsWLKB9+/bs3Lkzy1oyW/HhSml7cb29vbNsN3nyZCIjI12PY8eO5XhvERGR/HA4nIz5aBPfbj3Bg59uISXVYXVJImVanoOvv79/uud9+vTJsm2vXr1cS51t3LjRdT4xMZHbb7+dyMhIqlatyrp16xg+fDhVqlTB3d2dGjVqcN999/H777/j5eXFiRMnGDlyZJa15DS+F9L3VPv5+WXZztPTk4CAgHQPERGRomCzGbw0sAWebjaW7DnNs9/uJB/L64tILuU5+Hp6ehISEuJ6nt1QAC8vL9c6vGfOnHGd/+mnn1zDF8aPH0/VqlUzfX3Tpk0ZPnw4AJs3b2br1q3prteoUQMwQ+3FixezrftSz21ISEiuJ7aJiIgUtatrVeSNIa0xDPhk3VHe/f0vq0sSKbPytZxZ06ZNXcepqanZtr10Pe0mF2mXFLv66quzfX2bNm1cx3v27El3rUmTJlleSyslJYWDBw8C0Lhx42zfT0REpLj9q1lVnu5v/pv2vx/38M3WExZXJFI25Sv4du/e3XX8119Z/2SadgOK0NBQ1/m0ITglJfvB/MnJyZm+DqBr166u4xUrVmR5j02bNrmGOnTp0iXb9xMREbHC6C51uauruZvpI59vZf1f5yyuSKTsyVfwvfXWW13H2W0BvGjRItdYpW7durnOp92meOXKldm+V9pAe+X2xj169CAwMBCAjz76KMtxUXPmzHEdDxgwINv3ExERscoT/Rrzr6ZVSUp1cPfczRw4nfMcFhHJvXwF3xYtWtC3b18APv30U5YsWZKhzcmTJ3nyyScBc7mx0aNHu6716tXLtYXw22+/neVyZj/++KMrWIeGhtKqVat01z08PHjwwQcBc/jEtGnTMtzj0pJoYG5r3K5du7x8VBERkWJjsxm8PqQVrWtVIDI+mVEfbtDubiKFKM8bWFyyb98+OnTowMWLF/Hy8mLixIn069cPb29vNmzYwJQpU4iIiADgpZde4rHHHkv3+ueee46nn34aMFdZGD9+PNdeey0VK1bk1KlTfP3117z33nuuoRBz5851TXRLKzo6mrZt27Jv3z4A7r77boYMGYK3tzfLli3jxRdfJCYmBm9vb9asWZMhPOdEO7eJiEhxOxeTyK1vr+HwuTha1Ahkwd0d8fFwy/mFIuVUke3cltaqVasYOHAgp06dyvzmhsETTzzBc889l+Ga0+nk4Ycf5o033sh26RZ3d3defPFFHnnkkSzbHDhwgH79+rF///5MrwcEBDBv3jz69++fwyfKSMFXRESscPhsLLe8vYbzsUn0alSZd+9og5s9X1/UipR5xRJ8Ac6dO8eMGTNYvHgxhw4dIikpiWrVqtGjRw/Gjx9P69ats3395s2bef/991m1ahVHjhwhLi4OPz8/wsLCCA8PZ9y4cTRo0CDHOmJjY3nzzTf54osvOHDgAElJSdSsWZN+/foxYcIEateuna/Pp+ArIiJW2XzkAkPfW0ez0EA+HN2OAC93q0sSKZGKLfiWdQq+IiJipc1HztO0eiBe7narSxEpsXKb1/SdiYiISAnWpnZQutB79FychdWIlG4KviIiIqWAw+HkpZ/20PvVFWw4dN7qckRKJQVfERGRUsAJ/HUmhqRUB38eu2B1OSKlktZGERERKQXsNoPXB7dm5f4z9Gla1epyREol9fiKiIiUEt4e9nShNy4phbikFAsrEildFHxFRERKoTPRidw+ax0PfvonqQ4t0CSSGwq+IiIipdCxC3HsPhnNb7tP8Z9vd2a7GZSImBR8RURESqGra1XkjcGtMAz4eO0R3l95yOqSREo8BV8REZFSqm/zajzRrzEAL/ywm++3/W1xRSIlm4KviIhIKXZX17qM6lwHgIc+/5ONh7XGr0hWFHxFRERKMcMweKp/E/o0qUJSioOxH2/i4JkYq8sSKZEUfEVEREo5u83gjSGtaVWzAhfjkhn94UbOxiRaXZZIiaPgKyIiUgZ4e9h5f2RbagX5cPR8HHd9tIn4pFSryxIpURR8RUREyohgP0/mjG5HBR93th67yIMLtmiNX5E0FHxFRETKkKtC/Hh/RFs83Gz8uusUr/+2z+qSREoMBV8REZEypm2dIF4f3IqGVfwZ3K6m1eWIlBhuVhcgIiIiha9f82pc26QK7nb1cYlcoj8NIiIiZVTa0PvTjpNs0hq/Us4p+IqIiJRxv+06xb3zNjPm401EXIizuhwRy2iog4iISBnXJSyYFqGBNK8RSNUAL6vLEbGMgq+IiEgZ5+1h59O7O+LtbscwDKvLEbGMhjqIiIiUAz4ebq7Qm5zqYO66I1rjV8od9fiKiIiUI06nk/vm/cGvu07x15kYnrmhqdUliRQb9fiKiIiUI4ZhcFOr6gB8uPows1cdsrgikeKj4CsiIlLO9G9RnX/3awTA89/v4sftf1tckUjxUPAVEREph8Z2u4oRnWrjdMLEz/5k8xGt8Stln4KviIhIOWQYBs/c0JTejSuTmOJgzEebOHQ21uqyRIqUgq+IiEg5ZbcZTL+9NS1qBHIhLplRH27gXEyi1WWJFBkFXxERkXLMx8ON2SPbUaOiN0fOxTHm400kJKdaXZZIkVDwFRERKedC/D2ZM7o9gd7ubDl6kQkLtmiNXymTFHxFRESEsMp+vDeiLR52Gz/vPMUL3++2uiSRQqcNLERERASA9nWDeGVQS8Z/uoXPNh6lW/1gQvw9M21byc+DaoHexVyhSMEo+IqIiIjLDS2rcz42kdd+28/oORuzbBfi58mq/+uJp5u9GKsTKRgNdRAREZF0RnSqQ60gHwwj8+uGAdUqeOFhV4yQ0kW/Y0VERCQdwzCY1KchzizmtzmdMKlPQ4yskrFICaXgKyIiIhl0rx9Mi9DADOdtBrSoEUj3+sEWVCVSMAq+IiIikoFhGEy6rmGG8w719koppuArIiIimepeP5gWNQKx/ZNxbQa0CA2kgrfmxkvppOArIiIimbo01vfSXhYOJ9Su5MOAt9bwyboj1hYnkg8KviIiIpKlS72+YPb2+nq64XDCk4t38Oove3FmNQNOpARS8BUREZEsGYbBY9c1IqyyH4/9qxFTbmnOxN71AZi+9AD/t3A7KakOi6sUyR3DqR/VshUVFUVgYCCRkZEEBARYXY6IiEiJMH/9UZ5cvB2HE3o1qszMoVfj7aHNLMQauc1r6vEVERGRPBvaoRbvDG+Dp5uNJXtOM/T9dZyPTbK6LJFsKfiKiIhIvvRpWpV5YzoQ6O3OlqMXGfjOGo6dj7O6LJEsKfiKiIhIvrWtE8TCeztRPdCLv87Ecuvba9h1IsrqskQypeArIiIiBRJW2Z+v7utCwyr+nI5OZPC7a1lz8KzVZYlkoOArIiIiBVY10IvP7+lE+7pBRCemcPfHm7kYpzG/UrJo6xUREREpFIHe7nx8Z3smfb6Vfs2rUcHHw+qSRNJR8BUREZFC4+VuZ+bQ1hiG4Tp3OiqBEH/PdOdErKChDiIiIlKo0gbcExfjuenN1Uz6YivJ2uhCLKbgKyIiIkVmW8RFTkcnsi0ikrjEVKvLkXJOQx1ERESkyPyrWTU+GOVGWGU/An3crS5Hyjn1+IqIiEiRCm8QQmgFb9fzRVsiOHIu1sKKpLxS8BUREZFis2T3KR7+fCu3vr2G7RGRVpcj5YyCr4iIiBSb5jUCaVw1gLMxSQyZtZaV+89YXZKUIwq+IiIiUmwq+3vx2biOdAmrRGxSKqM/3MjiLcetLkvKCQVfERERKVb+Xu58OKo9N7asTorDycTP/uS93/+yuiwpBxR8RUREpNh5uNl4fXArxnStC8ALP+zmue924XA4La5MyjIFXxEREbGEzWbwZP8mPNGvMQCzVx1i4md/kpii9X6laCj4ioiIiKXGdr+K1we3wt1u8M3WE9w5ZyPRCclWlyVlkIKviIiIWO7m1qF8MKodvh52Vh84x+B313E6OsHqsqSMKZTge/ToUZ555hnatm1LSEgIXl5e1KxZk27duvH000+zY8eOdO0PHz6MYRh5etSpUyfbGuLi4pg6dSrt2rUjKCgIX19fGjVqxKRJkzhy5EhhfEwREREpQt3qh/DZuE4E+3mw6+8olu05bXVJUsYUeMviGTNmMHnyZGJj0+/AEhERQUREBKtWrSIqKorXX3+9QO/TsGHDLK8dOHCAfv36sX///nTn9+7dy969e3n//feZN28e/fv3L1ANIiIiUrSahQay8N7O/LrrFIPb1bK6HCljChR8n3/+eZ566ikAGjRowNixY2nXrh2BgYGcO3eOLVu2sGjRImy29B3LoaGhbN++Pcf7T5kyhfnz5wMwcuTITNtER0dz/fXXu0Lv2LFjGTJkCN7e3ixbtowpU6YQFRXF4MGDWb16Na1atSrAJxYREZGiVruSL2O6XeV6HhmXzM4TkXQOC7awKikLDKfTma91Q5YsWULv3r0BGDFiBO+//z7u7u6Ztk1KSsLDwyNP909NTaVWrVqcOHECf39/Tp06hbe3d4Z2Tz/9NM899xwAU6dO5dFHH013fc2aNYSHh5OSkkJ4eDjLly/PUx1RUVEEBgYSGRlJQEBAnl4rIiIiBZOQnMqI2RvYfPQCrw5qyU2tQq0uSUqg3Oa1fI3xdTgc3HvvvQC0bNmS2bNnZxl6gTyHXoDffvuNEydOADBw4MBMQ29ycjLTp08HoHHjxkyaNClDm86dO3PXXXcBsGLFCjZu3JjnWkRERMQadptBjSBvfNztNKjib3U5UsrlK/j+8ssvrqEFjz/+OG5uBR4qnMHHH3/sOs5qmMOyZcuIjIx0tblySMUlo0aNch0vWrSo8IoUERGRIuVut/HKbS35dnxXGlfTN69SMPkKvl988QUAhmGkmzB2/vx59u/fz/nz5wtUVHR0NIsXLwagTp06dO/ePdN2q1atch2Hh4dneb+2bdvi4+MDwOrVqwtUm4iIiBQvwzCoE+zrer7x8HkmLthCQrI2upC8yVfwXbduHWCGUn9/f+bPn0/z5s2pVKkSDRo0oFKlSjRs2JBp06aRmJiY5/t/+eWXxMXFAXDHHXdgGEam7Xbt2uU6btSoUZb3c3NzIywsDIDdu3fnuR4REREpGeKTUrlv3h8s/vMEIz7YQGS8NrqQ3Mtz8HU4HOzZsweA4OBgJkyYwLBhwzKs1btv3z4effRRrrnmGi5evJin90g7zGHEiBFZtouIiADA19eXChUqZHvPmjVrAnDmzJlsw3hiYiJRUVHpHiIiIlIyeHvYeWNIK/w93dhw6DyD3lnLyUhtdCG5k+fgGxkZicPhAGD79u1Mnz6datWq8cknn3D+/Hni4uJYsWIFHTt2BMxVFe68885c3//o0aOsWLECMCemXeqpzUx0dDQAfn5+Od7X1/fyVyQxMTFZtpsyZQqBgYGux6XALCIiIiVD53rBfDauE5X9Pdl7Kppb3lrNgdPRVpclpUCeg2/ajSoSEhLw8fFh2bJlDBs2jIoVK+Lt7U337t1ZunQpLVu2BMwJZevXr8/V/T/55BMurbCWXW/vpfeH3K0a4enp6TqOj4/Pst3kyZOJjIx0PY4dO5abskVERKQYNakewMJ7O3NViC8nIhO49e21bDpcsDlGUvblOfh6eXmlez5mzJhMd1Xz9vbmhRdecD3/7LPPcnX/uXPnAmZQHTx4cK5qSUpKyvG+aYc3ZLY02iWenp4EBASke4iIiEjJUzPIh4X3dKZ1rQpExicz7P31/LLzpNVlSQmW53XI/P3Tr6HXp0+fLNv26tULNzc3Uv6/vTuPi6rc/wD+GYZ9lwAFQUIFScUlxTQREBdySXPtqilamZVbN6+aZWpSVy1NU6/lQi65FS6ZeruZhv5EcUHN3DAQSAlFkH1nmPP7g+bENsM+Z2A+79drXh3nPOeZ7zmd4XznOc95HoWiRuPnXrp0Sew/PGLEiGr77api0dR1QaVsS3VNukY0NEEQoFAoUFLCJ1CJdIGBgQGMjIzUPjxLRE1DCwtj7H29N2btvYpT0Y/x5u4r+Pglb0x8jtMdU2W1TnxNTEzg4OCAlJQUANDYB9bU1BT29vZ49OiRWF6Tmj7UpuLi4oKLFy8iNzcXGRkZGhNlVZcFBweHct0eGpsgCEhPT0dGRkadRrggosYjl8thZWUFGxsbcchDImp6zIzl2Dy5Bz44fBPfRj3A+4dv4HF2AeYO8OCPWyqnTjNPdOrUSZz6t7oWTNX66ia5KC4uxv79+wEAjo6OeOGFF6qNo2PHjjh48CAAIDo6WnygriKFQoF79+4BKJ3hTZuSk5ORnp4OKysrODg4wNDQkF9CIokJggClUonc3FxkZWUhIyMDLi4ule5oEVHTYSg3wMox3mhpbYL1v8Ri3ckYJGcV4OOXvCE34HWXStUp8fXz8xMT37i4OHTv3r3KcllZWUhNTQUAtG6teW7t48eP48mTJwCAiRMn1mg2OF9fX3G57EgSFUVFRYldHfr27VttvQ0lMzMT6enpcHJyqrbbBhFpn4WFBRwcHJCUlITExES4ubmx5ZeoCZPJZHh3cAc4WptiyZGbKChWgikvlVWnCSzGjBkjLmuaAvjw4cPiCA39+vXTWGdNpiiuKCAgADY2NgCAnTt3ip9V0Y4dO8TlUaNG1ajuhpCVlQVzc3MmvUQ6TCaTwdnZGUZGRuIU6ETUtL3S2w37pvfGqjFdYMDWXiqjTolvly5dMGTIEADAvn37cOrUqUplHj16hMWLFwMoHW5s2rRpautLS0vD8ePHAQDe3t7o1q1bjeIwNjbGnDlzAJTOyLZ69epKZSIjIxEaGgqgdFpjHx+fGtVdX6rbqFI8SEdEtSOTyWBtbY3s7Gy1P6CJqGl5ru1TMDYsTXNKlAL+/d87+DND/XCmpB/qlPgCwLp162BrawulUonhw4dj0aJFOHv2LKKiorBp0yb4+PiIM6uFhIRo7Oqwf/9+cUiymrb2qsyfPx+enp4AgAULFmDGjBkIDw/HhQsXsGLFCgwePBgKhQJmZmZYt25d3Xa2DhQKBQRBqDT8GxHpJnNzc5SUlKC4mNOfEjU3X5yKwZb/i8M/tkSiUMHRlfSZTKhH80ZERATGjh2L5OTkqiuXyfDBBx8gJCREYz29e/fGxYsXIZfLkZiYiFatWtUqjtjYWAwdOhQxMTFVrre2tsaePXswfPjwWtULlHZXsLGxQWZmZq3G9C0oKEB8fDyefvppjeMGE5FuyM/PR0JCAtzd3fmDlaiZScrIx6s7LmNWYHsM7+IsdTjUCGqar9Xp4TYVX19f3Lp1Cxs2bMD333+P+Ph4FBUVwcnJCQEBAZg9e7baB99UYmJixFndBg0aVOukFwDat2+Pa9eu4T//+Q/CwsIQGxuLoqIiuLq6YujQoZg7dy7c3NzqtI/1xREciJoGfleJmi9nWzMcne0LI/nfN7rzi0pgZiyXMCqSQr1afPVBfVt82XpE1DTwO0ukPx5m5mPsl5F4w68tgp9/WupwqAHUNF+rcx9fIiIioqbo8LU/8WdGPpb+cAuf/i+aD7XqESa+REREpFfe8m+Hfw0ufTB+0+l7+FfYbyguUUocFWkDE18iIiLSKzKZDLMCPfDpmC6QG8hw8Goipu+KQl6RQurQqJEx8SXSkoSEBMhkMshksnKTqhARkTTG+7hi65QeMDUywOm7KZiw5QKe5BRKHRY1Iia+1KSVTSbr8yIiIv0U6NUSe6f3RgtzI1xPzMTYryJx/0me1GFRI2HiS0RERHrt2TYtcOCt59Ha1gzxqbkY/eV53PyTU5g3R/Uax5dIaq1bt8aNGzfUrvf29gYA9OzZE9u3b9dWWFV6+umn+eQwEZGOaudgiUNvP4+p2y/jzsMsvLw5Epsn94Svh73UoVEDYuJLTZqRkRE6d+5cbTkLC4salSMiIv3V0toU387ojRm7riAy7gmm7biE7VN7MfltRtjVgYiIiOgv1qZG2PGqD4Z3cUKHVlbo1sZW6pCoATHxJb0VEBAAmUyGgIAAAKXTZ8+aNQseHh4wNzeHTCZDQkKCWP7hw4fYtGkTxo4dCw8PD1hYWMDExAStW7fGyJEj8e2330KpVD8OZHWjOixbtqzcw3YFBQX47LPP8Oyzz8LKygpWVlbo1asXNm7cCIWCQ+4QETUWE0M51v+jO/a83huWJqU3xwVBYHe1ZoBdHfREUkY+0nKL1K5/ytIYTjZmWoxItxw5cgSTJk1Cbm5uletLSkrg4uJSZWKblJSEH374AT/88ANCQ0Nx6NAhWFpa1iue5ORkvPDCC/j111/LvX/58mVcvnwZJ06cwPfffw8DA/52JSJqDAYGMtiYGYn//vLMPdx9lI3PxnaFsSH/9jZVTHz1QKGiBCM2RiA1R33i62Bpgoj3+sPEUK7FyHTD/fv38corr8Dc3Bwffvgh+vXrB7lcjsuXL4sJrOpXfmBgIIYMGQJvb284ODggOzsbcXFx2Lp1KyIjI/Hzzz9j5syZ2LlzZ71iGj16NG7fvo05c+bgxRdfhJ2dHe7evYuQkBDcuXMHR48exdatWzFjxox67z8REWn2IC0Pa3/+HcUlAnyetkM3V1u1ZfW9IUnXMfHVA8ZyAzjbmuFJbhGquksjkwFOtqYwluvnL9j4+Hg4OzsjMjISbdq0Ed9/7rnnxGW5XI67d++iffv2lbb39/fHtGnTsHTpUixfvhzffPMNFi9eDA8PjzrHpGrVVXXDAIBnn30WQUFB6NixI5KTk7Fp0yYmvkREWuBqZ45twT64GPcE607+zoakJkw/Mx0dlFekqPVLUWZecUWJEnlFChQUl1SqN7+4BLP6t68y6QUAQQBm9W+P/OIS5BUpys1XXqIUSusoKl9vflFJjeNsClauXFku6a1IJpNVmfSWtWTJEtjb20MQBPzwww/1imf27Nnlkl4VOzs7TJs2DQBw48YNZGZynEkiIm3w93TA/KAOcLY1g7p5j/S9IakpYIuvjui45Kdab/Ofic9iWBcnAMBPt5Ixc+9VPOduh29n9BHL+K4K19i3V+WNb66Iy8tHdsKUPk8DAC7Fp2HC1gvwcLTEz+/6i2VGbIxAzOOcGsWZsHJYjcpJxdjYGOPGjavVNkqlEo8ePUJ2djaKi4vF911cXJCamorr16/XK6ZJkyapXdejRw8Apd0v4uPj0a1bt3p9FhER1YxMJsO8wR0Q/PWlKtcLAjBvcAfOCKrDmPiS3vPw8ICpqWm15QRBwJ49exAaGoqLFy8iPz9fbdnU1NR6xeTl5aV2nZ2dnbicnZ1dr88hIqLa8fOwR0cna9x+mFXufQMZ0Lm1Dfw45q9OY+KrI24vD6r1NmVvpQR1aonby4NgUOFXZsTC/uKyIAh4efMF3H6YBaVQ+iXt6GSNb2f0Lvfr1KhMvb3c7XB7eRBkKF/vD7N8IaB5DOvSokWLassUFBRg9OjR+PHHH2tUp6akuCbMzc3Vris7kkNJSYnackRE1PBkMhkWDvGq1OqrFIDZge3Z2qvj2AlFR5gbG9b6ZVgmQTWUG8Dc2BCmRnK19VqYGGH+C15Q/pWvKgVg/gtesDAxKleubOIrN5DB3NgQZsbl6zUzltc4Tl0nl1f/AMInn3wiJr3+/v747rvvEBsbi5ycHJSUlIjjO/br1w8AONYjEVEz5udhjy4uNjCokON+fuJ3JKRWPSwm6QYmvnpG9WUFgC4uvCVTE4IgYNu2bQCAfv364ZdffsG4cePQrl07WFhYlGuBTUtLkypMIiLSElVfX2WZNg5LE0PceZSN4Rsi8N8bD6ULjjRi4qtnZDIZFgR5ob2jJRYEefGWTA2kpaXh0aNHAIBx48apnTQiJycHd+/e1WZoREQkkYoNST//0w8+T7dATqECb++5imU/3EKRQv1sniQNJr56yNfDHiff9YcvW3trpOz0wOpmdgOAbdu2cSphIiI9UbEhycnWDPum98ab/u0AADvOJ2Dc5kg8SMuTOFIqi4kvUTUcHBxga2sLANi3bx8KCwsrlbl8+TI+/PBDLUdGRERSqtiQZCg3wHtDvBAa3BM2Zka4/iADw9afxbX76RJHSipMfImqYWBgII6r+9tvv8HX1xf79u1DVFQUTp06hXnz5sHPzw+mpqbw9PSUOFoiIpLagGda4vgcX3RztcVTliZo72gpdUj0F91/5J5IB3zyySc4d+4cfv31V0RFRWHixInl1tvZ2eHgwYNYsmQJfv/9d4miJCIiXeHSwhzfzeiDx9kFsDI1AlD6sPST3CLYW5pIHJ3+YosvUQ3Y2Njg3LlzCAkJgbe3N0xNTWFpaYlnnnkG//rXv3D9+nX4+flJHSYREekQY0MDuLT4e1z27ecSMOjzMzh997GEUek3mcABRzXKysqCjY0NMjMzYW1tXePtCgoKEB8fD3d39xrNCkZE0uJ3logaU4lSwNivzuPa/Qwse7EjpvZ1lzqkZqWm+Rq7OhARERE1MrmBDPum98b31/7Eyz6u4vuCIHBoUS1iVwciIiIiLTA1kuMfvdqIiW52QTHGb47E+dhUiSPTH0x8iYiIiCSwMTwWlxPSMSn0Ir44GYMSJXufNjYmvkREREQS+OdAT7zc0xWCAKw9+Tumbr+E1JzKY8VTw2HiS0RERCQBUyM5Vo3tgjXjusLMSI6zMakYtv4sLsY9kTq0ZouJLxEREZGExvRwwZFZfdHe0RLJWYWYuO0ivjx9D0p2fWhwTHyJiIiIJObZ0gpHZvbFqO6tUaIUsOp/0Xht52Wk5xZJHVqzwsSXiIiISAdYmBji8/FdsXK0N4wNDRB+NwXD1p/F1fvpUofWbDDxJSIiItIRMpkM/+jVBofffh5PP2WOpMwCjP8qEtvOxoFzjtUfE18iIiIiHdPJ2QZHZ/timLcTFEoBJ+8kg11+648ztxERERHpICtTI2yc2B19L9lj4DOOkBtwhrf6YosvERERkY6SyWSY+FwbOFqbiu99fOw2volMYNeHOmCLLxEREVETcTHuCbZFxAMAurm2gLeLjcQRNS1MfImIiIiaiF7udlg87Blk5Rcz6a0DJr5ERERETYRMJsPr/dqWe+9BWh4i455gXA8XyGTsB6wJE18iIiKiJqpIocSsfddw/UEGLsQ9wccvdYa5MdM7dfhwGxEREVETZWggQ1CnlpAbyHDo6p8YufEcYpKzpQ5LZzHxJSIiImqiDAxkeDugPfa+/hwcrUwQ8zgHIzaew+FriVKHppOY+BIRERE1cc+1fQr/ndsPvu3tkV9cgn9+ex3vHfwNBcUlUoemU5j4EjWQZcuWQSaTqX2wICAgADKZDAEBAfX6HNVnLFu2rF71NITq9pmIiLTH3tIEO1/thXcGekAmA/ZffoCX/nMOcSk5UoemM5j4UpM2Y8YMMfH65ZdfarXtiRMnxG3nzp3bSBESERFpj9xAhncGemL3a8/B3tIY0Y+yMWLjORz7LUnq0HQCE19q0qZMmSIu7969u1bbfvPNN1XWo+927Ngh/iBISEiQOhwiIqqDvu3tcXxOPzznboecQgVm7b2GJUduolCh310fmPhSk9a3b1+0a9cOAHDw4EHk5+fXaLvc3FwcPnwYANCpUyf06NGj0WJUOX36NARBwOnTpxv9s7Rl2bJlEASB02YSEemgltam2PP6c5jZv/Q6uSvyD3x1Ok7iqKTFxJeavMmTJwMAsrKycOTIkRptc+jQIeTm5pbbnoiIqLkxlBtgfpAXtk/zQZ+2T+ENv7bVb9SMMfGlJm/y5Mniw1U17e6g6uZgYGCAV155pdFiIyIi0gX9Ozhi7/TnYGYsBwAolQL2XryP4hKlxJFpFxNfavLatm2Lvn37AgB++uknPH78WGP5pKQknDp1CgAQGBiI1q1bAwAuXLiAxYsXIyAgAK1atYKxsTGsra3RsWNHvPXWW7h9+3a94qzpqA579+5FQEAAWrRoAUtLS3Tu3BlLly5FRkZGjT7n5s2b+PjjjxEUFAQXFxeYmJjA0tISHh4eCA4OxoULF6rc7vTp05DJZJg2bZr4nru7u9jfV/Uq21WjpqM6JCQk4J///Cc6deoEKysrmJubw8PDAzNmzMCNGzc0bltxFIvLly9jwoQJ4r61bt0akydPxp07d2p0fIiI9FXZv9VfnrmH9w/fQPDXl/SquxrntNMXmYlAbqr69RYOgE1r7cXTwKZMmYKIiAgoFArs378fc+bMUVt27969UCqV4nZA6QNdZRM+leLiYty5cwd37tzB1q1bsX79erz99tuNsg8KhQITJ05EWFhYufdv3bqFW7duYffu3Th58qTGOk6fPo3+/ftXer+oqAixsbGIjY3Frl278N5772HFihUNGr86u3btwhtvvIHCwsJy76viCQ0NRUhICBYtWlRtXZs2bcLcuXOhUCjE95KSkrB7924cOnQIP/74I/z8/Bp8H4iImhsPR0tYmxripW6t9WpISia++kBRCGzpD+RqaAm1dATeuQkYmmgvrgY0fvx4zJkzBwUFBfjmm280Jr6qbg6WlpYYPXo0gNKks0WLFhg5ciT8/Pzg4eEBCwsLJCUl4erVq1i/fj1SU1Mxa9YseHl5ITAwsMH34V//+peY9Hbo0AELFixAly5dkJmZibCwMGzduhUvv/yyxjoUCgUsLCwwbNgwBAYGwsvLC9bW1nj8+DFu3bqF9evX448//sDKlSvh6elZLtn38fHBjRs3cOTIESxevBhAaQu6s7Nzuc9wd3ev8T4dP34cU6dOhSAIsLS0xLx58zBw4EAYGhri/PnzWLFiBVJTU/H+++/D1tYWb731ltq6fvrpJ1y6dAne3t6YO3cuvL29kZ+fj8OHD+OLL75AXl4eJk+ejJiYGBgbG9c4RiIifTS4Uyv84tYCT1n8/ffyQVoenGxMYShvxh0CBNIoMzNTACBkZmbWarv8/Hzh9u3bQn5+fiNFVgtKpSBs9heEpbaCsNS6ipdt6XqlUupI62X8+PECAAGAEB0dXWWZ69evi2WmTJkivp+YmCjk5uaqrTsjI0Po0qWLAEDw9fWtsszSpUvFuqvi7+8vABD8/f0rrfvtt98EAwMDAYDw7LPPCtnZ2ZXK7Ny5U6wfgLB06dJKZVJSUoT09HS1+1FYWCgMGjRIACC4ubkJCoWiUpnt27eLnxEfH6+2LkHQvM9FRUWCs7OzAECwtLQUrl27VqlMQkKC4OTkJAAQzM3NhZSUlEplyu7z0KFDhcLCwkplPv74Y7HMoUOHNMasjk59Z4mItCwtp1Do8++TwrgvzwuPMpve38Ga5mvNOKVvYopya/8q+ft2L0oUpe8V51eutzgP8JsPQF0HdmXp+uK8v+otLrOq5K/Py6tQb17N49SSsmPxlh2jtyx1Y/e2bt0a5ubmauu2sbHB8uXLAQARERF48uRJfcMt56uvvhK7X2zZsgWWlpaVykyZMgVDhgzRWI+9vT1sbW3Vrjc2NsZnn30GAPjjjz/w66+/1jnm6hw+fBhJSaUDpi9evBjdunWrVMbNzU2MJy8vD9u3b1dbn6mpKbZv315la+6cOXPE98+ePdsA0RMR6Ze7ydnIKlDgUkIahn5xFmdjUqQOqVGwq4Ou+Ldz9WUqGrcD6DSqdDn6KBA2FXDzBaYd/7vMOm8grwZJ2v6Jfy8PXQ30ml66/Md5YOdwwMELmHnx7zJb+wMp0TWLc1lmzcrVU1BQEFq2bInk5GTs2bMHISEh5fotKZVK7N27FwDg4uJSZV9YldzcXKSkpCA3N1fs9G9kZCSuv379eoN2d1D13fX29tY4pvCrr76KH3/8scb1FhYWIjk5GTk5OWJiLZR5iOH69euNNoaxap9kMhleffVVteXGjRuHmTNnIjMzEydPnsT8+fOrLDdo0CA4OjpWuc7KygoeHh64desW4uL0e4xKIqK66N32KRyd7Yu391zFnYdZmPL1JcwO9MDcAR6QGzSfPsBs8aVmw9DQEBMnlibwCQkJiIiIKLf+1KlTYgvkpEmTYGBQ/vRX9TXt0KEDrKys4O7ujs6dO8Pb2xve3t4YNmxYubINpbCwEDExMQBK+9lq0qtXr2rry83NxYoVK9C1a1dYWFjAzc0NnTp1Eveje/fuYtmG3I+Kbt68CaC0T7CDg4PacsbGxmJMqm2q4uXlpfHz7OzsAADZ2dm1DZWIiAC421vg8NvPY0IvVwgCsP5UDKZ8fREp2YXVb9xEsMVXV7xfhzm05WUeRPN6sbQOWYXfMu+UGSpKEIAdQ4FHNwGhBJDJgVadgan/Bco+0SkvcyvZ7fm/Yqvwa296OEq7VOqWKVOmYO3atQBKuzX069dPXKdpiuIrV64gKCioxl0YajpDXE2kp6eLrbDqWjRVWrZsqXF9QkICAgMDER8fX6PPbsj9qCgtLQ1A9fsEAK1atSq3TVU0dUUBIP6QKSnR7+k4iYjqw9RIjhWju6CXux3eP3QT52KfYOj6s9gwoTt6t31K6vDqjS2+usLYovYveZnfLXLD0veMzNTXa2IJDFhSmvQCpf8dsKT0/XL1/n1LHwbyv96vkHQYm9c8Ti3q1q0bvL29AQBhYWHiEFq5ubk4dOgQAKBHjx7o2LGjuE1RURHGjx+PJ0+ewMjICO+++y7OnDmDhw8foqCgQJyS9969e+I2QiONeVjfIWUmT56M+Ph4sXvBiRMn8ODBAxQUFECpVEIQhHKJYWPtR1n6NEwOEVFzMaq7C36Y1RcejpZIyS7ExK0X8J/wWCiVutfoVRsNkvjev38fS5cuRc+ePeHg4ABTU1O4urqiX79+WLJkicbblyonT57E1KlT0b59e1hYWMDGxgaenp4YO3YsvvzyS+Tk5GjcPi8vD59++il8fHxgZ2cHCwsLeHl5Yd68efjjjz8aYjebh3YDAOe/bnU7dy/9dzOjas3NyMjA0aNHAZQ+aKWaorhia+8vv/wi9gvdtGkT1qxZAz8/P7Rq1QomJn+3qmtqjayPsg+jJScnayyraX10dLTYveP9999HaGgoBg0aJE70oEpAG2s/KlJ1PahunwDg0aNH5bYhIiLpebS0wpFZfTH62dZQCsBnP93FtB2XkZZbJHVodVbvxHfDhg3o2LEjli9fjitXriA1NRWFhYVITExEREQEQkJCsG3bNrXbp6en46WXXsKgQYOwc+dO3Lt3D3l5ecjKykJMTAwOHjyIt99+G7GxsWrriI2NRbdu3bBw4UJERUUhPT0deXl5uHv3Lj7//HN06dIFx44dq++uNg8yGTBgKWDfofS/zbA1btKkSZDLS6dkVE1hrOrmYGRkhAkTJpQrf+vWLXFZ0zi5UVFRDR0qgNLRCjw8PACUzkqmiab1DbUfDdVC27lzZwBAfHw8UlLUPx1cXFyMa9eulduGiIh0g7mxIdaM64pPx3SBiaEBzvyegmHrz+LPjMbrKteY6pX4fvzxx5gzZw5yc3Ph6emJzz77DKdPn8a1a9dw8uRJfPbZZ3j++ecrPUSkkpmZiUGDBuHIkSMAgFGjRmHPnj24cOECLl++jEOHDmHu3LlwcXFRG0N2djaGDRsmPhw0ffp0nDp1CufPn8cnn3wCS0tLZGVl4eWXX27UoZualHb9gVmXSv/bDDk5OWHgwIEAgP/+97+4efOmOEXxCy+8UOlBq7KzgKlahStSKpXYunVrI0UMMd4bN26ISWBVvv76a7XrarIfQOnQaZqYmpqKyxVnW6sN1T4JgqBxmLIDBw4gMzOz3DZERKQ7ZDIZxvu44vuZfdHW3gIdWlnBydq0+g11UV0HCj558mS5iQCKiorUlq1qwHlBEITJkycLAAQTExPhyJEjardXKpVCcXFxles+/PBDMY5PP/200vpz584JhoaGaicOqE6zmMBCD+3Zs0c8Lzp16iQuh4WFVSp78OBBcf2KFSuqrG/BggXlJlLYvn17pTL1mcDi119/FWQymQBA6Nmzp5CTk1OpzO7duzVOYHHlyhVx3YwZM6qMYdOmTdVOgnHmzBlx/fHjx6uspyb7XFhYKE5gYW1tLfz222+Vyty/f18sU90EFlXFWpam41sT/M4SEVUvu6BYSM/9O6/LK1QIGbnqc0BtqWm+VqdRHZRKpTi1aNeuXREaGgpDQ/VVVTXgfEREhHj7+eOPP8aIESPUbi+Tyaqsv7i4GOvXrwcAPPPMM5g3b16lMs8//zxee+01bN68GWfOnMHly5erHTKKmr5Ro0bBysoK2dnZYheAFi1a4MUXX6xUNigoCI6Ojnj8+DEWL16MhIQEjBo1Cvb29oiNjcXWrVtx6tQp9O3bF+fOnWuUeLt27YqZM2di48aNiIqKQs+ePbFw4UJ4e3uLUxZv2bIFPXv2VNtVoXv37ujcuTNu3ryJzZs3Iz09HZMnT4aTkxMSExOxe/duHDhwoNr96N69O0xNTVFQUIAPP/wQRkZGcHNzE+/ctG7dGmZmZmq3VzE2NsaWLVvw4osvIisrC3379sX8+fMxYMAAyOVynD9/HitXrsTjx6VTaa9evRr29vZ1OHpERKQtlibl87EPj9zEhbgn2DTpWdhbmmjs//uUpTGcbKq/fjSmOiW+J06cELsWLFy4UGPSq87GjRsBlM6INWvWrLqEgfDwcPEWaXBwsNouFVOnTsXmzZsBlD7kxMS3+TMzM8PYsWPL3WIfP358uYfVVCwsLLBr1y689NJLKCgowObNm8XzRSUgIAAbN25s1D6on3/+OZKSknDo0CFER0dj2rRp5da7u7vj22+/Rbt27arcXiaT4ZtvvkFgYCDS09Px3Xff4bvvvitXxtvbG2FhYXB2Vj9hipWVFebMmYNPP/0UV69exeDBg8utDw8PR0BAQI32adiwYdi+fTtmzJiB7OxsLFmyBEuWLClXRi6XIyQkRPwxTURETUNGXhEuxachKSMfGXnFeHXHZaTmqE98HSxNEPFef5gYyrUYZXl16uMbFhYGoPRCO3z4cPH9tLQ0xMTEVPvUeFFRkdivd9CgQWKfwpKSEjx48AAJCQkoKCioNo6yExT4+/urLdezZ09xDNDGarEj3RMcHFzu3xVHcygrKCgIUVFReOWVV+Ds7AwjIyM4ODjA398fW7ZswalTp2Bh0bhDsxkZGeHgwYPi+MM2NjYwNzfHM888g/fffx9XrlxB27ZtNdbRrVs3/Prrr3jzzTfh5uYGIyMj2NnZoVevXli9ejUuXboEJyenamNZuXIltm7din79+sHOzk58WLAugoODER0djblz5+KZZ56BhYUFzMzM0K5dO0yfPh3Xrl3DokWL6lw/ERFJw9bcGMfm+GLTpGfRz8MezrZmap+Zl8kAJ1tTGMulHUlXJgi1H8izU6dOuH37Ntzd3REXF4e9e/dixYoV5YYt8/T0xPTp0zF79uxKrWyXL18WZ6D66KOP8M4772DJkiXYuXMnMjIyAJTeJvXz88MHH3ygtnVp7NixOHjwIIDS0SHKDgtVUdeuXfHbb7/BwcFBvLVaE1lZWbCxsUFmZiasra1rvF1BQQHi4+Ph7u5e7mEhItJN/M4SEdXPmd9TEPz1JbXrd77aC/6e6mfyrI+a5mu1TruVSiWio6MBAPb29pg7dy4mTZpUaaze33//HfPnz0dgYKCYzKrcvn27XH09e/bEF198Ua5cUVERTp48icDAQKxatarKWBITEwGU3qrWlPQCgKurKwAgJSWlXk+qExEREVFlfh72sDKt3P3VQAZ0cbGBn4f0z3HUOvHNzMyEUqkEUDr00vr16+Hk5ITdu3cjLS0NeXl5OHPmDHr37g0AOH/+PF599dVydZTtCrFq1SrExMTghRdewKVLl1BQUIDHjx/jyy+/hI2NDQRBwHvvvSd2jSgrOzsbAGBpaVlt3GVvU2uaDKOwsBBZWVnlXkRERESkmUwmw6rR3pXeVwrAvMEddGImz1onvmXHBy0oKIC5uTnCw8MxadIktGjRAmZmZvDz88Mvv/yCrl27Aih9oOzixYtq6xg0aBCOHTsGHx8fmJiYwMHBAW+++SaOHTsmPrC2aNGiStOrqvoBVzVqREVlu1vk56sfdHnFihWwsbERX6qWYiIiIiLSbIi3E7q0toHBXzmuLrX2AnVIfCv2fXv99dfRoUOHSuXMzMzwySefiP/+9ttv1daxatWqKh+e8fX1xejRowEAd+7cwY0bN6qMpaio+qnzynZv0DQU06JFi5CZmSm+Hjx4UG3dRERERFTa6jsvqAOUf7VV6lJrL1CHxNfKyqrcvysOdVTWgAEDxKHOyk61WrYOBwcHdO/eXW0dQUFB4nLF6VpV9WjquqBStpVZU9cIExMTWFtbl3sRERERUc34ediji4sNAN1q7QXqkPiquiKoaOoKYGpqKg5In5KSUuU2mqYjrli2bB1lt83Nza30AF1FqpZbBweHKsdyJSIiIqL6k8lkWBDkhfaOllgQ5KUzrb1AHcfx7dSpk7hcUlKisaxqfdlJLuqyfcU6AKBjx47ismqkiaooFArcu3cPQOkMb0RERETUeHw97HHyXX/46lBrL1DHxNfPz09cjouLU1suKysLqampAEqnOVVxc3NDmzZtAAAJCQmVHlorS5WwVqwDKO0DrHLmzBm1dURFRYldHfr27au2HBERERE1X3VKfMeMGSMuHz58WG25w4cPi0ltv379qqwjKysLp06dUlvHoUOHxOWyiS5QOo2sjU1pH5KdO3eqTaB37NghLo8aNUrtZxERERFR81WnxLdLly4YMmQIAGDfvn1VJq6PHj3C4sWLAZQONzZt2rRy69955x1xVIZ33323yvFyd+/ejdOnTwMAhg0bVqk/sbGxMebMmQOgdNSH1atXV6ojMjISoaGhAEqnNfbx8anNrhIRERFRM1HnCZPXrVsHW1tbKJVKDB8+HIsWLcLZs2cRFRWFTZs2wcfHR5xZLSQkpFI3hTZt2mD58uUASifC6NWrF7Zv344rV64gPDwcs2fPxtSpUwEA1tbWWLt2bZVxzJ8/H56engCABQsWYMaMGQgPD8eFCxewYsUKDB48GAqFAmZmZli3bl1dd7fO6jAjNBFJgN9VIqLmTybU4699REQExo4di+Tk5Korl8nwwQcfICQkRG0dixYtwqpVq9RedBwdHfH999+jT58+auuIjY3F0KFDERMTU+V6a2tr7NmzB8OHD9ewN1Wr6dzPFRUVFeHevXtwdXWt0cxyRCSt7OxsJCYmon379jAyMpI6HCIiqoWa5mv1SnwB4MmTJ9iwYQO+//57xMfHo6ioCE5OTggICMDs2bM1jtGrEhkZiS+//BJnz57Fw4cPYWpqCk9PT4wYMQKzZ88W+/Fqkpubi//85z8ICwtDbGwsioqK4OrqiqFDh2Lu3Llwc3Or0/7VNfEVBAH37t2DpaUlWrVqVafPJiLtSUxMRFFREdzd3XVq6B0iIqqe1hLf5q6uiS8AJCcnIyMjA23atNE4WxwRSSs9PR2PHj1Cy5YtYWdnJ3U4RERUSzXN1wzVrqF6s7e3R35+Pu7fvw9ra2tYWVlBLpezNYlIYoIgQKlUoqCgADk5OcjLy0OLFi3QokULqUMjIqJGxMS3Ecnlcri6uiI1NRXZ2dnVzi5HRNplYGAAc3NzODs716hLFRERNW1MfBuZXC5Hy5Yt4ejoiOLiYiiVSqlDIiKUJr2GhoYwMKjz4DZERNTEMPHVEplMBmNjY6nDICIiItJbbOogIiIiIr3AxJeIiIiI9AITXyIiIiLSC0x8iYiIiEgvMPElIiIiIr3AxJeIiIiI9AITXyIiIiLSC0x8iYiIiEgvMPElIiIiIr3AxJeIiIiI9AKnLK6GIAgAgKysLIkjISIiIqKqqPI0Vd6mDhPfamRnZwMAXF1dJY6EiIiIiDTJzs6GjY2N2vUyobrUWM8plUokJSXBysoKMpms0T8vKysLrq6uePDgAaytrRv985oKHhf1eGyqxuOiHo9N1Xhc1OOxqRqPi3raPjaCICA7OxvOzs4wMFDfk5ctvtUwMDCAi4uL1j/X2tqaX6Iq8Liox2NTNR4X9Xhsqsbjoh6PTdV4XNTT5rHR1NKrwofbiIiIiEgvMPElIiIiIr3AxFfHmJiYYOnSpTAxMZE6FJ3C46Iej03VeFzU47GpGo+Lejw2VeNxUU9Xjw0fbiMiIiIivcAWXyIiIiLSC0x8iYiIiEgvMPElIiIiIr3AxJeIiIiI9AITXyIiIiLSC0x8JRQVFYXly5dj8ODBcHFxgYmJCSwtLeHp6Ylp06YhIiJC6hAlkZWVhf3792PevHnw9/dH+/btYWNjA2NjYzg6OiIgIACffvopnjx5InWoOmXhwoWQyWTi6/Tp01KHpFVl913TKyAgQOpQJVFUVIRt27YhKCgITk5O4t+bDh06YNq0aTh//rzUITaox48f49ixY1iyZAmGDBkCe3t78RyYOnVqrev78ccfMWrUKPFvtYuLC0aNGoUff/yx4YNvRA1xXHbs2FHj79uOHTsadX8aUkNfk5vLOdMQx0WnzhmBJNGvXz8BQLWvKVOmCIWFhVKHq1U///xzjY6Nvb298L///U/qcHXCtWvXBENDw3LHJzw8XOqwtKom5wwAwd/fX+pQtS4hIUHo1KlTtcdm9uzZglKplDrcBqFpP4ODg2tcT0lJifDaa69prO/1118XSkpKGm9nGlBDHJft27fX+Pu2ffv2Rt2fhtKQ1+TmdM401HHRpXPGUG1GTI0qKSkJAODs7Ixx48ahX79+aNOmDUpKShAZGYk1a9bgzz//xK5du1BcXIy9e/dKHLF2ubq6on///ujRowdcXV3h5OQEpVKJxMREHDhwAIcOHUJqaipGjBiBS5cuoWvXrlKHLBmlUok33ngDCoUCjo6OePz4sdQhSeqtt97C22+/rXa9hYWFFqORXnFxMYYNG4Zbt24BALp06YJ3330XHTp0QHZ2NiIiIrBmzRrk5uZiw4YNcHZ2xnvvvSdx1A2rTZs28PLywokTJ2q97QcffIDQ0FAAQPfu3bFgwQK0a9cO9+7dw6effopr165h27ZtcHBwwL///e+GDr1R1ee4qPz0009wdnZWu97FxaXOdWtTQ16Tm9M50xi5iuTnTKOm1aTWsGHDhG+//VZQKBRVrk9JSRE8PT3FX0BnzpzRcoTSUXdMyjp8+LB4bEaNGqWFqHTX2rVrBQCCl5eXsGjRIr1v8V26dKnUoeiUsLAw8dj06dOnyu9XVFSUYGRkJAAQbG1theLiYgkibVhLliwRjh49Kjx69EgQBEGIj4+vdcvm3bt3xTspPXv2FPLy8sqtz83NFXr27CkAEAwNDYWYmJiG3o0G1xDHpWzrXXx8fOMFq0UNdU1ubudMQx0XXTpn2MdXIseOHcP48eMhl8urXG9vb481a9aI/z5w4IC2QpOcumNS1ksvvYQOHToAAM6ePdvYIems+/fv48MPPwQAfPXVVzA2NpY4ItI1ZfvuLlq0qMrvV48ePTB8+HAAQEZGBu7cuaO1+BrLRx99hOHDh6Nly5Z1rmPdunVQKBQAgA0bNsDMzKzcenNzc2zYsAEAoFAosHbt2roHrCUNcVyao4a6Jje3c6Y55ipMfHVY//79xeV79+5JGIlusrKyAgAUFBRIHIl0Zs6ciZycHAQHB8Pf31/qcEgHFRUVictt27ZVW65du3ZVbqOvBEHAkSNHAABeXl7o3bt3leV69+4t/gg/cuQIBEHQWoykXdVdk/X1nGlquQoTXx1WWFgoLtekFVSf3L17F7/++iuA0j8w+ui7777DsWPHYGdnh9WrV0sdDuko1QUWAOLi4tSWU12wZDIZPDw8Gj0uXRcfHy/2b6zuR6Vq/Z9//omEhITGDo0kUt01WV/PmaaWqzDx1WFnzpwRl5955hkJI9ENeXl5iImJweeffw5/f3/xdtI777wjbWASyMjIwNy5cwEAq1atgr29vcQR6Y6wsDB07NgR5ubmsLKygoeHB4KDgxEeHi51aJKYMGECrK2tAZSeKyUlJZXKXLt2DcePHwcATJw4USyvz27fvi0uV/fjuuz65tBNpDamTZsGZ2dnGBsbw97eHr1798bixYvx559/Sh1ag6vumqyv50xtcxWpzxkmvjpKqVRi5cqV4r/Hjx8vYTTSKTv2n4WFBTw9PTFv3jwkJycDAN577z1MnDhR4ii1b8GCBXj06BH69u2L1157TepwdMrt27dx584d5OfnIycnB7Gxsdi1axcCAwMxatQoZGZmSh2iVtnb2+Obb76Bubk5zp07Bx8fH+zatQsXLlzAyZMn8dFHH8Hf3x9FRUV49tlny/XX02eJiYnicnVPmbu6uorLDx48aLSYdNHp06fx8OFDFBcX48mTJ7h48SI++eQTtG/fHps3b5Y6vAZTk2uyPp4zdclVpD5nOJyZjlq7di0uXboEABg9ejR69OghcUS6pVu3btiyZQt8fHykDkXrzp49i23btsHQ0BBfffUVZDKZ1CHpBHNzc4wYMQIDBgyAl5cXLC0tkZKSgjNnzuCrr77CkydP8P3332PkyJH4+eefYWRkJHXIWjNixAhcuXIFa9asQWhoKIKDg8utb9myJUJCQjB9+nSYm5tLFKVuyc7OFpctLS01li07RF5OTk6jxaRL2rZti9GjR6NPnz5iEhcXF4eDBw/iwIEDKCgowJtvvgmZTIY33nhD4mjrrybXZH08Z2qTq+jMOSPpmBJUpdOnT4vDoTg6OgrJyclShySZ9PR04caNG8KNGzeES5cuCfv27RNGjRolABDatWsnHD16VOoQtaqwsFDw8vISAAjz58+vtH7p0qV6O5xZenq62nWPHj0SunfvLh6bL774QnuB6YDCwkJh0aJFgoODg9pB43v27CkcOXJE6lAbTW2H7Vq+fLlY/tSpUxrLnjp1SiwbEhLSQBFrR12GM8vIyNA40cnRo0fF4fHMzc2Fhw8fNlC00qjpNVlfzhmV2uQqunTOsKuDjrl16xZGjRoFhUIBU1NThIWFwdHRUeqwJGNra4vOnTujc+fO8PHxwT/+8Q8cOnQIu3btQlxcHEaOHNmkpsSsr3//+9+Ijo5GmzZtsHTpUqnD0Sm2trZq17Vs2RIHDhwQW3lVwwnpg9zcXAwcOBArVqxAWloaFixYgDt37qCwsBCZmZk4ceIEfH19ERUVhZdeegmff/651CHrBFNTU3G5ulEuyj7cU3H4qubIxsZG452m4cOHY8mSJQBKn81QTebQFNXmmqxP50xtcxVdOmeY+OqQ+Ph4DB48GOnp6ZDL5di/fz/8/PykDksnTZ48GePGjYNSqcSsWbOQlpYmdUiNLjo6GitWrABQmrjp2wxk9dW2bVsMGjQIABAbGys+fd3cLVu2TBzrOjQ0FKtWrYKXlxeMjY1hbW2NQYMGITw8HP3794cgCJg/fz6uX78ucdTSUw2XCFR/Kzo3N1dcru4Wt7544403xESn7MNPTUltr8n6cs40Vq6irXOGia+OSEpKwsCBA5GUlASZTIavv/4aI0eOlDosnaY6Prm5ufjf//4ncTSNb+3atSgqKkLbtm2Rl5eH/fv3V3rdvHlTLP/LL7+I75f9I6vPOnbsKC43x6fOKxIEAV9//TUAwNPTs1LfXhVDQ0OEhIQAKH1YRZ/uoqhT9uGksg8tVaXsw0llH1rSZ46OjnjqqacANM3vWl2uyfpwzjRmrqKtc4YPt+mA1NRUDBo0SBxjc8OGDZgyZYrEUek+BwcHcfmPP/6QMBLtUN0ai4uLw4QJE6otr0pkgNJf6Gwhht49CJicnCzeDenevbvGsmUfSomOjm7UuJqCsj+SqjseZddz6Mm/NdXvW12vyc39nNFGrqKNc4YtvhLLzMxEUFCQOP7fypUrMXPmTImjahrK/iJsareKSBplx9l0dnaWMBLtMDT8u21DNe61OsXFxVVup6/c3d3Fc6S6267/93//BwBo3bo1nn766cYOrUlISUlBamoqgKb1XavPNbk5nzPayFW0dc4w8ZVQXl4ehg0bhqtXrwIAPvjgAyxcuFDiqJqOsLAwcdnb21vCSLRjx44dEARB46vsA2/h4eHi+03hD2tji4+Px88//wygdHre1q1bSxxR47OzsxMno4iMjNSY/Ja9ULu7uzd6bLpOJpOJt3Cjo6Nx4cKFKstduHBBbL0bOXJkk23lbGhbtmwRp+JtKtOp1/ea3FzPGW3lKlo7ZxptvAjSqLCwUBg8eLA4nMncuXOlDklnbN++XcjPz9dY5vPPPxePnbu7u6BQKLQUnW7T1+HMfvjhB6G4uFjt+orDma1Zs0aL0UlrwoQJ4n4vW7asyjJpaWlCx44dxXI//fSTlqNsfHUZtuvu3buCXC4Xh3vLy8srtz4vL0/o2bOnAEAwNDQUfv/990aIvHHV9rjEx8cLV69e1Vjm6NGjgrGxsQBAMDMzExITExso2sbTUNfk5nbONMRx0bVzhvezJDJhwgScOHECABAYGIjXXnut3INJFRkbG8PT01Nb4Ulq2bJlmDdvHsaMGQNfX1+0a9cOlpaWyM7Oxo0bN7Bnzx6cO3cOQOlx2bJlS5OYH5waz+zZs1FcXIwxY8agT58+ePrpp2FmZobU1FScPn0amzdvFm+h+fr66lV3oiVLluDIkSPIy8vDsmXLcOXKFQQHB6Nt27YoKCjAhQsXsG7dOty/fx8AMGDAAAwePFjiqOsvIiICsbGx4r9V//+B0lE9Kj7AN3Xq1Ep1eHp6Yv78+Vi5ciWioqLQt29fLFy4EO3atcO9e/ewatUqXLt2DQAwf/58eHh4NMq+NKT6HpeEhAT0798fffr0wYsvvoiuXbuKw1jFxcXhwIEDOHDggNhyt3r16iZxd6WhrsnN7ZxpiOOic+dMo6XUpBHUDCKv7uXm5iZ1yFrj5uZWo2Pi4uIinDhxQupwdYq+tvjW9JwZM2aMxokumquff/5ZsLe3r/b4BAYGCmlpaVKH2yCCg4Nr9TdWnZKSEuHVV1/VuO1rr70mlJSUaHHv6q6+xyU8PLxG25mbmwubN2+WYA/rpiGvyc3pnGmI46Jr5wxbfEnn/PTTTzh+/DjOnTuH2NhYJCcn48mTJzAzM4OjoyO6deuG4cOHY/z48ZxelQAAO3fuxJkzZxAZGYm4uDikpqYiKysLlpaWcHV1xfPPP4/g4GD06dNH6lAlMXDgQERHRyM0NBQ//vgjbt26hYyMDBgaGqJVq1bw8fHBxIkTMWLECJ3vb6htBgYGCA0NxZgxY7BlyxZcvnwZqampsLe3h4+PD2bMmIEhQ4ZIHabW9OjRA7t370ZkZCSioqLw8OFDpKamQqFQoEWLFujUqRMGDBiA119/XW8nX+I5U56unTOyvzJ6IiIiIqJmjaM6EBEREZFeYOJLRERERHqBiS8RERER6QUmvkRERESkF5j4EhEREZFeYOJLRERERHqBiS8RERER6QUmvkRERESkF5j4EhEREZFeYOJLRERERHqBiS8RERER6QUmvkRERESkF5j4EhEREZFeYOJLRERERHrh/wGrfpFPkv+6mAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use validation to get the optimal number of rules\n",
    "tsl_cv_train_accuracy = []\n",
    "tsl_cv_val_accuracy = []\n",
    "\n",
    "kf = KFold(n_splits=number_of_folds)\n",
    "\n",
    "for number_of_rules in number_of_rules_array:\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        ts_model = TsModel.TsModel(number_of_rules, fuzzification_coefficient=1.2)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        ts_model.fit(x_train[train_index], y_train[train_index])\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        tsl_train_pred = ts_relu_wrapper(ts_model.predict(x_train[train_index]))\n",
    "        tsl_val_pred = ts_relu_wrapper(ts_model.predict(x_train[test_index]))\n",
    "\n",
    "        train_rmse = root_mean_squared_error(y_train[train_index], tsl_train_pred)\n",
    "        val_rmse = root_mean_squared_error(y_train[test_index], tsl_val_pred)\n",
    "\n",
    "        tsl_cv_train_accuracy.append(train_rmse)\n",
    "        tsl_cv_val_accuracy.append(val_rmse)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "number_of_rules_array_strings = [str(number) for number in number_of_rules_array]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsl_cv_train_accuracy).reshape(-1, 10), axis=1), '-.v', label='Train')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsl_cv_val_accuracy).reshape(-1, 10), axis=1), '-.v', label='Validation')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b264e4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2030, 12)\n",
      "[[9.53451292e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.31439845e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99512777e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99839957e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.94864080e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.88594281e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[9.53451292e-01 4.65487083e-02]\n",
      " [1.31439845e-04 9.99868560e-01]\n",
      " [9.99512777e-01 4.87222834e-04]\n",
      " ...\n",
      " [9.99839957e-01 1.60043399e-04]\n",
      " [5.94864080e-03 9.94051359e-01]\n",
      " [2.88594281e-02 9.71140572e-01]]\n",
      "FCM training RMSE: 944.3386152363356\n",
      "(2030, 12)\n",
      "[[9.98672377e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.81773445e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.81259938e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99843266e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.63695870e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.88020908e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[9.98672377e-01 1.32762303e-03]\n",
      " [1.81773445e-04 9.99818227e-01]\n",
      " [8.81259938e-06 9.99991187e-01]\n",
      " ...\n",
      " [9.99843266e-01 1.56734334e-04]\n",
      " [5.63695870e-03 9.94363041e-01]\n",
      " [2.88020908e-02 9.71197909e-01]]\n",
      "FCM training RMSE: 950.072183198773\n",
      "(2030, 12)\n",
      "[[1.50220315e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99773003e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99988979e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.92356495e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94223868e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.75856976e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[1.50220315e-03 9.98497797e-01]\n",
      " [9.99773003e-01 2.26997162e-04]\n",
      " [9.99988979e-01 1.10209446e-05]\n",
      " ...\n",
      " [1.92356495e-04 9.99807644e-01]\n",
      " [9.94223868e-01 5.77613193e-03]\n",
      " [9.75856976e-01 2.41430236e-02]]\n",
      "FCM training RMSE: 961.1279959325589\n",
      "(2030, 12)\n",
      "[[1.43483275e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804613e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99990703e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.49759979e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94223775e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.72216558e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[1.43483275e-03 9.98565167e-01]\n",
      " [9.99804613e-01 1.95387461e-04]\n",
      " [9.99990703e-01 9.29674555e-06]\n",
      " ...\n",
      " [1.49759979e-04 9.99850240e-01]\n",
      " [9.94223775e-01 5.77622537e-03]\n",
      " [9.72216558e-01 2.77834420e-02]]\n",
      "FCM training RMSE: 949.4927735523986\n",
      "(2030, 12)\n",
      "[[9.98735060e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.81952477e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.57873818e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99868572e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.49070638e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.41895922e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[9.98735060e-01 1.26494003e-03]\n",
      " [1.81952477e-04 9.99818048e-01]\n",
      " [6.57873818e-06 9.99993421e-01]\n",
      " ...\n",
      " [9.99868572e-01 1.31428370e-04]\n",
      " [6.49070638e-03 9.93509294e-01]\n",
      " [3.41895922e-02 9.65810408e-01]]\n",
      "FCM training RMSE: 957.505764223362\n",
      "(2030, 12)\n",
      "[[9.98620522e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.87863074e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.94593257e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99826641e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.44706259e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.90362453e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 2)\n",
      "[[9.98620522e-01 1.37947797e-03]\n",
      " [1.87863074e-04 9.99812137e-01]\n",
      " [8.94593257e-06 9.99991054e-01]\n",
      " ...\n",
      " [9.99826641e-01 1.73358950e-04]\n",
      " [5.44706259e-03 9.94552937e-01]\n",
      " [2.90362453e-02 9.70963755e-01]]\n",
      "FCM training RMSE: 940.0343038559269\n",
      "(2031, 12)\n",
      "[[1.36902269e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99801010e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991829e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.70504253e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94170231e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.68523793e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 2)\n",
      "[[1.36902269e-03 9.98630977e-01]\n",
      " [9.99801010e-01 1.98989932e-04]\n",
      " [9.99991829e-01 8.17072739e-06]\n",
      " ...\n",
      " [1.70504253e-04 9.99829496e-01]\n",
      " [9.94170231e-01 5.82976939e-03]\n",
      " [9.68523793e-01 3.14762073e-02]]\n",
      "FCM training RMSE: 945.5969688401184\n",
      "(2031, 12)\n",
      "[[1.24529162e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99820444e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99990995e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.65810704e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94352024e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.72044251e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 2)\n",
      "[[1.24529162e-03 9.98754708e-01]\n",
      " [9.99820444e-01 1.79555833e-04]\n",
      " [9.99990995e-01 9.00452893e-06]\n",
      " ...\n",
      " [1.65810704e-04 9.99834189e-01]\n",
      " [9.94352024e-01 5.64797639e-03]\n",
      " [9.72044251e-01 2.79557488e-02]]\n",
      "FCM training RMSE: 952.5326252420076\n",
      "(2031, 12)\n",
      "[[1.83750589e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99789217e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99987046e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.83862289e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.95222230e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.76926176e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 2)\n",
      "[[1.83750589e-03 9.98162494e-01]\n",
      " [9.99789217e-01 2.10783425e-04]\n",
      " [9.99987046e-01 1.29544162e-05]\n",
      " ...\n",
      " [1.83862289e-04 9.99816138e-01]\n",
      " [9.95222230e-01 4.77777042e-03]\n",
      " [9.76926176e-01 2.30738237e-02]]\n",
      "FCM training RMSE: 938.3805116743258\n",
      "(2031, 12)\n",
      "[[9.98789065e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.80795924e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.50481354e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99239443e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71846147e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99851929e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 2)\n",
      "[[9.98789065e-01 1.21093543e-03]\n",
      " [1.80795924e-04 9.99819204e-01]\n",
      " [6.50481354e-06 9.99993495e-01]\n",
      " ...\n",
      " [9.99239443e-01 7.60557197e-04]\n",
      " [9.71846147e-01 2.81538532e-02]\n",
      " [9.99851929e-01 1.48071263e-04]]\n",
      "FCM training RMSE: 931.3243664192856\n",
      "(2030, 18)\n",
      "[[5.32628588e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99678221e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.19860538e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.43071197e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.90564392e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81502978e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[5.32628588e-02 9.47877583e-02 8.51949383e-01]\n",
      " [9.99678221e-01 2.54962833e-04 6.68166356e-05]\n",
      " [2.19860538e-05 5.79212757e-04 9.99398801e-01]\n",
      " ...\n",
      " [3.43071197e-06 9.99628335e-01 3.68234589e-04]\n",
      " [9.90564392e-01 7.57944098e-03 1.85616725e-03]\n",
      " [7.81502978e-01 2.11742636e-01 6.75438595e-03]]\n",
      "FCM training RMSE: 914.94248310555\n",
      "(2030, 18)\n",
      "[[6.33956141e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.30380181e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.72850250e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99545732e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.00391281e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.13122404e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[6.33956141e-02 9.30878093e-01 5.72629264e-03]\n",
      " [1.30380181e-04 5.71124565e-05 9.99812507e-01]\n",
      " [3.72850250e-06 1.68536637e-06 9.99994586e-01]\n",
      " ...\n",
      " [9.99545732e-01 4.50064148e-04 4.20414092e-06]\n",
      " [7.00391281e-03 1.65439529e-03 9.91341692e-01]\n",
      " [2.13122404e-01 6.24802024e-03 7.80629575e-01]]\n",
      "FCM training RMSE: 918.0682624354977\n",
      "(2030, 18)\n",
      "[[7.33411857e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.64584671e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.44006016e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99568737e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.77950586e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.01446912e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[7.33411857e-02 9.20037266e-01 6.62154794e-03]\n",
      " [1.64584671e-04 6.88940445e-05 9.99766521e-01]\n",
      " [4.44006016e-06 1.91825084e-06 9.99993642e-01]\n",
      " ...\n",
      " [9.99568737e-01 4.27042080e-04 4.22102948e-06]\n",
      " [7.77950586e-03 1.72601686e-03 9.90494477e-01]\n",
      " [2.01446912e-01 5.85894277e-03 7.92694145e-01]]\n",
      "FCM training RMSE: 925.8610878910125\n",
      "(2030, 18)\n",
      "[[5.95624721e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804365e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994286e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.47917577e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91564135e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.01608157e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[5.95624721e-03 6.10810492e-02 9.32962704e-01]\n",
      " [9.99804365e-01 1.34489368e-04 6.11457571e-05]\n",
      " [9.99994286e-01 3.91109914e-06 1.80297922e-06]\n",
      " ...\n",
      " [3.47917577e-06 9.99638488e-01 3.58032614e-04]\n",
      " [9.91564135e-01 6.75474645e-03 1.68111880e-03]\n",
      " [8.01608157e-01 1.92234475e-01 6.15736803e-03]]\n",
      "FCM training RMSE: 915.1458240605325\n",
      "(2030, 18)\n",
      "[[5.45716662e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.28928376e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.81655252e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99607609e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.48510058e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.17694549e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[5.45716662e-02 9.40610122e-01 4.81821176e-03]\n",
      " [1.28928376e-04 6.02710935e-05 9.99810801e-01]\n",
      " [2.81655252e-06 1.28993097e-06 9.99995894e-01]\n",
      " ...\n",
      " [9.99607609e-01 3.89023337e-04 3.36726637e-06]\n",
      " [7.48510058e-03 1.98730322e-03 9.90527596e-01]\n",
      " [2.17694549e-01 7.25133271e-03 7.75054118e-01]]\n",
      "FCM training RMSE: 930.2200886062923\n",
      "(2030, 18)\n",
      "[[5.60850647e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99817372e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994856e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.26296569e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91647910e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.70320436e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 3)\n",
      "[[5.60850647e-03 5.99242246e-02 9.34467269e-01]\n",
      " [9.99817372e-01 1.26488373e-04 5.61397062e-05]\n",
      " [9.99994856e-01 3.55541181e-06 1.58838678e-06]\n",
      " ...\n",
      " [4.26296569e-06 9.99537357e-01 4.58380048e-04]\n",
      " [9.91647910e-01 6.71386533e-03 1.63822435e-03]\n",
      " [7.70320436e-01 2.22988855e-01 6.69070884e-03]]\n",
      "FCM training RMSE: 909.1953928934731\n",
      "(2031, 18)\n",
      "[[5.76838131e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99796524e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994973e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.94299363e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91241763e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.71824565e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 3)\n",
      "[[5.76838131e-03 9.35158941e-01 5.90726773e-02]\n",
      " [9.99796524e-01 6.32497064e-05 1.40226554e-04]\n",
      " [9.99994973e-01 1.57919254e-06 3.44780502e-06]\n",
      " ...\n",
      " [3.94299363e-06 4.13033048e-04 9.99583024e-01]\n",
      " [9.91241763e-01 1.73747921e-03 7.02075737e-03]\n",
      " [7.71824565e-01 6.92689586e-03 2.21248539e-01]]\n",
      "FCM training RMSE: 916.5146572653999\n",
      "(2031, 18)\n",
      "[[4.13652475e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99711261e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99993924e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.14260582e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.70053572e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.75404492e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 3)\n",
      "[[4.13652475e-04 1.90188963e-02 9.80567451e-01]\n",
      " [9.99711261e-01 6.04051719e-05 2.28333567e-04]\n",
      " [9.99993924e-01 3.68788565e-06 2.38832208e-06]\n",
      " ...\n",
      " [1.14260582e-04 9.14520405e-01 8.53653348e-02]\n",
      " [9.70053572e-01 1.94640542e-03 2.80000225e-02]\n",
      " [8.75404492e-01 1.13206192e-02 1.13274889e-01]]\n",
      "FCM training RMSE: 995.687400109515\n",
      "(2031, 18)\n",
      "[[7.21037933e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99799626e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99992815e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.74550478e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.92740264e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.11434613e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 3)\n",
      "[[7.21037933e-03 9.30985739e-01 6.18038815e-02]\n",
      " [9.99799626e-01 6.22113339e-05 1.38163041e-04]\n",
      " [9.99992815e-01 2.20660957e-06 4.97795632e-06]\n",
      " ...\n",
      " [3.74550478e-06 3.51247754e-04 9.99645007e-01]\n",
      " [9.92740264e-01 1.45109953e-03 5.80863690e-03]\n",
      " [8.11434613e-01 5.91090082e-03 1.82654486e-01]]\n",
      "FCM training RMSE: 900.1444290070351\n",
      "(2031, 18)\n",
      "[[6.84441524e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.30547665e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.67403744e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.65649541e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.26968695e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.86435298e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 3)\n",
      "[[6.84441524e-02 9.26258414e-01 5.29743316e-03]\n",
      " [1.30547665e-04 5.57952413e-05 9.99813657e-01]\n",
      " [2.67403744e-06 1.13587988e-06 9.99996190e-01]\n",
      " ...\n",
      " [3.65649541e-04 9.99616497e-01 1.78536724e-05]\n",
      " [1.26968695e-01 8.05509215e-01 6.75220901e-02]\n",
      " [2.86435298e-03 9.97106079e-01 2.95677383e-05]]\n",
      "FCM training RMSE: 905.9149071952056\n",
      "(2030, 24)\n",
      "[[2.66863269e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99462554e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.04396423e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.98537568e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.84921644e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.68075144e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[2.66863269e-03 2.43203291e-03 9.89848820e-01 5.05051456e-03]\n",
      " [9.99462554e-01 1.35140849e-04 4.75427420e-05 3.54762801e-04]\n",
      " [7.04396423e-09 2.03549878e-06 9.99997764e-01 1.93903109e-07]\n",
      " ...\n",
      " [2.98537568e-06 1.25044818e-04 3.64463019e-04 9.99507507e-01]\n",
      " [9.84921644e-01 6.16539658e-03 7.27284016e-04 8.18567545e-03]\n",
      " [7.68075144e-01 1.54320139e-02 2.89897205e-03 2.13593870e-01]]\n",
      "FCM training RMSE: 945.0766468974598\n",
      "(2030, 24)\n",
      "[[2.88234433e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99763343e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994660e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.75761829e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.86446546e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.66890651e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[2.88234433e-03 9.19221039e-01 3.37440068e-02 4.41526098e-02]\n",
      " [9.99763343e-01 9.27409015e-05 1.14591991e-04 2.93237747e-05]\n",
      " [9.99994660e-01 9.87790488e-07 2.78226295e-06 1.56972576e-06]\n",
      " ...\n",
      " [3.75761829e-06 1.54095573e-04 9.99367317e-01 4.74829731e-04]\n",
      " [9.86446546e-01 5.34581031e-03 7.56399017e-03 6.43653631e-04]\n",
      " [7.66890651e-01 1.36745258e-02 2.16740902e-01 2.69392128e-03]]\n",
      "FCM training RMSE: 950.4333598440505\n",
      "(2030, 24)\n",
      "[[5.32711552e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99543711e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99995160e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.92835072e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.27623327e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.90501301e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[5.32711552e-03 3.07533180e-02 2.69188449e-01 6.94731117e-01]\n",
      " [9.99543711e-01 7.06545456e-05 3.43530137e-04 4.21038224e-05]\n",
      " [9.99995160e-01 2.49562861e-06 1.73468539e-06 6.10146379e-07]\n",
      " ...\n",
      " [6.92835072e-06 9.77684859e-01 2.14828350e-02 8.25377568e-04]\n",
      " [9.27623327e-01 2.91116997e-03 6.77233737e-02 1.74212965e-03]\n",
      " [2.90501301e-01 1.99823418e-02 6.86996766e-01 2.51959135e-03]]\n",
      "FCM training RMSE: 966.646710696594\n",
      "(2030, 24)\n",
      "[[6.09299336e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98250008e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99989365e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.32091253e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.82338004e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.99528582e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[6.09299336e-04 2.49709533e-01 1.54988311e-02 7.34182336e-01]\n",
      " [9.98250008e-01 1.42426674e-05 2.23829354e-05 1.71336620e-03]\n",
      " [9.99989365e-01 3.95534279e-08 5.75188540e-08 1.05384058e-05]\n",
      " ...\n",
      " [6.32091253e-08 1.66062691e-05 9.99968804e-01 1.45263792e-05]\n",
      " [4.82338004e-01 1.91630906e-03 5.44722414e-03 5.10298463e-01]\n",
      " [5.99528582e-02 1.25507243e-03 1.79236010e-02 9.20868468e-01]]\n",
      "FCM training RMSE: 841.5400128396088\n",
      "(2030, 24)\n",
      "[[7.70755917e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.12546406e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.40482492e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.99312912e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.03487746e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.86511699e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[7.70755917e-01 2.18138804e-02 2.02990634e-01 4.43956844e-03]\n",
      " [4.12546406e-05 5.80111300e-05 2.98195644e-04 9.99602539e-01]\n",
      " [4.40482492e-07 1.48938888e-06 1.12623479e-06 9.99996944e-01]\n",
      " ...\n",
      " [6.99312912e-04 9.80908820e-01 1.83865595e-02 5.30732267e-06]\n",
      " [2.03487746e-03 2.70687596e-03 6.57312014e-02 9.29527045e-01]\n",
      " [2.86511699e-03 1.97049730e-02 7.16871547e-01 2.60558363e-01]]\n",
      "FCM training RMSE: 971.1924851301346\n",
      "(2030, 24)\n",
      "[[7.62238529e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.50440347e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.65042210e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.52495667e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.63538680e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.69998130e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 4)\n",
      "[[7.62238529e-01 2.09978272e-01 2.27845490e-02 4.99865036e-03]\n",
      " [3.50440347e-05 2.60202720e-04 5.05349706e-05 9.99654218e-01]\n",
      " [5.65042210e-07 1.47923220e-06 2.01655171e-06 9.99995939e-01]\n",
      " ...\n",
      " [7.52495667e-04 1.83154393e-02 9.80925997e-01 6.06782722e-06]\n",
      " [1.63538680e-03 5.47686466e-02 2.21950391e-03 9.41376463e-01]\n",
      " [2.69998130e-03 7.08539858e-01 1.87911338e-02 2.69969027e-01]]\n",
      "FCM training RMSE: 951.1756222564385\n",
      "(2031, 24)\n",
      "[[8.83585530e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.37676361e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.59815227e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.91096166e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.46314722e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.44404069e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 4)\n",
      "[[8.83585530e-01 1.08265875e-01 7.88726747e-03 2.61327311e-04]\n",
      " [2.37676361e-03 1.39284535e-05 2.49820563e-05 9.97584326e-01]\n",
      " [1.59815227e-05 3.86994223e-08 6.52814262e-08 9.99983914e-01]\n",
      " ...\n",
      " [2.91096166e-05 3.94702979e-05 9.99931277e-01 1.43503682e-07]\n",
      " [6.46314722e-01 1.46048572e-03 4.77049575e-03 3.47454297e-01]\n",
      " [8.44404069e-01 2.28291600e-03 4.32115792e-02 1.10101436e-01]]\n",
      "FCM training RMSE: 792.7864480010157\n",
      "(2031, 24)\n",
      "[[8.71207245e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.68810966e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12681957e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.92573195e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.03909595e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.13539071e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 4)\n",
      "[[8.71207245e-01 7.79686980e-03 1.20724788e-01 2.71096739e-04]\n",
      " [2.68810966e-03 2.57722711e-05 1.55354296e-05 9.97270583e-01]\n",
      " [1.12681957e-05 5.90857122e-08 3.58855634e-08 9.99988637e-01]\n",
      " ...\n",
      " [1.92573195e-05 9.99955403e-01 2.52493019e-05 9.06212109e-08]\n",
      " [7.03909595e-01 3.86841778e-03 1.34282929e-03 2.90879158e-01]\n",
      " [9.13539071e-01 2.18539543e-02 1.35063179e-03 6.32563424e-02]]\n",
      "FCM training RMSE: 812.3835684821491\n",
      "(2031, 24)\n",
      "[[5.16935389e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98295897e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99985123e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.05831050e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.76645322e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.70004012e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 4)\n",
      "[[5.16935389e-04 7.96042009e-01 1.91095614e-01 1.23454417e-02]\n",
      " [9.98295897e-01 1.67133180e-03 1.25186497e-05 2.02525650e-05]\n",
      " [9.99985123e-01 1.47547645e-05 4.76919807e-08 7.42744707e-08]\n",
      " ...\n",
      " [7.05831050e-08 1.52599668e-05 1.77967246e-05 9.99966873e-01]\n",
      " [4.76645322e-01 5.16838207e-01 1.68029154e-03 4.83617958e-03]\n",
      " [7.70004012e-02 8.99060702e-01 1.50780580e-03 2.24310907e-02]]\n",
      "FCM training RMSE: 813.7526851364097\n",
      "(2031, 24)\n",
      "[[1.16464091e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.97087415e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12057158e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.55641327e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.47519123e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.58556021e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 4)\n",
      "[[1.16464091e-02 8.39674754e-01 4.06913835e-04 1.48271923e-01]\n",
      " [1.97087415e-05 1.29847286e-03 9.98670913e-01 1.09052364e-05]\n",
      " [1.12057158e-07 2.38312494e-05 9.99975991e-01 6.59741976e-08]\n",
      " ...\n",
      " [2.55641327e-04 4.87460900e-04 5.88560233e-06 9.99251012e-01]\n",
      " [1.47519123e-03 9.88320848e-01 3.16766694e-04 9.88719434e-03]\n",
      " [2.58556021e-03 7.74172582e-04 9.89229094e-06 9.96630375e-01]]\n",
      "FCM training RMSE: 793.651521718962\n",
      "(2030, 30)\n",
      "[[2.19071177e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.71988770e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.48257652e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.40610787e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.89354281e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.81680834e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[2.19071177e-01 4.63872698e-01 8.54842833e-03 4.99629304e-03\n",
      "  3.03511404e-01]\n",
      " [1.71988770e-02 5.85509712e-05 4.30850446e-04 9.82232228e-01\n",
      "  7.94940767e-05]\n",
      " [4.48257652e-05 9.98030354e-01 1.10115594e-04 8.15510937e-06\n",
      "  1.80655002e-03]\n",
      " ...\n",
      " [2.40610787e-06 2.01111516e-04 7.71173170e-03 1.28707249e-06\n",
      "  9.92083464e-01]\n",
      " [9.89354281e-04 4.44969801e-05 8.85885399e-04 9.98034103e-01\n",
      "  4.61607965e-05]\n",
      " [1.81680834e-02 1.19971266e-03 2.23723317e-01 7.50434290e-01\n",
      "  6.47459613e-03]]\n",
      "FCM training RMSE: 900.3394992749545\n",
      "(2030, 30)\n",
      "[[9.30741556e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.87683323e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.02158101e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.57211173e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.28003334e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.15405665e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[9.30741556e-01 1.38840918e-03 5.89998356e-02 8.72536961e-03\n",
      "  1.44829713e-04]\n",
      " [3.87683323e-03 1.39943060e-05 1.31900256e-05 6.61877442e-05\n",
      "  9.96029795e-01]\n",
      " [1.02158101e-04 2.22847682e-07 9.90873572e-08 1.90092206e-07\n",
      "  9.99897330e-01]\n",
      " ...\n",
      " [4.57211173e-05 9.94804527e-01 1.08349845e-04 5.04100165e-03\n",
      "  4.00248406e-07]\n",
      " [7.28003334e-01 1.06009884e-03 1.04380266e-03 1.84362318e-02\n",
      "  2.51456532e-01]\n",
      " [3.15405665e-01 1.47621752e-02 2.72959259e-03 4.77084896e-01\n",
      "  1.90017671e-01]]\n",
      "FCM training RMSE: 792.7486789982669\n",
      "(2030, 30)\n",
      "[[1.21315558e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98557908e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99993903e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.26681655e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.79701422e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.49399384e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[1.21315558e-03 4.85813772e-02 1.75212440e-01 2.23741946e-02\n",
      "  7.52618832e-01]\n",
      " [9.98557908e-01 1.00281055e-05 1.37910633e-03 2.31794881e-05\n",
      "  2.97783633e-05]\n",
      " [9.99993903e-01 4.79890915e-08 5.96978454e-06 4.94293158e-08\n",
      "  3.01232649e-08]\n",
      " ...\n",
      " [3.26681655e-08 8.60558948e-06 5.56286674e-06 9.99982984e-01\n",
      "  2.81471159e-06]\n",
      " [6.79701422e-01 8.96484685e-04 3.07023890e-01 5.81587408e-03\n",
      "  6.56232994e-03]\n",
      " [1.49399384e-02 1.55473996e-04 9.80331175e-01 3.83751997e-03\n",
      "  7.35892526e-04]]\n",
      "FCM training RMSE: 936.2704348672052\n",
      "(2030, 30)\n",
      "[[2.96388995e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.88069974e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.37698376e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.07914744e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.53632015e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.57892322e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[2.96388995e-03 9.72806386e-01 6.01387721e-05 2.35801885e-02\n",
      "  5.89396619e-04]\n",
      " [8.88069974e-05 7.30816857e-03 9.92558014e-01 2.10662655e-05\n",
      "  2.39442867e-05]\n",
      " [1.37698376e-07 6.55388015e-05 9.99934038e-01 8.26431070e-08\n",
      "  2.02695463e-07]\n",
      " ...\n",
      " [1.07914744e-02 7.18591696e-05 6.20158472e-07 1.55308928e-04\n",
      "  9.88980737e-01]\n",
      " [9.53632015e-03 8.53962086e-01 1.35085727e-01 6.77987994e-04\n",
      "  7.37878393e-04]\n",
      " [3.57892322e-01 4.20508302e-01 2.00813149e-01 2.92933220e-03\n",
      "  1.78568953e-02]]\n",
      "FCM training RMSE: 785.2410005006356\n",
      "(2030, 30)\n",
      "[[8.48774902e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.90890876e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.59419836e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.70274978e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.45425215e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.92779681e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[8.48774902e-01 4.06264070e-02 9.34524573e-02 1.61066236e-02\n",
      "  1.03960996e-03]\n",
      " [3.90890876e-05 1.19734734e-05 1.32087404e-03 2.52809771e-05\n",
      "  9.98602782e-01]\n",
      " [2.59419836e-08 3.83058622e-08 3.21659655e-06 3.74890489e-08\n",
      "  9.99996682e-01]\n",
      " ...\n",
      " [1.70274978e-06 4.85809358e-06 3.37667310e-06 9.99990043e-01\n",
      "  1.93447445e-08]\n",
      " [8.45425215e-03 1.00022727e-03 2.69269616e-01 5.66866325e-03\n",
      "  7.15607241e-01]\n",
      " [4.92779681e-04 9.33692821e-05 9.89377777e-01 1.97726870e-03\n",
      "  8.05880512e-03]]\n",
      "FCM training RMSE: 961.1471346473479\n",
      "(2030, 30)\n",
      "[[2.76177829e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99665607e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99995718e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.84453904e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.58243090e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.06289287e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 5)\n",
      "[[2.76177829e-03 4.62127814e-02 8.88195577e-01 5.43682174e-02\n",
      "  8.46164615e-03]\n",
      " [9.99665607e-01 2.19495328e-05 6.88902798e-05 1.99649865e-04\n",
      "  4.39036064e-05]\n",
      " [9.99995718e-01 7.78874583e-07 5.12634180e-07 1.27037645e-06\n",
      "  1.71985586e-06]\n",
      " ...\n",
      " [3.84453904e-06 5.18241640e-04 1.74596215e-04 1.48852862e-02\n",
      "  9.84418031e-01]\n",
      " [9.58243090e-01 6.36847613e-04 5.07948730e-03 3.41692937e-02\n",
      "  1.87128108e-03]\n",
      " [3.06289287e-01 1.35145626e-03 6.66372128e-03 6.66088801e-01\n",
      "  1.96067350e-02]]\n",
      "FCM training RMSE: 962.8520604851915\n",
      "(2031, 30)\n",
      "[[3.96813023e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.57723673e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.18745448e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.19887455e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.02684903e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.93269370e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 5)\n",
      "[[3.96813023e-02 5.90339977e-03 9.30027526e-04 1.00593330e-04\n",
      "  9.53384677e-01]\n",
      " [1.57723673e-05 7.90720016e-05 1.70546377e-05 9.95439464e-01\n",
      "  4.44863701e-03]\n",
      " [9.18745448e-08 1.74924417e-07 2.09124376e-07 9.99913427e-01\n",
      "  8.60974505e-05]\n",
      " ...\n",
      " [1.19887455e-04 5.61945750e-03 9.94207199e-01 4.55949876e-07\n",
      "  5.30000036e-05]\n",
      " [1.02684903e-03 1.81750339e-02 1.06678962e-03 2.35400465e-01\n",
      "  7.44330862e-01]\n",
      " [2.93269370e-03 5.08365752e-01 1.64096003e-02 2.01523382e-01\n",
      "  2.70768572e-01]]\n",
      "FCM training RMSE: 784.4975378713982\n",
      "(2031, 30)\n",
      "[[4.81992918e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94538290e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99921659e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.02807418e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.80049170e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.91400919e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 5)\n",
      "[[4.81992918e-05 9.77963971e-01 4.57787702e-04 1.88747181e-02\n",
      "  2.65532345e-03]\n",
      " [9.94538290e-01 5.33121491e-03 2.00774710e-05 1.80264971e-05\n",
      "  9.23909589e-05]\n",
      " [9.99921659e-01 7.77909448e-05 2.45346828e-07 1.00964326e-07\n",
      "  2.03969504e-07]\n",
      " ...\n",
      " [6.02807418e-07 7.34896860e-05 9.92967614e-01 1.53405378e-04\n",
      "  6.80488778e-03]\n",
      " [1.80049170e-01 8.03744687e-01 8.76637808e-04 8.30571196e-04\n",
      "  1.44989340e-02]\n",
      " [1.91400919e-01 2.55700252e-01 1.52967754e-02 2.64331372e-03\n",
      "  5.34958741e-01]]\n",
      "FCM training RMSE: 781.2464505103164\n",
      "(2031, 30)\n",
      "[[2.63711022e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.01108278e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.89459884e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.34545313e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.60608323e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.87128899e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 5)\n",
      "[[2.63711022e-01 6.66346292e-01 1.35288481e-02 7.03864659e-04\n",
      "  5.57099726e-02]\n",
      " [1.01108278e-05 2.10734996e-03 1.29169865e-05 9.97661441e-01\n",
      "  2.08181321e-04]\n",
      " [2.89459884e-08 1.34969692e-06 3.79844216e-08 9.99992266e-01\n",
      "  6.31706525e-06]\n",
      " ...\n",
      " [1.34545313e-06 6.95138217e-07 9.99996543e-01 5.02100663e-09\n",
      "  1.41167427e-06]\n",
      " [3.60608323e-04 8.97074323e-01 7.60764679e-04 9.73648947e-02\n",
      "  4.43940940e-03]\n",
      " [5.87128899e-05 9.94976148e-01 4.94789358e-04 2.60629710e-03\n",
      "  1.86405235e-03]]\n",
      "FCM training RMSE: 898.7798302498088\n",
      "(2031, 30)\n",
      "[[9.27333071e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.75516181e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.39894734e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.71716690e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99581321e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.04645615e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 5)\n",
      "[[9.27333071e-01 1.46866477e-03 1.07031981e-02 1.66598417e-04\n",
      "  6.03284672e-02]\n",
      " [2.75516181e-03 1.40267980e-05 6.96689605e-05 9.97148305e-01\n",
      "  1.28374079e-05]\n",
      " [1.39894734e-04 3.25133437e-07 2.93407535e-07 9.99859345e-01\n",
      "  1.42194082e-07]\n",
      " ...\n",
      " [6.71716690e-04 6.18316790e-04 6.64967376e-05 5.21448924e-06\n",
      "  9.98638255e-01]\n",
      " [9.99581321e-01 7.25924104e-05 2.19431830e-05 9.27752383e-06\n",
      "  3.14866225e-04]\n",
      " [7.04645615e-04 4.09875116e-04 8.88989107e-03 9.41159451e-06\n",
      "  9.89986177e-01]]\n",
      "FCM training RMSE: 774.913417385383\n",
      "(2030, 48)\n",
      "[[1.40046463e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.53393832e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.77828737e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99233982e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.46804223e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.60415754e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[1.40046463e-03 3.13110455e-04 3.80605713e-02 ... 3.09554755e-05\n",
      "  8.62398573e-04 9.58998770e-01]\n",
      " [5.53393832e-05 3.62507587e-03 3.25485293e-05 ... 1.28887105e-01\n",
      "  1.36066083e-02 8.53459575e-01]\n",
      " [1.77828737e-07 1.61521024e-09 9.99998525e-01 ... 6.11150589e-10\n",
      "  1.52018111e-08 4.59050342e-07]\n",
      " ...\n",
      " [9.99233982e-01 2.61048839e-08 6.54561616e-06 ... 2.51949399e-08\n",
      "  2.67894516e-06 5.20225579e-06]\n",
      " [9.46804223e-05 1.57121578e-03 3.87129126e-05 ... 9.61220936e-01\n",
      "  1.59362509e-03 3.37504632e-02]\n",
      " [3.60415754e-04 9.01594138e-04 4.77005089e-05 ... 3.19429910e-02\n",
      "  9.55513380e-01 3.22487183e-03]]\n",
      "FCM training RMSE: 802.0577035030833\n",
      "(2030, 48)\n",
      "[[2.03154741e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.96859773e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99978707e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.89954818e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.54628685e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.02159870e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[2.03154741e-05 8.78495828e-04 9.84364705e-01 ... 7.40809948e-05\n",
      "  6.32326696e-04 2.08488992e-04]\n",
      " [9.96859773e-01 1.92186775e-05 2.23827524e-03 ... 8.15511212e-05\n",
      "  7.80176810e-04 5.85699892e-06]\n",
      " [9.99978707e-01 2.32492109e-08 1.81645293e-05 ... 2.25934762e-06\n",
      "  7.72828611e-07 3.36901633e-08]\n",
      " ...\n",
      " [1.89954818e-08 1.20001525e-03 2.26300592e-06 ... 1.49305756e-06\n",
      "  1.24322135e-06 9.98786156e-01]\n",
      " [1.54628685e-01 5.94436405e-03 6.92161534e-01 ... 2.30354128e-03\n",
      "  1.42503637e-01 5.84773551e-04]\n",
      " [1.02159870e-05 1.05348914e-05 9.35396161e-06 ... 4.23843450e-05\n",
      "  9.99926000e-01 8.74225449e-07]]\n",
      "FCM training RMSE: 866.4350977590759\n",
      "(2030, 48)\n",
      "[[7.56837299e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.92763228e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.20052900e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.52708955e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.73407601e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.31342758e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[7.56837299e-03 2.77754114e-05 3.11819587e-04 ... 9.75917594e-01\n",
      "  1.92348229e-04 4.04338887e-04]\n",
      " [1.92763228e-05 9.95127084e-01 9.86034235e-06 ... 4.30812929e-03\n",
      "  4.81794112e-04 4.24706125e-06]\n",
      " [1.20052900e-08 9.99976554e-01 3.73356173e-08 ... 2.09145323e-05\n",
      "  2.41067160e-06 2.16345055e-08]\n",
      " ...\n",
      " [3.52708955e-06 6.06698202e-08 9.97966667e-01 ... 6.67203161e-06\n",
      "  2.76748252e-06 1.43096454e-05]\n",
      " [1.73407601e-03 1.16656118e-01 5.61224852e-04 ... 8.61770804e-01\n",
      "  1.10857842e-02 1.21668707e-04]\n",
      " [1.31342758e-04 2.37539364e-03 2.30426127e-04 ... 2.86943071e-03\n",
      "  9.89761248e-01 1.59616886e-05]]\n",
      "FCM training RMSE: 842.4850948922677\n",
      "(2030, 48)\n",
      "[[1.42828482e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.33463919e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.13904365e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.04068254e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.62927530e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.01578243e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[1.42828482e-04 2.00019728e-06 1.65167564e-04 ... 2.95878257e-05\n",
      "  1.81838532e-03 7.05866210e-06]\n",
      " [5.33463919e-08 9.66178397e-05 3.47954185e-07 ... 8.32778643e-08\n",
      "  1.63179890e-07 9.99884624e-01]\n",
      " [2.13904365e-08 9.99149458e-01 2.75917048e-08 ... 3.20370038e-08\n",
      "  1.52744394e-08 8.42448438e-04]\n",
      " ...\n",
      " [6.04068254e-06 2.46669576e-08 7.27203743e-04 ... 9.99257361e-01\n",
      "  2.14440465e-06 2.24285407e-08]\n",
      " [4.62927530e-05 1.95019195e-03 1.59739476e-03 ... 1.15917159e-04\n",
      "  3.26722933e-04 9.07962508e-01]\n",
      " [1.01578243e-04 1.88826047e-03 1.60108727e-02 ... 7.90074322e-04\n",
      "  4.82993144e-04 7.16769378e-02]]\n",
      "FCM training RMSE: 802.720328739317\n",
      "(2030, 48)\n",
      "[[7.77558394e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.47799004e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.97448240e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.41093012e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.66556233e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.97385387e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[7.77558394e-07 8.70639193e-06 9.99418439e-01 ... 1.11867922e-06\n",
      "  4.75851440e-04 4.88632924e-05]\n",
      " [8.47799004e-05 8.57962909e-08 4.98140661e-05 ... 9.99862881e-01\n",
      "  1.57459721e-07 5.95183460e-08]\n",
      " [9.97448240e-01 7.18981185e-08 1.36440632e-05 ... 2.53576172e-03\n",
      "  3.09328827e-08 5.15990921e-08]\n",
      " ...\n",
      " [5.41093012e-08 9.98646363e-01 4.49269078e-06 ... 2.85541375e-08\n",
      "  3.74685138e-06 1.13448978e-05]\n",
      " [1.66556233e-03 8.73271659e-05 7.51345612e-01 ... 2.44525585e-01\n",
      "  2.31734853e-04 3.88840332e-05]\n",
      " [1.97385387e-03 7.74139207e-04 2.52908525e-02 ... 5.12246626e-02\n",
      "  4.74465013e-04 1.11010293e-04]]\n",
      "FCM training RMSE: 823.9285627631409\n",
      "(2030, 48)\n",
      "[[4.47729686e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.64294371e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.57856805e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.30999105e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.46146520e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.71852906e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 8)\n",
      "[[4.47729686e-05 9.32621558e-06 4.93743986e-04 ... 9.99379486e-01\n",
      "  1.25908254e-06 6.09796304e-05]\n",
      " [3.64294371e-07 8.96914578e-08 1.65508895e-07 ... 6.32965453e-05\n",
      "  9.99841312e-01 6.78210385e-08]\n",
      " [7.57856805e-08 9.30665298e-08 4.18727774e-08 ... 1.66541869e-05\n",
      "  3.81650845e-03 7.57762283e-08]\n",
      " ...\n",
      " [6.30999105e-04 9.99353919e-01 2.17571564e-06 ... 2.40078766e-06\n",
      "  1.74271152e-08 7.19140309e-06]\n",
      " [7.46146520e-04 5.68162996e-05 1.47541051e-04 ... 8.32507378e-01\n",
      "  1.64642934e-01 2.75560032e-05]\n",
      " [2.71852906e-02 1.22939355e-03 7.38955330e-04 ... 4.99146080e-02\n",
      "  8.34001777e-02 1.91451540e-04]]\n",
      "FCM training RMSE: 812.2630769244106\n",
      "(2031, 48)\n",
      "[[4.76610315e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.94995572e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98803857e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.07498861e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.02697591e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.19360360e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 8)\n",
      "[[4.76610315e-06 3.87987862e-04 5.71870113e-05 ... 1.50715641e-05\n",
      "  4.81237725e-03 3.00515126e-04]\n",
      " [5.94995572e-05 2.42545499e-07 1.45984696e-06 ... 9.99929778e-01\n",
      "  1.10413020e-07 3.37345178e-08]\n",
      " [9.98803857e-01 3.59677350e-08 1.50255544e-06 ... 1.18533496e-03\n",
      "  1.96700203e-08 2.60996584e-08]\n",
      " ...\n",
      " [4.07498861e-08 8.91754022e-04 3.03865794e-06 ... 3.37181434e-08\n",
      "  3.60885630e-06 9.18766224e-06]\n",
      " [2.02697591e-03 1.81292556e-03 1.59602214e-03 ... 9.35832100e-01\n",
      "  3.62086674e-04 4.60608270e-05]\n",
      " [1.19360360e-03 1.26688304e-02 9.42376078e-01 ... 3.76601088e-02\n",
      "  3.31906074e-04 6.53676835e-05]]\n",
      "FCM training RMSE: 802.764706920425\n",
      "(2031, 48)\n",
      "[[1.63727743e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.37687220e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98377771e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.68130545e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.69263473e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.14330593e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 8)\n",
      "[[1.63727743e-06 2.28656404e-05 1.25519910e-04 ... 1.14653378e-04\n",
      "  1.36147681e-03 4.13833227e-06]\n",
      " [5.37687220e-05 5.09385077e-08 2.13676980e-07 ... 3.26397137e-08\n",
      "  9.65457235e-08 9.99933341e-01]\n",
      " [9.98377771e-01 5.09623323e-08 4.23155214e-08 ... 3.32017879e-08\n",
      "  2.26603630e-08 1.60973321e-03]\n",
      " ...\n",
      " [4.68130545e-08 9.98824967e-01 1.14846419e-03 ... 1.10245159e-05\n",
      "  3.81186246e-06 3.33875530e-08]\n",
      " [2.69263473e-03 1.59303685e-04 2.24573576e-03 ... 6.50211467e-05\n",
      "  4.42197346e-04 8.40050982e-01]\n",
      " [9.14330593e-04 3.70084088e-04 8.04305128e-03 ... 4.72612143e-05\n",
      "  2.18654693e-04 2.33167322e-02]]\n",
      "FCM training RMSE: 802.3454094875282\n",
      "(2031, 48)\n",
      "[[5.15402948e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.31421473e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.17852569e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [7.05154632e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.98557059e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.10271092e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 8)\n",
      "[[5.15402948e-04 7.79610112e-06 7.40255511e-03 ... 6.19588041e-04\n",
      "  1.08545264e-04 3.36640622e-05]\n",
      " [4.31421473e-08 8.24968128e-05 1.38287510e-07 ... 2.93267926e-07\n",
      "  6.85839471e-08 9.99905633e-01]\n",
      " [2.17852569e-08 9.99204423e-01 1.62918512e-08 ... 2.93054930e-08\n",
      "  3.36638155e-08 7.86707517e-04]\n",
      " ...\n",
      " [7.05154632e-06 3.04519256e-08 2.64987440e-06 ... 8.35258710e-04\n",
      "  9.99146211e-01 2.98150694e-08]\n",
      " [2.98557059e-05 1.34846614e-03 2.25382953e-04 ... 1.08658463e-03\n",
      "  7.59179831e-05 9.69493073e-01]\n",
      " [5.10271092e-05 1.00539649e-03 2.52201463e-04 ... 8.49030661e-03\n",
      "  4.05569231e-04 3.55645008e-02]]\n",
      "FCM training RMSE: 792.114888723025\n",
      "(2031, 48)\n",
      "[[6.75319729e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.70368498e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99958583e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.31818362e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.48813521e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.65285034e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 8)\n",
      "[[6.75319729e-05 3.91799752e-03 9.20120128e-01 ... 4.98676410e-02\n",
      "  5.24368340e-04 4.05899967e-03]\n",
      " [9.70368498e-01 5.00674284e-06 2.88049258e-02 ... 1.50511259e-05\n",
      "  1.75566764e-04 3.12637031e-05]\n",
      " [9.99958583e-01 2.58938032e-08 7.50277149e-06 ... 1.83750254e-08\n",
      "  1.38863047e-06 3.20869563e-08]\n",
      " ...\n",
      " [2.31818362e-09 9.99994229e-01 4.29172803e-08 ... 4.62175093e-06\n",
      "  3.13838952e-08 3.63874047e-08]\n",
      " [1.48813521e-05 8.23823958e-04 3.19743280e-03 ... 1.38941077e-04\n",
      "  6.62573252e-05 3.63006798e-05]\n",
      " [1.65285034e-09 2.40718571e-06 6.37554497e-07 ... 9.99994220e-01\n",
      "  1.80965998e-08 2.55156634e-06]]\n",
      "FCM training RMSE: 785.6139438852207\n",
      "(2030, 60)\n",
      "[[1.39270501e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.42218009e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99998277e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.21429927e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.02554836e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.68556772e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[1.39270501e-02 1.03676068e-05 5.88820148e-05 ... 9.82998285e-01\n",
      "  1.02668698e-04 2.24847704e-03]\n",
      " [6.42218009e-05 1.54818832e-01 8.35838106e-02 ... 7.21693752e-01\n",
      "  1.89752520e-04 1.19059950e-03]\n",
      " [9.99998277e-01 5.52664253e-10 8.10184939e-09 ... 6.10320008e-07\n",
      "  8.22807300e-07 1.17721012e-07]\n",
      " ...\n",
      " [4.21429927e-07 1.38782540e-09 2.57107303e-07 ... 3.07948464e-07\n",
      "  1.62814405e-07 4.56011892e-06]\n",
      " [5.02554836e-05 9.31885533e-01 3.67217599e-02 ... 2.59107524e-02\n",
      "  3.93419016e-04 2.86242639e-04]\n",
      " [2.68556772e-06 1.17171373e-03 9.94465396e-01 ... 1.24989747e-04\n",
      "  1.39262459e-05 3.23664768e-04]]\n",
      "FCM training RMSE: 814.4333238836278\n",
      "(2030, 60)\n",
      "[[1.54117054e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.36998391e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.23599500e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.05742343e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.10304267e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99831961e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[1.54117054e-04 3.57985643e-04 3.78676030e-05 ... 5.17633865e-06\n",
      "  7.51080948e-05 1.07685325e-02]\n",
      " [3.36998391e-06 3.04749258e-08 3.74009487e-07 ... 6.01363961e-05\n",
      "  4.49181851e-08 1.91237803e-06]\n",
      " [4.23599500e-07 1.83377126e-08 6.07461011e-07 ... 9.98264894e-01\n",
      "  2.50013867e-08 5.24504234e-06]\n",
      " ...\n",
      " [5.05742343e-07 2.02135086e-06 1.52034582e-06 ... 8.31498682e-09\n",
      "  9.99557378e-01 1.62024888e-06]\n",
      " [6.10304267e-04 2.46115749e-06 1.94332244e-05 ... 1.07693636e-04\n",
      "  5.93901353e-06 2.09253327e-04]\n",
      " [9.99831961e-01 1.27012801e-07 5.02023435e-05 ... 2.49591008e-06\n",
      "  8.58098304e-07 2.38744512e-06]]\n",
      "FCM training RMSE: 813.9657328548737\n",
      "(2030, 60)\n",
      "[[3.60787579e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.94735437e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.02756616e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.48255876e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.22126155e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.67932335e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[3.60787579e-05 8.78963183e-06 9.84462497e-01 ... 1.61621491e-04\n",
      "  3.48360513e-04 5.38516244e-06]\n",
      " [4.94735437e-07 9.99838204e-01 8.67645993e-05 ... 4.28311328e-06\n",
      "  1.73917850e-07 6.78250126e-05]\n",
      " [8.02756616e-07 1.80400954e-03 3.63600295e-06 ... 5.13767168e-07\n",
      "  2.11155884e-08 9.98185408e-01]\n",
      " ...\n",
      " [1.48255876e-06 6.61619264e-09 5.15687627e-07 ... 6.25451959e-07\n",
      "  6.72065665e-04 1.12566479e-08]\n",
      " [2.22126155e-05 1.30983605e-02 9.85754706e-01 ... 7.17047243e-04\n",
      "  6.33202481e-05 1.12924231e-04]\n",
      " [5.67932335e-05 3.65163427e-05 5.18822648e-05 ... 9.99839863e-01\n",
      "  9.42380114e-06 2.18171992e-06]]\n",
      "FCM training RMSE: 818.3875679481381\n",
      "(2030, 60)\n",
      "[[8.63853755e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99860810e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.39631003e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.85701800e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.51615645e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.95637918e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[8.63853755e-06 1.20807774e-02 3.13225661e-04 ... 3.42500945e-04\n",
      "  6.81432927e-05 1.35740733e-04]\n",
      " [9.99860810e-01 1.71281453e-06 1.46346231e-07 ... 2.94584839e-08\n",
      "  4.29452041e-08 3.61888042e-06]\n",
      " [1.39631003e-03 3.96712232e-06 1.70542680e-08 ... 1.61874459e-08\n",
      "  2.17554768e-08 4.14079276e-07]\n",
      " ...\n",
      " [3.85701800e-09 1.44512261e-06 4.24484115e-04 ... 1.53102147e-06\n",
      "  9.99570015e-01 3.35392450e-07]\n",
      " [1.51615645e-02 2.13275818e-04 6.22653414e-05 ... 2.58596529e-06\n",
      "  6.16292080e-06 6.80163586e-04]\n",
      " [2.95637918e-05 1.60845959e-06 6.98539797e-06 ... 8.44522151e-08\n",
      "  5.68151803e-07 9.99884669e-01]]\n",
      "FCM training RMSE: 814.7609940917743\n",
      "(2030, 60)\n",
      "[[1.17766365e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.22137192e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.33804595e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.20189250e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.13269869e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.45505430e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[1.17766365e-05 8.13765854e-07 1.07547853e-06 ... 2.08671039e-05\n",
      "  9.98561522e-01 5.31867830e-05]\n",
      " [4.22137192e-07 4.92035995e-05 9.99915393e-01 ... 4.25492016e-06\n",
      "  3.03439922e-05 3.17515346e-08]\n",
      " [1.33804595e-06 9.97161553e-01 2.82454940e-03 ... 9.47597650e-07\n",
      "  1.14491313e-05 3.76651034e-08]\n",
      " ...\n",
      " [3.20189250e-06 9.36217559e-09 4.62517485e-09 ... 4.03748643e-07\n",
      "  6.87943032e-07 2.08771373e-06]\n",
      " [4.13269869e-04 1.62727969e-03 1.91827442e-01 ... 1.19261117e-02\n",
      "  7.92835796e-01 3.80660764e-05]\n",
      " [2.45505430e-05 1.80807889e-06 3.00658937e-05 ... 9.99916286e-01\n",
      "  1.75686598e-05 9.92800838e-08]]\n",
      "FCM training RMSE: 852.5470217205358\n",
      "(2030, 60)\n",
      "[[3.57203942e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.21612036e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.85366576e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.86356344e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.80364182e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.08983663e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 10)\n",
      "[[3.57203942e-04 6.62894666e-05 8.75931477e-03 ... 3.32153729e-05\n",
      "  4.17725362e-03 5.44679792e-06]\n",
      " [3.21612036e-08 4.52030220e-08 1.95608316e-06 ... 3.58800985e-07\n",
      "  9.45152397e-08 6.65285661e-05]\n",
      " [1.85366576e-08 2.41402610e-08 5.39660925e-06 ... 5.75410688e-07\n",
      "  1.30820096e-08 9.98265543e-01]\n",
      " ...\n",
      " [1.86356344e-06 9.99579433e-01 1.37794684e-06 ... 1.37558458e-06\n",
      "  6.62983805e-07 7.85788401e-09]\n",
      " [2.80364182e-06 6.34628294e-06 2.21359197e-04 ... 1.96555699e-05\n",
      "  1.85575901e-05 1.33967873e-04]\n",
      " [2.08983663e-07 1.32827282e-06 3.85094653e-06 ... 6.86328345e-05\n",
      "  9.40351729e-07 4.22739640e-06]]\n",
      "FCM training RMSE: 805.6869974842917\n",
      "(2031, 60)\n",
      "[[8.50021408e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.98043597e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.79250423e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.33897943e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.63793360e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.63844462e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 10)\n",
      "[[8.50021408e-03 5.71401464e-05 2.41604000e-04 ... 4.14230768e-06\n",
      "  1.34291723e-04 3.61192367e-03]\n",
      " [1.98043597e-06 4.39957628e-08 1.41260724e-07 ... 5.65239527e-05\n",
      "  2.79344864e-06 8.82054440e-08]\n",
      " [5.79250423e-06 2.59507910e-08 1.84522115e-08 ... 9.98339413e-01\n",
      "  3.48122010e-07 1.32537877e-08]\n",
      " ...\n",
      " [2.33897943e-06 9.99188744e-01 8.01243264e-04 ... 1.30316062e-08\n",
      "  9.63182749e-07 1.19195437e-06]\n",
      " [2.63793360e-04 7.01394039e-06 6.72322020e-05 ... 1.25957950e-04\n",
      "  6.99078096e-04 1.98877865e-05]\n",
      " [4.63844462e-06 1.69698698e-06 1.88921814e-05 ... 4.28454654e-06\n",
      "  9.99674477e-01 1.09682829e-06]]\n",
      "FCM training RMSE: 805.9978969046332\n",
      "(2031, 60)\n",
      "[[9.96398516e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.41375006e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.18853923e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.03170806e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.36070487e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.53606084e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 10)\n",
      "[[9.96398516e-01 7.58563312e-06 4.70241287e-05 ... 1.82230680e-04\n",
      "  2.87846024e-03 2.22211126e-04]\n",
      " [4.41375006e-06 9.99952643e-01 9.98877749e-08 ... 7.84256157e-08\n",
      "  5.09139097e-08 2.01263259e-06]\n",
      " [1.18853923e-06 2.26742485e-04 3.73529361e-08 ... 3.49432122e-09\n",
      "  2.52715755e-09 7.20064792e-08]\n",
      " ...\n",
      " [5.03170806e-07 2.02620760e-09 6.60968712e-06 ... 1.84635648e-04\n",
      "  2.55875981e-07 2.75100389e-07]\n",
      " [9.36070487e-02 8.65648337e-01 4.39529800e-04 ... 1.62072625e-03\n",
      "  5.09226598e-04 3.32591770e-02]\n",
      " [4.53606084e-05 2.31765052e-04 9.03106387e-05 ... 5.26411994e-05\n",
      "  3.12368898e-06 9.99092018e-01]]\n",
      "FCM training RMSE: 810.6872560874283\n",
      "(2031, 60)\n",
      "[[3.77957905e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.22541335e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.88052052e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.30872329e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.64099448e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.75666848e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 10)\n",
      "[[3.77957905e-04 1.14734350e-02 5.17688036e-03 ... 8.11203607e-05\n",
      "  1.05030541e-05 9.82239134e-01]\n",
      " [1.22541335e-07 1.40488478e-06 7.35746802e-08 ... 3.48894987e-08\n",
      "  9.99876987e-01 6.75818380e-05]\n",
      " [1.88052052e-08 4.69044269e-06 1.27943246e-08 ... 2.34810616e-08\n",
      "  1.52739713e-03 3.62118005e-06]\n",
      " ...\n",
      " [4.30872329e-04 1.41947775e-06 6.10773211e-07 ... 9.99563289e-01\n",
      "  4.06577757e-09 3.09680935e-07]\n",
      " [5.64099448e-05 1.77711600e-04 1.59028949e-05 ... 5.37215476e-06\n",
      "  1.36562756e-02 9.85292186e-01]\n",
      " [5.75666848e-06 1.21972909e-06 3.08765237e-07 ... 4.31401148e-07\n",
      "  2.14371586e-05 3.33530208e-05]]\n",
      "FCM training RMSE: 799.7283424815207\n",
      "(2031, 60)\n",
      "[[1.19909451e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50530227e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.38060983e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.24854083e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.16581580e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.43829229e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 10)\n",
      "[[1.19909451e-04 3.81073047e-06 5.11104575e-05 ... 5.89147796e-03\n",
      "  6.13748615e-06 9.90274114e-01]\n",
      " [2.50530227e-06 5.70665198e-05 4.16554115e-08 ... 1.91223344e-06\n",
      "  9.99878443e-01 5.94627690e-05]\n",
      " [4.38060983e-07 9.98326435e-01 2.96844438e-08 ... 7.43875999e-06\n",
      "  1.66154686e-03 3.44547587e-06]\n",
      " ...\n",
      " [1.24854083e-08 4.40772583e-09 2.90201879e-07 ... 1.73909545e-06\n",
      "  1.23779931e-09 7.04714275e-08]\n",
      " [1.16581580e-06 1.02389500e-06 3.70260412e-06 ... 9.99623340e-01\n",
      "  2.58110932e-07 3.37921378e-04]\n",
      " [9.43829229e-08 1.19167975e-09 1.23657943e-07 ... 1.01862801e-07\n",
      "  2.75096815e-09 1.83272263e-06]]\n",
      "FCM training RMSE: 786.915114977785\n",
      "(2030, 90)\n",
      "[[2.40250857e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.26088926e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.41721192e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.17026425e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.50982140e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.90222471e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[2.40250857e-08 2.83867535e-03 2.41353877e-07 ... 1.96911231e-07\n",
      "  5.76757113e-05 9.97081506e-01]\n",
      " [1.26088926e-03 1.08833407e-02 5.13230988e-04 ... 1.05976550e-04\n",
      "  4.24026390e-06 4.17374337e-04]\n",
      " [2.41721192e-10 1.23600881e-07 8.32898945e-09 ... 6.51177211e-10\n",
      "  9.99961479e-01 3.07747562e-05]\n",
      " ...\n",
      " [6.17026425e-10 5.46202711e-08 9.15856176e-07 ... 7.03488750e-10\n",
      "  3.38638010e-07 1.43831857e-06]\n",
      " [9.50982140e-03 5.07755898e-04 4.29576268e-04 ... 5.85639983e-05\n",
      "  3.23457853e-06 8.69843992e-05]\n",
      " [1.90222471e-05 1.89968640e-06 2.76330119e-03 ... 7.05717419e-07\n",
      "  7.56946467e-08 7.43186143e-07]]\n",
      "FCM training RMSE: 774.3304516736042\n",
      "(2030, 90)\n",
      "[[2.95639770e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.33048370e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.54098832e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.10492163e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.55226240e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.76374784e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[2.95639770e-05 1.71394294e-04 2.47133410e-05 ... 1.05570626e-04\n",
      "  3.69671090e-04 8.31419922e-06]\n",
      " [1.33048370e-08 2.68717268e-08 2.11881930e-07 ... 3.88298621e-05\n",
      "  3.40216016e-07 9.99887594e-01]\n",
      " [7.54098832e-08 7.69107293e-08 3.69331781e-06 ... 6.93492711e-02\n",
      "  1.78890931e-07 6.41304883e-03]\n",
      " ...\n",
      " [3.10492163e-04 9.99660562e-01 1.33460825e-08 ... 9.41994407e-10\n",
      "  9.65067703e-08 1.08665434e-10]\n",
      " [2.55226240e-06 9.88726852e-06 1.60508215e-05 ... 7.68078741e-04\n",
      "  3.29542811e-04 1.04780076e-02]\n",
      " [1.76374784e-07 6.06460296e-07 1.85361577e-05 ... 1.48281175e-06\n",
      "  4.79401801e-04 1.19828369e-05]]\n",
      "FCM training RMSE: 795.6383720847525\n",
      "(2030, 90)\n",
      "[[4.67305500e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.01801363e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.83608745e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.25176634e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.13055388e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99599795e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[4.67305500e-06 7.33166619e-05 1.02702493e-05 ... 4.34498035e-05\n",
      "  1.21344281e-07 6.31998903e-06]\n",
      " [1.01801363e-05 9.74312560e-06 7.55962862e-07 ... 3.16099628e-07\n",
      "  6.26345252e-01 2.33718837e-07]\n",
      " [4.83608745e-08 1.94740803e-06 2.86349451e-09 ... 1.20179111e-09\n",
      "  9.81277738e-05 2.48532834e-09]\n",
      " ...\n",
      " [2.25176634e-08 2.75528048e-08 3.88106254e-06 ... 1.38717045e-08\n",
      "  1.35700542e-10 9.98631908e-01]\n",
      " [3.13055388e-04 1.19881590e-04 5.69517455e-05 ... 1.02115148e-05\n",
      "  2.01038326e-03 9.00784626e-06]\n",
      " [9.99599795e-01 2.80806825e-06 3.36242111e-05 ... 7.61447676e-07\n",
      "  6.25120598e-05 2.23890276e-06]]\n",
      "FCM training RMSE: 789.7121549525693\n",
      "(2030, 90)\n",
      "[[1.77638234e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.16520303e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.43924479e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.67301992e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.73828424e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.72692925e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[1.77638234e-09 1.02836795e-08 2.93147889e-10 ... 9.66461525e-09\n",
      "  3.00119757e-09 2.30856651e-08]\n",
      " [1.16520303e-07 6.83026571e-08 3.85556234e-05 ... 4.99079149e-08\n",
      "  1.51499907e-08 4.42134997e-07]\n",
      " [3.43924479e-08 1.26640075e-09 9.99787418e-01 ... 7.37228833e-09\n",
      "  1.63975648e-09 1.14613462e-08]\n",
      " ...\n",
      " [4.67301992e-08 1.46106875e-06 1.72655364e-10 ... 5.42843527e-05\n",
      "  9.99376917e-01 1.17142004e-07]\n",
      " [7.73828424e-07 3.63993771e-06 6.66617960e-06 ... 8.12870882e-07\n",
      "  2.53256444e-07 1.80592865e-05]\n",
      " [1.72692925e-05 3.35166073e-06 5.86315569e-07 ... 1.90850311e-06\n",
      "  1.76903342e-07 2.18748883e-03]]\n",
      "FCM training RMSE: 779.6388085485111\n",
      "(2030, 90)\n",
      "[[2.95636019e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.56414755e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99840728e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.76075529e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.36966510e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.61686541e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[2.95636019e-08 1.92923125e-06 2.47197793e-06 ... 5.99349167e-08\n",
      "  2.29962876e-06 2.31322595e-07]\n",
      " [1.56414755e-04 2.28988247e-07 5.60919679e-08 ... 1.26084127e-05\n",
      "  1.73250973e-01 5.42607574e-07]\n",
      " [9.99840728e-01 1.15266290e-09 1.33822743e-09 ... 1.16780617e-05\n",
      "  3.94549652e-05 2.84553904e-08]\n",
      " ...\n",
      " [3.76075529e-10 5.71398963e-05 1.23746970e-07 ... 1.79638403e-09\n",
      "  1.54393004e-09 1.00619510e-07]\n",
      " [3.36966510e-05 1.53157128e-05 8.06322731e-07 ... 1.79135365e-05\n",
      "  8.02573209e-01 5.12193276e-06]\n",
      " [3.61686541e-07 1.66913643e-06 3.32406989e-08 ... 9.01615855e-06\n",
      "  8.27789929e-06 1.62285278e-05]]\n",
      "FCM training RMSE: 781.0402142217138\n",
      "(2030, 90)\n",
      "[[2.31940825e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.22520981e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.41727380e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.95452648e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.32256095e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94714070e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 15)\n",
      "[[2.31940825e-06 1.34152161e-05 6.61894499e-06 ... 5.03480371e-08\n",
      "  4.13222687e-05 3.32384073e-06]\n",
      " [4.22520981e-06 1.18919454e-07 9.21300150e-02 ... 9.07412402e-01\n",
      "  2.46890182e-07 3.89379748e-07]\n",
      " [8.41727380e-08 8.33751740e-09 7.56298386e-05 ... 5.73814339e-04\n",
      "  5.82931969e-09 8.04928361e-09]\n",
      " ...\n",
      " [2.95452648e-07 4.81948289e-07 7.44815433e-09 ... 7.62345009e-10\n",
      "  1.54375678e-07 1.44733723e-04]\n",
      " [3.32256095e-05 3.99010436e-07 9.95057274e-01 ... 3.84077674e-04\n",
      "  1.45406114e-06 4.91923868e-06]\n",
      " [9.94714070e-01 3.25634675e-06 1.15985919e-03 ... 6.28882752e-04\n",
      "  9.00369638e-06 1.33506296e-04]]\n",
      "FCM training RMSE: 759.1574446896009\n",
      "(2031, 90)\n",
      "[[5.03916435e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.27490625e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.35617508e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.18026518e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.30239483e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.42110812e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 15)\n",
      "[[5.03916435e-05 4.34725030e-05 1.59202436e-04 ... 1.98486566e-02\n",
      "  1.24604616e-05 1.12879527e-04]\n",
      " [8.27490625e-03 2.80230394e-07 4.26739625e-08 ... 6.87261797e-07\n",
      "  3.94273558e-08 1.00093232e-07]\n",
      " [8.35617508e-02 2.07925455e-07 1.84317685e-08 ... 5.75471784e-07\n",
      "  2.08959054e-08 2.15904846e-08]\n",
      " ...\n",
      " [4.18026518e-10 4.29699405e-07 3.63954527e-08 ... 1.67957871e-07\n",
      "  5.78644438e-04 9.99418330e-01]\n",
      " [2.30239483e-02 2.28257049e-05 3.27513081e-06 ... 9.38101518e-05\n",
      "  3.66482551e-06 2.15248034e-05]\n",
      " [3.42110812e-05 8.01899869e-05 4.95930905e-07 ... 5.16578875e-06\n",
      "  1.38316730e-06 6.95844422e-06]]\n",
      "FCM training RMSE: 769.4124288392942\n",
      "(2031, 90)\n",
      "[[1.26911349e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.61428860e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.80456615e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.11576700e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.50127104e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.70848262e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 15)\n",
      "[[1.26911349e-07 5.99739417e-05 5.73597292e-07 ... 1.52926467e-06\n",
      "  2.10941883e-05 1.91869299e-04]\n",
      " [7.61428860e-06 9.60591654e-08 5.67123759e-05 ... 3.39461985e-08\n",
      "  1.41805612e-07 3.07421898e-06]\n",
      " [9.80456615e-06 2.28442531e-09 4.81529188e-07 ... 2.05658949e-09\n",
      "  1.12948411e-09 6.20799917e-07]\n",
      " ...\n",
      " [2.11576700e-09 1.33530647e-07 3.15352448e-09 ... 8.84553963e-08\n",
      "  2.08457914e-08 1.05700069e-07]\n",
      " [5.50127104e-06 9.51184175e-07 1.76010499e-04 ... 1.67907918e-07\n",
      "  2.01582302e-06 2.65398131e-05]\n",
      " [8.70848262e-06 7.62474769e-08 9.99095880e-01 ... 1.81492708e-08\n",
      "  1.37945986e-07 5.83311803e-07]]\n",
      "FCM training RMSE: 768.5972935607683\n",
      "(2031, 90)\n",
      "[[4.44030253e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.52880824e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.98908474e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.76137344e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.70411585e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.57288076e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 15)\n",
      "[[4.44030253e-03 1.49224352e-04 5.47166834e-04 ... 9.77777562e-01\n",
      "  6.03830251e-05 1.96075078e-04]\n",
      " [2.52880824e-08 2.16161900e-08 8.49917160e-08 ... 2.22729530e-05\n",
      "  1.05195366e-08 3.15010310e-07]\n",
      " [7.98908474e-09 6.24925845e-09 2.30045051e-08 ... 2.15341387e-06\n",
      "  1.25450821e-08 9.15579822e-08]\n",
      " ...\n",
      " [1.76137344e-07 3.75743666e-04 2.22737811e-05 ... 9.04107381e-08\n",
      "  9.99594245e-01 3.97963241e-07]\n",
      " [1.70411585e-05 2.61423586e-05 1.33694303e-04 ... 9.83057948e-01\n",
      "  5.01210857e-06 2.61180016e-04]\n",
      " [7.57288076e-07 2.98529545e-06 9.18399895e-05 ... 7.86092739e-05\n",
      "  8.18492038e-07 4.26272545e-02]]\n",
      "FCM training RMSE: 760.8266578852309\n",
      "(2031, 90)\n",
      "[[1.14905285e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.49758827e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.14977288e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.64592709e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.14661446e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.27303744e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 15)\n",
      "[[1.14905285e-07 1.64743185e-04 5.55636752e-07 ... 2.14685398e-06\n",
      "  3.48588891e-07 5.37443709e-07]\n",
      " [1.49758827e-07 1.92601315e-04 9.66503348e-07 ... 3.31770891e-08\n",
      "  5.40833969e-08 1.07724587e-07]\n",
      " [2.14977288e-08 6.28617530e-07 1.56654037e-08 ... 1.85219907e-09\n",
      "  2.82093332e-09 1.75726679e-09]\n",
      " ...\n",
      " [8.64592709e-09 2.29930508e-09 1.17186703e-09 ... 1.01429662e-03\n",
      "  1.42346398e-08 2.06683026e-09]\n",
      " [8.14661446e-06 1.79543843e-04 2.36201249e-06 ... 4.35354722e-05\n",
      "  8.32601632e-06 1.67133125e-06]\n",
      " [8.27303744e-10 1.78429600e-08 7.36120052e-09 ... 5.99395158e-07\n",
      "  9.60344968e-09 8.39814637e-08]]\n",
      "FCM training RMSE: 757.4646960817397\n",
      "(2030, 120)\n",
      "[[4.13054771e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42110073e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.34650700e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.43560753e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25145834e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.33353354e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[4.13054771e-06 6.08083220e-05 1.04749183e-06 ... 1.30056164e-06\n",
      "  1.95605587e-07 9.99725716e-08]\n",
      " [1.42110073e-05 7.83409525e-04 9.93721479e-01 ... 1.15106172e-04\n",
      "  7.86472547e-05 2.48116277e-03]\n",
      " [2.34650700e-10 1.57182220e-10 7.04811779e-11 ... 2.55611602e-11\n",
      "  4.74028190e-11 9.19075969e-12]\n",
      " ...\n",
      " [4.43560753e-10 2.06244398e-11 5.29674478e-11 ... 1.01388234e-11\n",
      "  5.27306516e-10 1.22939055e-11]\n",
      " [1.25145834e-06 3.99650663e-05 9.87376756e-01 ... 4.86490534e-06\n",
      "  2.34143697e-05 2.30547832e-04]\n",
      " [5.33353354e-05 2.40461832e-06 1.04385015e-04 ... 3.84602946e-05\n",
      "  3.66878124e-02 9.62946438e-01]]\n",
      "FCM training RMSE: 768.8252197308245\n",
      "(2030, 120)\n",
      "[[7.90681373e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.45419132e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.86168858e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.33439380e-12 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.14902900e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.56215021e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[7.90681373e-09 3.99627994e-08 5.19360476e-08 ... 5.70962831e-08\n",
      "  1.15608996e-05 1.60455069e-08]\n",
      " [9.45419132e-01 3.36502083e-08 3.90599492e-07 ... 6.70053093e-05\n",
      "  1.12252169e-07 7.15881497e-06]\n",
      " [3.86168858e-04 3.88692343e-09 8.75386887e-08 ... 1.13047683e-06\n",
      "  3.85223510e-09 2.24863248e-05]\n",
      " ...\n",
      " [1.33439380e-12 1.76513572e-05 6.03832883e-10 ... 1.69391158e-11\n",
      "  5.97431821e-10 1.43644094e-11]\n",
      " [4.14902900e-04 2.33053430e-07 1.42572177e-06 ... 1.52285336e-04\n",
      "  1.29376258e-06 4.80920283e-06]\n",
      " [9.56215021e-06 9.72113279e-08 1.98163491e-05 ... 9.97325248e-01\n",
      "  1.72672263e-07 1.19840907e-05]]\n",
      "FCM training RMSE: 765.7601539847583\n",
      "(2030, 120)\n",
      "[[3.19337107e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.96840763e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.57290916e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.68064030e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.87841144e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.57831590e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[3.19337107e-09 3.46642061e-08 8.49362914e-09 ... 1.21091042e-09\n",
      "  1.84485223e-08 1.23285390e-06]\n",
      " [1.96840763e-03 2.61604697e-09 8.07874781e-08 ... 1.33127653e-06\n",
      "  4.14936181e-07 3.53538581e-07]\n",
      " [7.57290916e-01 1.31365516e-08 2.60188199e-06 ... 1.19721454e-02\n",
      "  5.28160944e-07 2.40495413e-05]\n",
      " ...\n",
      " [6.68064030e-10 9.95540146e-01 2.18058181e-08 ... 9.24793364e-10\n",
      "  1.40577128e-08 6.31454131e-08]\n",
      " [7.87841144e-05 2.57735732e-07 1.41014304e-06 ... 1.82957954e-06\n",
      "  1.79172848e-05 1.65690314e-05]\n",
      " [2.57831590e-08 2.24561134e-09 3.92697882e-07 ... 1.19671877e-08\n",
      "  9.99952795e-01 9.42214931e-09]]\n",
      "FCM training RMSE: 754.5544518401157\n",
      "(2030, 120)\n",
      "[[1.46516279e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.35504097e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.05406105e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.84193539e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.40419304e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.73612685e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[1.46516279e-09 9.07785016e-08 3.14788030e-06 ... 1.03142072e-08\n",
      "  3.01481516e-06 8.22872715e-09]\n",
      " [6.35504097e-09 2.34552397e-08 2.37186988e-06 ... 1.50020479e-07\n",
      "  1.26253636e-04 1.30346693e-08]\n",
      " [5.05406105e-09 2.71497282e-09 1.92977395e-07 ... 2.23215715e-08\n",
      "  2.85407413e-06 5.47200175e-09]\n",
      " ...\n",
      " [8.84193539e-06 7.95091370e-11 8.63124652e-10 ... 9.47188196e-10\n",
      "  3.20392508e-11 9.99985846e-01]\n",
      " [2.40419304e-07 1.71402854e-06 2.67054385e-03 ... 1.37729515e-05\n",
      "  9.78051978e-01 9.13989646e-07]\n",
      " [7.73612685e-08 1.60377479e-07 2.40916937e-04 ... 1.21021904e-03\n",
      "  1.61196117e-05 2.62440412e-07]]\n",
      "FCM training RMSE: 760.9950654748562\n",
      "(2030, 120)\n",
      "[[9.95392877e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.36928744e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.22304816e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.72905640e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.61062219e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.98265833e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[9.95392877e-01 3.96500376e-07 1.89595744e-07 ... 1.22982966e-05\n",
      "  5.92998170e-09 1.39246750e-06]\n",
      " [1.36928744e-06 3.45100626e-08 1.14349901e-06 ... 1.33992569e-07\n",
      "  8.17839221e-05 1.23214800e-06]\n",
      " [1.22304816e-07 7.71053587e-09 1.77666577e-07 ... 5.30612241e-09\n",
      "  9.82036933e-01 3.79162205e-08]\n",
      " ...\n",
      " [3.72905640e-10 6.95521918e-11 3.94298017e-11 ... 3.20585309e-11\n",
      "  1.61569704e-13 2.79816189e-10]\n",
      " [9.61062219e-05 4.07820376e-07 1.44328381e-05 ... 4.33299975e-06\n",
      "  1.23725184e-05 7.99550868e-05]\n",
      " [5.98265833e-06 1.44032026e-07 5.33736697e-03 ... 9.97195783e-07\n",
      "  1.93642422e-06 4.63153614e-03]]\n",
      "FCM training RMSE: 776.233928096143\n",
      "(2030, 120)\n",
      "[[1.37388562e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.26937847e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.34360673e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.24525935e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.01944755e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94233881e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 20)\n",
      "[[1.37388562e-08 2.23274894e-08 2.14337268e-07 ... 1.08511981e-05\n",
      "  6.28263847e-08 2.50531045e-06]\n",
      " [3.26937847e-06 8.31066318e-09 9.81923398e-09 ... 5.39399515e-08\n",
      "  3.17790864e-09 1.69507334e-04]\n",
      " [1.34360673e-07 4.07099960e-09 1.31041448e-09 ... 3.98769746e-08\n",
      "  3.75200845e-10 1.03545234e-06]\n",
      " ...\n",
      " [2.24525935e-10 1.08898707e-07 4.51972353e-05 ... 2.44961950e-08\n",
      "  9.99788369e-01 4.21206136e-10]\n",
      " [7.01944755e-05 4.21684821e-07 1.64239578e-06 ... 4.81111918e-06\n",
      "  4.75860453e-07 9.98059793e-01]\n",
      " [9.94233881e-01 4.49460490e-06 5.73842754e-06 ... 7.39556860e-07\n",
      "  4.20732196e-07 2.44334759e-05]]\n",
      "FCM training RMSE: 759.6871923297131\n",
      "(2031, 120)\n",
      "[[2.01199360e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.02196696e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25965640e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.16363723e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.84227220e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.26043499e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 20)\n",
      "[[2.01199360e-07 1.70677483e-09 5.33224110e-09 ... 4.95465524e-06\n",
      "  4.61407420e-09 8.39078939e-06]\n",
      " [2.02196696e-08 8.51741044e-07 8.25964629e-06 ... 8.18187170e-08\n",
      "  2.56559788e-08 9.59775300e-07]\n",
      " [1.25965640e-08 4.73966009e-05 4.31103510e-06 ... 5.19429765e-07\n",
      "  2.33701794e-07 2.70030533e-06]\n",
      " ...\n",
      " [8.16363723e-09 1.24857234e-09 1.17143118e-09 ... 1.81822156e-07\n",
      "  2.26440587e-07 3.43302128e-07]\n",
      " [8.84227220e-07 2.55864351e-06 8.16813943e-05 ... 2.59936480e-06\n",
      "  3.60659302e-07 1.25406737e-04]\n",
      " [4.26043499e-08 4.83515640e-06 9.99880619e-01 ... 7.08355192e-08\n",
      "  3.94264872e-07 8.66142710e-06]]\n",
      "FCM training RMSE: 756.4540810827642\n",
      "(2031, 120)\n",
      "[[4.85429722e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.70076818e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.45064199e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.74928142e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.79049763e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.21898456e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 20)\n",
      "[[4.85429722e-06 9.07501772e-07 4.71303512e-05 ... 9.84234029e-06\n",
      "  9.99129254e-01 2.61827963e-04]\n",
      " [1.70076818e-08 3.09735764e-07 3.42121188e-08 ... 4.85589444e-07\n",
      "  4.65611689e-07 2.23253738e-06]\n",
      " [9.45064199e-09 4.84494287e-08 8.98436319e-09 ... 2.48955179e-06\n",
      "  2.29441261e-07 1.40310669e-06]\n",
      " ...\n",
      " [8.74928142e-08 1.43256769e-07 1.47475503e-07 ... 4.91450581e-08\n",
      "  3.09427652e-07 4.26588252e-07]\n",
      " [7.79049763e-07 3.74280716e-05 2.97830884e-06 ... 1.63064733e-05\n",
      "  8.07188640e-05 5.88058339e-04]\n",
      " [7.21898456e-08 2.43534270e-03 1.85855297e-07 ... 4.85368793e-07\n",
      "  1.34685980e-06 4.46519634e-05]]\n",
      "FCM training RMSE: 762.0498928339757\n",
      "(2031, 120)\n",
      "[[7.48626331e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.32697351e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.51108910e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.22523598e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.50965565e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.77328396e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 20)\n",
      "[[7.48626331e-06 3.04692114e-07 1.05893811e-05 ... 2.65980926e-08\n",
      "  6.78987390e-07 3.73777905e-06]\n",
      " [1.32697351e-08 1.00046395e-08 3.07530695e-08 ... 9.82307002e-01\n",
      "  6.96461517e-09 1.51266133e-02]\n",
      " [1.51108910e-08 1.38667312e-08 8.42673141e-09 ... 1.33918054e-04\n",
      "  1.46816618e-08 2.30060651e-04]\n",
      " ...\n",
      " [1.22523598e-07 9.98549419e-01 2.09584788e-08 ... 1.61079269e-10\n",
      "  8.00754356e-08 1.74857268e-09]\n",
      " [6.50965565e-07 6.17891018e-07 2.85880576e-06 ... 1.13746513e-03\n",
      "  2.18248980e-07 9.22388183e-01]\n",
      " [6.77328396e-08 1.44462937e-07 2.20740614e-07 ... 1.21712851e-05\n",
      "  2.75844620e-08 1.19404503e-05]]\n",
      "FCM training RMSE: 762.902900241343\n",
      "(2031, 120)\n",
      "[[2.25985551e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.36492551e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16580948e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.67752130e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.51887812e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.37451851e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 20)\n",
      "[[2.25985551e-06 3.32024946e-08 1.50624774e-07 ... 4.78738667e-07\n",
      "  1.99338066e-07 3.16005399e-05]\n",
      " [1.36492551e-06 5.39783332e-05 3.14532997e-07 ... 5.01096116e-08\n",
      "  1.72865943e-08 1.01568374e-07]\n",
      " [2.16580948e-05 9.10566640e-06 1.42646513e-07 ... 3.43289285e-08\n",
      "  9.96937398e-09 2.32220611e-07]\n",
      " ...\n",
      " [2.67752130e-07 1.41498350e-09 8.86146547e-09 ... 5.34026774e-08\n",
      "  5.70708047e-08 4.55665160e-05]\n",
      " [1.51887812e-01 2.19773135e-06 5.43867535e-06 ... 2.44942168e-05\n",
      "  1.01616005e-05 8.33571556e-01]\n",
      " [4.37451851e-08 1.02630804e-08 1.01161056e-07 ... 4.90166427e-07\n",
      "  9.10609492e-07 9.51225105e-07]]\n",
      "FCM training RMSE: 743.0418593256186\n",
      "(2030, 150)\n",
      "[[5.31107882e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.05134476e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.33763637e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.40786383e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.27699290e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.21967640e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[5.31107882e-08 1.15612397e-07 1.25003530e-03 ... 1.18266682e-06\n",
      "  5.66510015e-07 9.98547606e-01]\n",
      " [4.05134476e-06 8.24561571e-04 5.65520517e-03 ... 4.04219790e-04\n",
      "  3.83208143e-01 2.82824678e-04]\n",
      " [1.33763637e-07 8.35931733e-10 3.52801493e-07 ... 8.58079960e-09\n",
      "  1.30884929e-08 4.89894525e-05]\n",
      " ...\n",
      " [1.40786383e-09 3.57264121e-11 5.00633776e-08 ... 7.62149925e-10\n",
      "  8.89971297e-09 3.02009112e-08]\n",
      " [1.27699290e-06 6.16031972e-05 3.19133849e-05 ... 3.15997465e-06\n",
      "  8.82435683e-03 6.28420309e-06]\n",
      " [6.21967640e-07 4.52723887e-06 1.89787751e-05 ... 1.61804532e-04\n",
      "  3.64898547e-03 1.59559352e-06]]\n",
      "FCM training RMSE: 740.6667803737101\n",
      "(2030, 150)\n",
      "[[1.51867963e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.85607134e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.30747845e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.42708392e-13 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98036018e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.72878067e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[1.51867963e-04 1.05900930e-05 6.01063002e-07 ... 2.15039029e-04\n",
      "  9.70679951e-07 2.48352581e-05]\n",
      " [1.85607134e-04 8.60558188e-07 2.92014848e-06 ... 8.14745854e-09\n",
      "  3.53185657e-04 8.52000845e-09]\n",
      " [1.30747845e-05 8.55485102e-05 1.57684626e-06 ... 8.99506199e-09\n",
      "  2.05512626e-01 4.80709398e-09]\n",
      " ...\n",
      " [1.42708392e-13 2.87639958e-13 8.17200381e-14 ... 5.88467025e-12\n",
      "  2.73053965e-14 5.87058287e-13]\n",
      " [9.98036018e-01 1.06099720e-05 3.87881072e-05 ... 5.28412061e-07\n",
      "  2.04659809e-04 5.35320026e-07]\n",
      " [4.72878067e-06 1.54231469e-07 9.99531380e-01 ... 3.55989817e-08\n",
      "  4.09505856e-07 4.10837380e-08]]\n",
      "FCM training RMSE: 754.5658851166983\n",
      "(2030, 150)\n",
      "[[1.00090695e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.59864489e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.07050050e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.47325978e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.99080692e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.47432605e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[1.00090695e-07 1.75459001e-08 1.20737633e-07 ... 7.19401922e-09\n",
      "  1.52411790e-08 8.88042627e-10]\n",
      " [5.59864489e-08 1.70176552e-06 1.98985168e-08 ... 1.44622660e-08\n",
      "  6.50353441e-05 2.62490698e-01]\n",
      " [1.07050050e-08 3.02202519e-07 1.23615892e-08 ... 1.02738051e-08\n",
      "  8.50863757e-02 6.74573171e-04]\n",
      " ...\n",
      " [1.47325978e-06 5.27908438e-12 4.62341936e-11 ... 1.60910871e-06\n",
      "  5.49090589e-13 5.27822089e-14]\n",
      " [2.99080692e-06 2.48250036e-05 2.81886187e-07 ... 2.47034587e-07\n",
      "  5.86683430e-05 1.98659419e-04]\n",
      " [3.47432605e-07 9.96730561e-01 1.81068246e-08 ... 3.24629033e-08\n",
      "  3.02323707e-07 2.45892382e-06]]\n",
      "FCM training RMSE: 766.6032762752077\n",
      "(2030, 150)\n",
      "[[2.02668843e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.33834042e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.29829492e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.96564917e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.72871678e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00946176e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[2.02668843e-06 4.54893160e-08 2.86750870e-08 ... 1.55395540e-10\n",
      "  8.97819725e-09 7.48518569e-09]\n",
      " [3.33834042e-07 9.25720837e-08 4.28435142e-07 ... 2.61577829e-05\n",
      "  2.37487131e-07 7.73232449e-09]\n",
      " [1.29829492e-07 4.24831698e-09 6.97830880e-09 ... 9.97964876e-01\n",
      "  1.92066835e-08 1.40547533e-09]\n",
      " ...\n",
      " [2.96564917e-08 7.70106116e-06 2.51876192e-08 ... 4.03142566e-11\n",
      "  2.90754866e-08 1.49541668e-08]\n",
      " [1.72871678e-05 1.29806584e-05 8.33061972e-05 ... 8.91246813e-06\n",
      "  1.19195039e-05 2.13920739e-07]\n",
      " [3.00946176e-07 9.97352693e-06 9.95746140e-04 ... 2.16428083e-07\n",
      "  7.77335600e-04 1.71694491e-08]]\n",
      "FCM training RMSE: 764.5870660647362\n",
      "(2030, 150)\n",
      "[[2.26755101e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00953337e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.15053302e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.42911481e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.43891259e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.38077040e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[2.26755101e-07 9.64987405e-07 3.72476564e-09 ... 2.42767597e-07\n",
      "  7.66187476e-08 9.99517691e-01]\n",
      " [3.00953337e-08 1.42821099e-08 5.90541171e-02 ... 1.34338197e-08\n",
      "  6.08929869e-07 2.68596041e-07]\n",
      " [7.15053302e-09 3.85613382e-08 8.75584419e-04 ... 1.37650260e-08\n",
      "  2.70780718e-07 2.33775322e-07]\n",
      " ...\n",
      " [4.42911481e-08 4.35116762e-09 1.40387336e-12 ... 9.99926117e-01\n",
      "  1.41306874e-10 4.76166684e-09]\n",
      " [3.43891259e-05 3.39383613e-06 9.47986030e-04 ... 7.04597889e-06\n",
      "  1.45583863e-04 3.17835722e-04]\n",
      " [7.38077040e-07 2.52178730e-08 1.90180470e-06 ... 1.40354188e-07\n",
      "  9.97548029e-01 4.98266549e-07]]\n",
      "FCM training RMSE: 756.9854023447218\n",
      "(2030, 150)\n",
      "[[7.18352022e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.15964614e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.28993231e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.29788816e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.98466332e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.74618086e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2030, 25)\n",
      "[[7.18352022e-03 1.67654438e-07 2.95997672e-08 ... 5.18106522e-05\n",
      "  8.11245376e-09 9.70516315e-08]\n",
      " [1.15964614e-06 3.01266659e-09 5.61316068e-07 ... 1.39933802e-04\n",
      "  8.48446393e-03 2.52376929e-08]\n",
      " [1.28993231e-07 4.44245214e-09 3.63384132e-05 ... 9.34849103e-06\n",
      "  2.41205837e-04 1.13417721e-07]\n",
      " ...\n",
      " [2.29788816e-09 9.99631447e-01 1.40833918e-10 ... 4.73199439e-10\n",
      "  1.05651706e-11 6.94982663e-09]\n",
      " [2.98466332e-03 2.81924885e-07 3.30049308e-06 ... 9.86547036e-01\n",
      "  8.42076515e-05 8.69456164e-07]\n",
      " [4.74618086e-05 7.51776983e-07 6.63403816e-05 ... 1.15747162e-04\n",
      "  5.16302975e-05 8.26584390e-05]]\n",
      "FCM training RMSE: 741.4547826008254\n",
      "(2031, 150)\n",
      "[[6.42261878e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.24896576e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.25543248e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.48615607e-14 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.57751038e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.84945710e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 25)\n",
      "[[6.42261878e-09 8.25897574e-06 4.05263284e-04 ... 2.07681748e-08\n",
      "  2.90049670e-06 3.17670152e-06]\n",
      " [5.24896576e-05 5.43032477e-08 5.01791541e-07 ... 9.27587874e-01\n",
      "  7.20566164e-02 4.99775351e-08]\n",
      " [9.25543248e-01 1.07824924e-08 2.14767047e-07 ... 1.13135511e-03\n",
      "  8.18812997e-05 1.04728438e-08]\n",
      " ...\n",
      " [4.48615607e-14 7.97018422e-11 1.48303451e-10 ... 4.88660527e-14\n",
      "  4.78971564e-13 1.12988231e-11]\n",
      " [1.57751038e-06 2.37760956e-07 2.98128122e-06 ... 1.73819250e-04\n",
      "  9.97639440e-01 1.61294302e-07]\n",
      " [4.84945710e-07 1.35425259e-07 7.55019358e-07 ... 1.42830186e-05\n",
      "  2.73426205e-05 1.18577309e-07]]\n",
      "FCM training RMSE: 753.2688666327905\n",
      "(2031, 150)\n",
      "[[8.86414550e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.12131475e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.27052753e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.96533678e-17 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.05446499e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.32459417e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 25)\n",
      "[[8.86414550e-08 1.26262180e-03 3.38163785e-06 ... 1.45161617e-08\n",
      "  2.77000802e-05 2.24589300e-07]\n",
      " [2.12131475e-07 3.05288993e-06 2.52778224e-08 ... 1.33340460e-06\n",
      "  2.03276538e-09 9.42180639e-09]\n",
      " [7.27052753e-05 9.37302433e-07 9.80930007e-08 ... 4.50092148e-01\n",
      "  1.14509892e-08 2.36352857e-07]\n",
      " ...\n",
      " [6.96533678e-17 5.19575104e-16 1.93425978e-14 ... 7.14181270e-18\n",
      "  4.01068601e-15 2.38681607e-15]\n",
      " [2.05446499e-05 7.72297001e-01 6.23893166e-05 ... 1.37554296e-05\n",
      "  2.78973846e-06 4.86408007e-06]\n",
      " [7.32459417e-06 1.40074789e-05 4.28418628e-04 ... 1.88371765e-07\n",
      "  5.68147205e-08 1.06939575e-05]]\n",
      "FCM training RMSE: 755.5942930427742\n",
      "(2031, 150)\n",
      "[[3.01013698e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.19322686e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16768344e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.02870773e-13 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.50752038e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.23248519e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 25)\n",
      "[[3.01013698e-08 7.83554243e-08 5.85419376e-06 ... 4.19255145e-05\n",
      "  1.19641271e-06 6.11060359e-07]\n",
      " [1.19322686e-05 9.76257286e-01 5.37027124e-08 ... 6.83088506e-08\n",
      "  1.89186532e-06 1.79793167e-08]\n",
      " [2.16768344e-03 1.52823159e-05 3.88797655e-10 ... 2.81827303e-10\n",
      "  1.26363368e-08 5.15481018e-10]\n",
      " ...\n",
      " [4.02870773e-13 2.95707915e-13 8.66395582e-06 ... 4.56254205e-11\n",
      "  2.48071866e-11 4.54563124e-06]\n",
      " [9.50752038e-07 1.39826340e-04 1.03861160e-06 ... 8.57528173e-07\n",
      "  9.92674365e-06 1.13676762e-07]\n",
      " [9.23248519e-08 2.14971483e-06 2.17091326e-07 ... 7.00252621e-08\n",
      "  9.98145732e-01 3.28000729e-08]]\n",
      "FCM training RMSE: 726.6791683308069\n",
      "(2031, 150)\n",
      "[[7.98182631e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.40143799e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.85153749e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.48419394e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.02906180e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.12050323e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2031, 25)\n",
      "[[7.98182631e-07 3.78367500e-05 2.17139950e-04 ... 5.19717970e-08\n",
      "  2.43334881e-06 3.70615121e-08]\n",
      " [1.40143799e-07 1.00657534e-07 1.21766543e-05 ... 1.57141691e-06\n",
      "  2.81054047e-07 1.23939729e-03]\n",
      " [5.85153749e-11 1.36995869e-11 5.13076709e-10 ... 4.23090596e-09\n",
      "  3.34495024e-11 9.99924106e-01]\n",
      " ...\n",
      " [5.48419394e-09 8.57594435e-07 9.82823261e-10 ... 3.42985122e-10\n",
      "  1.19414163e-09 7.10059270e-11]\n",
      " [1.02906180e-05 1.93299920e-05 4.39491127e-05 ... 1.34271218e-06\n",
      "  3.50426810e-06 1.31748947e-06]\n",
      " [3.12050323e-09 2.98298530e-04 5.08382088e-08 ... 1.01734402e-10\n",
      "  2.68382623e-08 4.17352740e-11]]\n",
      "FCM training RMSE: 730.4546874872827\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use validation to get the optimal number of rules\n",
    "tsc_cv_train_accuracy = []\n",
    "tsc_cv_val_accuracy = []\n",
    "\n",
    "kf = KFold(n_splits=number_of_folds)\n",
    "\n",
    "for number_of_rules in number_of_rules_array:\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
    "        ts_model = TsModel_constant.TsModel_constant(number_of_rules, fuzzification_coefficient=1.2)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        ts_model.fit(x_train[train_index], y_train[train_index])\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        tsc_train_pred = ts_relu_wrapper(ts_model.predict(x_train[train_index]))\n",
    "        tsc_val_pred = ts_relu_wrapper(ts_model.predict(x_train[test_index]))\n",
    "\n",
    "        train_rmse = root_mean_squared_error(y_train[train_index], tsc_train_pred)\n",
    "        val_rmse = root_mean_squared_error(y_train[test_index], tsc_val_pred)\n",
    "\n",
    "        tsc_cv_train_accuracy.append(train_rmse)\n",
    "        tsc_cv_val_accuracy.append(val_rmse)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "number_of_rules_array_strings = [str(number) for number in number_of_rules_array]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsc_cv_train_accuracy).reshape(-1, 10), axis=1), '-.v', label='Train')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsc_cv_val_accuracy).reshape(-1, 10), axis=1), '-.v', label='Validation')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25ddc376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 687.243612872598\n",
      "FCM training RMSE: 684.7121466218159\n",
      "FCM training RMSE: 684.7121330985409\n",
      "FCM training RMSE: 686.4958598808166\n",
      "FCM training RMSE: 686.4405535673844\n",
      "FCM training RMSE: 684.7121318886847\n",
      "FCM training RMSE: 684.712132114227\n",
      "FCM training RMSE: 684.7121481300491\n",
      "FCM training RMSE: 684.7121470957844\n",
      "FCM training RMSE: 684.7121467915708\n",
      "TS Linear Train RMSE: 685.235 ± 0.963\n",
      "TS Linear Test RMSE: 778.874 ± 3.517\n",
      "TS Linear R2: 0.776 ± 0.002\n",
      "TS Linear Time: 0.142 ± 0.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TS with linear conclusion\n",
    "tsl_opt_train_accuracy = []\n",
    "tsl_opt_test_accuracy = []\n",
    "tsl_r2s = []\n",
    "tsl_time = []\n",
    "tsl_model = None\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    ts_model = TsModel.TsModel(number_of_rules=10, fuzzification_coefficient=1.2)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ts_model.fit(x_train, y_train)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    tsl_train_pred = ts_relu_wrapper(ts_model.predict(x_train))\n",
    "    tsl_test_pred = ts_relu_wrapper(ts_model.predict(x_test))\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, tsl_train_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, tsl_test_pred)\n",
    "\n",
    "    tsl_opt_train_accuracy.append(train_rmse)\n",
    "    tsl_opt_test_accuracy.append(test_rmse)\n",
    "    tsl_r2 = r2_score(y_test, tsl_test_pred)\n",
    "    tsl_r2s.append(tsl_r2)\n",
    "    tsl_time.append(time_used)\n",
    "    tsl_model = ts_model\n",
    "\n",
    "tsl_train_accuracy_mean = np.round(np.mean(tsl_opt_train_accuracy), 3)\n",
    "tsl_train_accuracy_std = np.round(np.std(tsl_opt_train_accuracy), 3)\n",
    "tsl_test_accuracy_mean = np.round(np.mean(tsl_opt_test_accuracy), 3)\n",
    "tsl_test_accuracy_std = np.round(np.std(tsl_opt_test_accuracy),3)\n",
    "tsl_r2_mean = np.round(np.mean(tsl_r2s),3)\n",
    "tsl_r2_std = np.round(np.std(tsl_r2s),3)\n",
    "tsl_time_mean = np.round(np.mean(tsl_time),3)\n",
    "tsl_time_std = np.round(np.std(tsl_time),3)\n",
    "\n",
    "print(f\"TS Linear Train RMSE: {tsl_train_accuracy_mean} ± {tsl_train_accuracy_std}\")\n",
    "print(f\"TS Linear Test RMSE: {tsl_test_accuracy_mean} ± {tsl_test_accuracy_std}\")\n",
    "print(f\"TS Linear R2: {tsl_r2_mean} ± {tsl_r2_std}\")\n",
    "print(f\"TS Linear Time: {tsl_time_mean} ± {tsl_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc36dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[7.37409589e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99954509e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.34855173e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.85224079e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.22409342e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.68079878e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[7.37409589e-05 2.13554902e-03 1.46219718e-03 ... 1.01517393e-02\n",
      "  9.35758800e-01 3.14405112e-04]\n",
      " [9.99954509e-01 4.22385232e-06 9.83802860e-08 ... 7.15277982e-08\n",
      "  3.28327633e-06 2.80562084e-08]\n",
      " [1.34855173e-03 7.19550680e-07 2.12108222e-08 ... 1.23010041e-08\n",
      "  7.68040912e-06 2.71728858e-08]\n",
      " ...\n",
      " [6.85224079e-09 6.10281197e-07 4.96436189e-04 ... 3.81704602e-07\n",
      "  1.62866878e-06 9.99495494e-01]\n",
      " [9.22409342e-01 4.70336162e-02 1.31686420e-03 ... 4.98637272e-04\n",
      "  2.54729128e-02 1.23926243e-04]\n",
      " [1.68079878e-04 9.99605716e-01 3.61284048e-05 ... 2.38828581e-06\n",
      "  1.89051827e-05 2.70315574e-06]]\n",
      "FCM training RMSE: 844.017507121709\n",
      "(2256, 60)\n",
      "[[9.99205467e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.02655382e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00893816e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.32432812e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.87289107e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.10422326e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[9.99205467e-01 1.99501469e-05 1.83028609e-05 ... 4.10210082e-06\n",
      "  2.83487696e-07 2.10615695e-04]\n",
      " [4.02655382e-05 8.99071255e-08 5.12603391e-07 ... 1.38178022e-07\n",
      "  1.70842179e-04 2.56630504e-07]\n",
      " [1.00893816e-06 2.04820008e-08 2.38130482e-08 ... 3.02859671e-08\n",
      "  9.98545112e-01 1.39964593e-08]\n",
      " ...\n",
      " [3.32432812e-06 4.96012746e-06 7.41076303e-04 ... 9.99242388e-01\n",
      "  2.02671337e-08 1.74767116e-06]\n",
      " [8.87289107e-03 3.51372091e-07 9.84140021e-06 ... 8.63158167e-07\n",
      "  1.50183574e-05 2.23293121e-06]\n",
      " [5.10422326e-02 9.08015797e-05 1.20168081e-02 ... 6.78381209e-04\n",
      "  1.76729305e-03 4.02054496e-04]]\n",
      "FCM training RMSE: 774.4482483414674\n",
      "(2256, 60)\n",
      "[[3.31155730e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.86383107e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.90054097e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.93750074e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.72439759e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.24421177e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[3.31155730e-04 7.96117608e-06 4.83588645e-06 ... 3.64026907e-05\n",
      "  1.42426097e-04 6.47919105e-05]\n",
      " [2.86383107e-08 9.99868461e-01 5.67629170e-05 ... 3.43713111e-07\n",
      "  3.28489060e-06 4.12383703e-08]\n",
      " [1.90054097e-08 1.67636616e-03 9.98313683e-01 ... 5.98711046e-07\n",
      "  4.52754396e-07 2.54013625e-08]\n",
      " ...\n",
      " [1.93750074e-06 4.68077717e-09 8.00045723e-09 ... 1.61119482e-06\n",
      "  4.72021635e-07 9.99522400e-01]\n",
      " [2.72439759e-06 1.48134527e-02 1.21210017e-04 ... 2.16584536e-05\n",
      "  7.06984682e-04 6.35625838e-06]\n",
      " [1.24421177e-07 4.08839531e-05 2.47999464e-06 ... 4.89539245e-05\n",
      "  9.99832579e-01 8.15028164e-07]]\n",
      "FCM training RMSE: 809.0425392336756\n",
      "(2256, 60)\n",
      "[[3.39048390e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99954259e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.41342017e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.58602781e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.10619459e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.26011252e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[3.39048390e-05 1.15273483e-05 9.33517831e-05 ... 8.33888119e-04\n",
      "  1.53756323e-04 9.83480282e-01]\n",
      " [9.99954259e-01 3.73174737e-05 2.42204614e-07 ... 3.76193740e-06\n",
      "  2.82369488e-08 4.16425360e-06]\n",
      " [1.41342017e-03 9.98576952e-01 7.03710611e-07 ... 6.84864504e-07\n",
      "  2.81984831e-08 8.13486512e-06]\n",
      " ...\n",
      " [6.58602781e-09 8.52662517e-09 1.78047335e-06 ... 5.85509922e-07\n",
      "  9.99501817e-01 1.55279832e-06]\n",
      " [9.10619459e-01 2.54209424e-03 4.80834444e-04 ... 4.05885485e-02\n",
      "  1.35318272e-04 4.34002997e-02]\n",
      " [1.26011252e-04 6.17002666e-06 1.13964151e-04 ... 9.99704083e-01\n",
      "  2.04282228e-06 1.75476263e-05]]\n",
      "FCM training RMSE: 838.1855896841585\n",
      "(2256, 60)\n",
      "[[1.42425230e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.28489410e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.52758841e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.72012044e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.06987340e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99832583e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[1.42425230e-04 7.96115541e-06 9.51346223e-03 ... 3.64027657e-05\n",
      "  2.98186812e-04 9.85539800e-01]\n",
      " [3.28489410e-06 9.99868462e-01 1.79390121e-06 ... 3.43710120e-07\n",
      "  1.43894674e-07 6.90531060e-05]\n",
      " [4.52758841e-07 1.67637591e-03 5.48118042e-06 ... 5.98709352e-07\n",
      "  1.98331894e-08 3.34001622e-06]\n",
      " ...\n",
      " [4.72012044e-07 4.68071294e-09 1.54460374e-06 ... 1.61119348e-06\n",
      "  4.70921136e-04 3.80467966e-07]\n",
      " [7.06987340e-04 1.48134690e-02 2.29899089e-04 ... 2.16584532e-05\n",
      "  6.68215439e-05 9.84012280e-01]\n",
      " [9.99832583e-01 4.08830208e-05 2.37236032e-06 ... 4.89526559e-05\n",
      "  1.08011716e-05 6.04088506e-05]]\n",
      "FCM training RMSE: 809.0425593810478\n",
      "(2256, 60)\n",
      "[[7.96115714e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99868462e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.67637514e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.68071788e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.48134676e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.08830979e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[7.96115714e-06 3.31155107e-04 2.98186846e-04 ... 4.06098006e-03\n",
      "  9.51346414e-03 9.85539797e-01]\n",
      " [9.99868462e-01 2.86381954e-08 1.43894717e-07 ... 8.59618165e-08\n",
      "  1.79390181e-06 6.90531382e-05]\n",
      " [1.67637514e-03 1.90054782e-08 1.98331822e-08 ... 1.36306678e-08\n",
      "  5.48117854e-06 3.34001552e-06]\n",
      " ...\n",
      " [4.68071788e-09 1.93747727e-06 4.70921706e-04 ... 7.13204537e-07\n",
      "  1.54460537e-06 3.80468325e-07]\n",
      " [1.48134676e-02 2.72440128e-06 6.68215299e-05 ... 1.85935229e-05\n",
      "  2.29899057e-04 9.84012282e-01]\n",
      " [4.08830979e-05 1.24418854e-07 1.08011878e-05 ... 5.79530440e-07\n",
      "  2.37236432e-06 6.04089520e-05]]\n",
      "FCM training RMSE: 809.0425574153606\n",
      "(2256, 60)\n",
      "[[3.31159144e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.86389422e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.90050433e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.93762625e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.72437739e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.24433870e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[3.31159144e-04 2.98189266e-04 4.83593057e-06 ... 1.42430442e-04\n",
      "  3.64023273e-05 9.51360068e-03]\n",
      " [2.86389422e-08 1.43897732e-07 5.67643429e-05 ... 3.28487318e-06\n",
      "  3.43728011e-07 1.79394497e-06]\n",
      " [1.90050433e-08 1.98326412e-08 9.98313732e-01 ... 4.52732269e-07\n",
      "  5.98719430e-07 5.48103468e-06]\n",
      " ...\n",
      " [1.93762625e-06 4.70964913e-04 8.00095911e-09 ... 4.72069235e-07\n",
      "  1.61120135e-06 1.54473015e-06]\n",
      " [2.72437739e-06 6.68205269e-05 1.21209163e-04 ... 7.06971338e-04\n",
      "  2.16584531e-05 2.29896769e-04]\n",
      " [1.24433870e-07 1.08023492e-05 2.48023799e-06 ... 9.99832560e-01\n",
      "  4.89602642e-05 2.37265132e-06]]\n",
      "FCM training RMSE: 809.0424344941447\n",
      "(2256, 60)\n",
      "[[2.41462067e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.42995333e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.34876915e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.23581318e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.54663552e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.95141900e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[2.41462067e-03 1.70511757e-02 9.78084608e-01 ... 2.24415832e-04\n",
      "  8.58969787e-04 5.03870119e-05]\n",
      " [2.42995333e-06 6.40888481e-08 3.55592139e-06 ... 1.11645378e-07\n",
      "  8.66339700e-08 9.99943939e-01]\n",
      " [6.34876915e-08 2.56591824e-09 1.22056275e-06 ... 3.33375741e-08\n",
      "  3.13807555e-09 1.96840210e-04]\n",
      " ...\n",
      " [3.23581318e-07 2.05570950e-07 4.18888118e-07 ... 5.44682202e-06\n",
      "  1.76016663e-04 1.80194745e-09]\n",
      " [3.54663552e-02 3.93597014e-04 2.89017399e-02 ... 2.93785270e-04\n",
      "  1.05703194e-03 9.30112793e-01]\n",
      " [9.95141900e-01 1.25255854e-05 1.20736450e-04 ... 3.20432429e-04\n",
      "  1.65561901e-04 1.04947096e-03]]\n",
      "FCM training RMSE: 815.0614207941817\n",
      "(2256, 60)\n",
      "[[5.83533250e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.47512923e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.37235485e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.28463620e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.55132505e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.57924904e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[5.83533250e-04 1.21644135e-04 1.02371799e-04 ... 1.48204242e-04\n",
      "  2.43847443e-03 1.38218503e-02]\n",
      " [2.47512923e-07 6.45810881e-08 1.45557361e-06 ... 2.79715474e-08\n",
      "  6.13835773e-08 2.67593699e-06]\n",
      " [2.37235485e-08 2.95866766e-08 8.75272419e-07 ... 1.74815566e-08\n",
      "  2.08726232e-08 6.22901695e-06]\n",
      " ...\n",
      " [8.28463620e-04 9.99150105e-01 2.25373818e-06 ... 3.90361603e-06\n",
      "  7.13940960e-06 4.65409686e-06]\n",
      " [7.55132505e-05 6.25614720e-06 7.20868263e-05 ... 1.33843984e-06\n",
      "  4.82416897e-06 2.12552825e-04]\n",
      " [9.57924904e-03 5.24378331e-04 8.99279770e-01 ... 4.02570040e-05\n",
      "  1.15235070e-04 1.40322680e-03]]\n",
      "FCM training RMSE: 782.0119515415192\n",
      "(2256, 60)\n",
      "[[1.28518282e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.43965843e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.80612685e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.22688989e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.01761857e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.92587962e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[1.28518282e-04 7.36621190e-04 9.57510033e-01 ... 1.90015205e-05\n",
      "  1.85263877e-02 1.06813403e-05]\n",
      " [1.43965843e-06 2.47857772e-07 1.11534027e-04 ... 9.99803549e-01\n",
      "  2.52456858e-06 8.03574489e-05]\n",
      " [8.80612685e-07 2.39908354e-08 3.68551297e-06 ... 1.38308353e-03\n",
      "  5.72050230e-06 9.98606527e-01]\n",
      " ...\n",
      " [2.22688989e-06 8.09051129e-04 1.19642809e-06 ... 1.50107556e-08\n",
      "  4.86040679e-06 2.40143856e-08]\n",
      " [6.01761857e-05 6.39902474e-05 9.86874578e-01 ... 1.27012157e-02\n",
      "  1.72051552e-04 9.32728969e-05]\n",
      " [8.92587962e-01 9.88499685e-03 6.41148553e-02 ... 2.94114283e-02\n",
      "  1.40510531e-03 1.37052260e-03]]\n",
      "FCM training RMSE: 782.1626702066663\n",
      "TS Constant Train RMSE: 807.206 ± 21.737\n",
      "TS Constant Test RMSE: 840.332 ± 16.199\n",
      "TS Constant R2: 0.74 ± 0.01\n",
      "TS Constant Time: 0.198 ± 0.104\n"
     ]
    }
   ],
   "source": [
    "# TS model\n",
    "# Constant conclusion\n",
    "tsc_opt_train_accuracy = []\n",
    "tsc_opt_test_accuracy = []\n",
    "tsc_r2s = []\n",
    "tsc_time = []\n",
    "tsc_model = None\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    ts_model = TsModel_constant.TsModel_constant(number_of_rules=10, fuzzification_coefficient=1.2)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ts_model.fit(x_train, y_train)\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    tsc_train_pred = ts_relu_wrapper(ts_model.predict(x_train))\n",
    "    tsc_test_pred = ts_relu_wrapper(ts_model.predict(x_test))\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, tsc_train_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, tsc_test_pred)\n",
    "\n",
    "    tsc_opt_train_accuracy.append(train_rmse)\n",
    "    tsc_opt_test_accuracy.append(test_rmse)\n",
    "    tsc_r2 = r2_score(y_test, tsc_test_pred)\n",
    "    tsc_r2s.append(tsc_r2)\n",
    "    tsc_time.append(time_used)\n",
    "    tsc_model = ts_model\n",
    "\n",
    "tsc_train_accuracy_mean = np.round(np.mean(tsc_opt_train_accuracy), 3)\n",
    "tsc_train_accuracy_std = np.round(np.std(tsc_opt_train_accuracy), 3)\n",
    "tsc_test_accuracy_mean = np.round(np.mean(tsc_opt_test_accuracy), 3)\n",
    "tsc_test_accuracy_std = np.round(np.std(tsc_opt_test_accuracy),3)\n",
    "tsc_r2_mean = np.round(np.mean(tsc_r2s),3)\n",
    "tsc_r2_std = np.round(np.std(tsc_r2s),3)\n",
    "tsc_time_mean = np.round(np.mean(tsc_time),3)\n",
    "tsc_time_std = np.round(np.std(tsc_time),3)\n",
    "\n",
    "print(f\"TS Constant Train RMSE: {tsc_train_accuracy_mean} ± {tsc_train_accuracy_std}\")\n",
    "print(f\"TS Constant Test RMSE: {tsc_test_accuracy_mean} ± {tsc_test_accuracy_std}\")\n",
    "print(f\"TS Constant R2: {tsc_r2_mean} ± {tsc_r2_std}\")\n",
    "print(f\"TS Constant Time: {tsc_time_mean} ± {tsc_time_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d62793fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP Train RMSE: 609.583 ± 143.467\n",
      "GP Test RMSE: 1769.605 ± 446.094\n",
      "GP R2: -0.228 ± 0.518\n",
      "GP Time: 16.736 ± 8.892\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_train_accuracy = []\n",
    "gp_test_accuracy = []\n",
    "gp_r2s = []\n",
    "gp_time = []\n",
    "gpr_model = None\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    \n",
    "    kernel = 1.0 * Matern(length_scale=1e-1, nu=1.5)\n",
    "    gpr_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "    indices = np.random.choice(x_train.shape[0], 2000, replace=False)      \n",
    "\n",
    "    start_time = time.time()\n",
    "    gpr_model.fit(x_train[indices,:], y_train[indices,:])\n",
    "    time_used = time.time() - start_time\n",
    "\n",
    "    train_means = gpr_model.predict(x_train)\n",
    "    test_means = gpr_model.predict(x_test)\n",
    "\n",
    "    train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "    gp_train_accuracy.append(train_rmse)\n",
    "    gp_test_accuracy.append(test_rmse)\n",
    "    gp_r2 = r2_score(y_test, test_means)\n",
    "    gp_r2s.append(gp_r2)\n",
    "    gp_time.append(time_used)\n",
    "\n",
    "gp_train_accuracy_mean = np.round(np.mean(gp_train_accuracy), 3)\n",
    "gp_train_accuracy_std = np.round(np.std(gp_train_accuracy), 3)\n",
    "gp_test_accuracy_mean = np.round(np.mean(gp_test_accuracy), 3)\n",
    "gp_test_accuracy_std = np.round(np.std(gp_test_accuracy),3)\n",
    "gp_r2_mean = np.round(np.mean(gp_r2s),3)\n",
    "gp_r2_std = np.round(np.std(gp_r2s),3)\n",
    "gp_time_mean = np.round(np.mean(gp_time),3)\n",
    "gp_time_std = np.round(np.std(gp_time),3)\n",
    "\n",
    "print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3646ec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 727.2435294896957\n",
      "FCM training RMSE: 727.2435244993485\n",
      "FCM training RMSE: 727.2435249465886\n",
      "FCM training RMSE: 727.2435259728553\n",
      "FCM training RMSE: 727.2435264769277\n",
      "FCM training RMSE: 727.2435222819125\n",
      "FCM training RMSE: 727.2435233181968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 727.243524311869\n",
      "FCM training RMSE: 727.2435256950264\n",
      "FCM training RMSE: 727.2435267197294\n",
      "FCM training RMSE: 710.5560671737016\n",
      "FCM training RMSE: 710.5560780098002\n",
      "FCM training RMSE: 710.556077909126\n",
      "FCM training RMSE: 710.5560678088067\n",
      "FCM training RMSE: 710.5560681454591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 710.5560651227042\n",
      "FCM training RMSE: 710.5560662258782\n",
      "FCM training RMSE: 710.5560765730917\n",
      "FCM training RMSE: 710.5560680169166\n",
      "FCM training RMSE: 710.5560653864\n",
      "FCM training RMSE: 715.9270118079288\n",
      "FCM training RMSE: 696.0571307145816\n",
      "FCM training RMSE: 715.9270136553213\n",
      "FCM training RMSE: 696.0571289565803\n",
      "FCM training RMSE: 696.0571412841683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 715.9270110168889\n",
      "FCM training RMSE: 709.9474620380803\n",
      "FCM training RMSE: 715.9270272580749\n",
      "FCM training RMSE: 696.0571255304413\n",
      "FCM training RMSE: 696.0571369358273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.362858250467\n",
      "FCM training RMSE: 710.4612981595686\n",
      "FCM training RMSE: 696.5534227763757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.5534210924856\n",
      "FCM training RMSE: 696.3628382513278\n",
      "FCM training RMSE: 696.3628580880463\n",
      "FCM training RMSE: 696.5534173419297\n",
      "FCM training RMSE: 706.1190900632381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.553422218637\n",
      "FCM training RMSE: 710.4612978344928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800560910633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800565971315\n",
      "FCM training RMSE: 690.0800563381757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.5048898974817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800563243928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 694.3942288466965\n",
      "FCM training RMSE: 690.080056687517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800561738731\n",
      "FCM training RMSE: 687.0728294317946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800443257333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.7121330335941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.7378213816986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 689.3332133094535\n",
      "FCM training RMSE: 686.4778986928948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.712146749228\n",
      "FCM training RMSE: 684.7121321546616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 687.2448777468213\n",
      "FCM training RMSE: 684.7121475789221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.7121320955135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 686.7728835573203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 676.4306487589342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 676.4306647095614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 676.6199621764509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 678.7214493367045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 677.717016134712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 675.8660489198005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 679.5321348494335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 678.1052723119521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.177604146678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 679.9141803772673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.2919484944931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 674.0211511113076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 664.6789635764105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 674.0655143650692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.9750328247105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.532297027113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.7443461384107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 674.5131995308291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 672.8626336285787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 671.724065810002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 664.5983710217575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.2297251114072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 667.0773260760338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 669.45458540131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 670.1954515864365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 669.7256817910998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 669.6050682282201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 659.4814939441958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 667.7692095207747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 670.9787588188236\n",
      "Number of rules: 2\n",
      "GP Train RMSE: 1607.976 ± 361.538\n",
      "GP Test RMSE: 1629.25 ± 351.911\n",
      "GP R2: -0.024 ± 0.441\n",
      "GP Time: 0.019 ± 0.005\n",
      "Number of rules: 3\n",
      "GP Train RMSE: 1393.446 ± 329.31\n",
      "GP Test RMSE: 1420.609 ± 320.462\n",
      "GP R2: 0.218 ± 0.393\n",
      "GP Time: 0.018 ± 0.007\n",
      "Number of rules: 4\n",
      "GP Train RMSE: 1614.271 ± 536.376\n",
      "GP Test RMSE: 1631.435 ± 526.91\n",
      "GP R2: -0.084 ± 0.592\n",
      "GP Time: 0.017 ± 0.007\n",
      "Number of rules: 5\n",
      "GP Train RMSE: 1750.951 ± 460.428\n",
      "GP Test RMSE: 1765.931 ± 452.226\n",
      "GP R2: -0.225 ± 0.522\n",
      "GP Time: 0.017 ± 0.007\n",
      "Number of rules: 8\n",
      "GP Train RMSE: 1057.569 ± 497.305\n",
      "GP Test RMSE: 1104.032 ± 478.803\n",
      "GP R2: 0.466 ± 0.517\n",
      "GP Time: 0.019 ± 0.011\n",
      "Number of rules: 10\n",
      "GP Train RMSE: 1168.041 ± 578.769\n",
      "GP Test RMSE: 1211.118 ± 556.707\n",
      "GP R2: 0.345 ± 0.597\n",
      "GP Time: 0.019 ± 0.005\n",
      "Number of rules: 15\n",
      "GP Train RMSE: 746.987 ± 3.92\n",
      "GP Test RMSE: 804.278 ± 4.023\n",
      "GP R2: 0.761 ± 0.002\n",
      "GP Time: 0.024 ± 0.007\n",
      "Number of rules: 20\n",
      "GP Train RMSE: 734.02 ± 4.31\n",
      "GP Test RMSE: 792.583 ± 4.231\n",
      "GP R2: 0.768 ± 0.002\n",
      "GP Time: 0.024 ± 0.007\n",
      "Number of rules: 25\n",
      "GP Train RMSE: 725.617 ± 3.085\n",
      "GP Test RMSE: 784.551 ± 2.634\n",
      "GP R2: 0.773 ± 0.002\n",
      "GP Time: 0.026 ± 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR from TS linear\n",
    "gp_tsl_train_accuracy = []\n",
    "gp_tsl_test_accuracy = []\n",
    "tsl_train_accuracy = []\n",
    "tsl_test_accuracy = []\n",
    "gp_tsl_r2s = []\n",
    "gp_tsl_time = []\n",
    "gpr_tsl_model = None\n",
    "\n",
    "# From ts linear\n",
    "for number_of_rules in number_of_rules_array:\n",
    "    for fold in range(number_of_folds):\n",
    "        \n",
    "        kernel = 1.0 * Matern(length_scale=1e-1, nu=1.5)\n",
    "        gpr_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "        tsl_model = get_tsl_model(x_train, y_train, number_of_rules)\n",
    "\n",
    "        start_time = time.time()\n",
    "        gpr_tsl_model.fit(tsl_model.cen, tsl_model.predict(tsl_model.cen + 1e-8))\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        gp_train_means = gpr_tsl_model.predict(x_train)\n",
    "        gp_test_means = gpr_tsl_model.predict(x_test)\n",
    "\n",
    "        tsl_train_means = tsl_model.predict(x_train)\n",
    "        tsl_test_means = tsl_model.predict(x_test)\n",
    "\n",
    "        gp_train_rmse = root_mean_squared_error(y_train, gp_train_means)\n",
    "        gp_test_rmse = root_mean_squared_error(y_test, gp_test_means)\n",
    "\n",
    "        gp_tsl_train_accuracy.append(gp_train_rmse)\n",
    "        gp_tsl_test_accuracy.append(gp_test_rmse)\n",
    "        tsl_train_accuracy.append(root_mean_squared_error(y_train, tsl_train_means))\n",
    "        tsl_test_accuracy.append(root_mean_squared_error(y_test, tsl_test_means))\n",
    "        gp_r2 = r2_score(y_test, gp_test_means)\n",
    "        gp_tsl_r2s.append(gp_r2)\n",
    "        gp_tsl_time.append(time_used)\n",
    "\n",
    "for idx, number_of_rules in enumerate(number_of_rules_array):\n",
    "    gp_train_accuracy_mean = np.round(np.mean(gp_tsl_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_train_accuracy_std = np.round(np.std(gp_tsl_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_mean = np.round(np.mean(gp_tsl_test_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_std = np.round(np.std(gp_tsl_test_accuracy[idx*10:idx*10+10]),3)\n",
    "    gp_r2_mean = np.round(np.mean(gp_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_r2_std = np.round(np.std(gp_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_time_mean = np.round(np.mean(gp_tsl_time[idx*10:idx*10+10]),3)\n",
    "    gp_time_std = np.round(np.std(gp_tsl_time[idx*10:idx*10+10]),3)\n",
    "\n",
    "    print(f\"Number of rules: {number_of_rules}\")\n",
    "    print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "    print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "    print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "    print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "960ae86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 12)\n",
      "[[9.98611235e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.93615959e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.75717126e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99836783e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.74791984e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.85636265e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[9.98611235e-01 1.38876532e-03]\n",
      " [1.93615959e-04 9.99806384e-01]\n",
      " [8.75717126e-06 9.99991243e-01]\n",
      " ...\n",
      " [9.99836783e-01 1.63217260e-04]\n",
      " [5.74791984e-03 9.94252080e-01]\n",
      " [2.85636265e-02 9.71436374e-01]]\n",
      "FCM training RMSE: 947.0528804622251\n",
      "(2256, 12)\n",
      "[[1.38876489e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217237e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252079e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436367e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876489e-03 9.98611235e-01]\n",
      " [9.99806384e-01 1.93615933e-04]\n",
      " [9.99991243e-01 8.75716826e-06]\n",
      " ...\n",
      " [1.63217237e-04 9.99836783e-01]\n",
      " [9.94252079e-01 5.74792070e-03]\n",
      " [9.71436367e-01 2.85636327e-02]]\n",
      "FCM training RMSE: 947.0528824502687\n",
      "(2256, 12)\n",
      "[[1.38876526e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217258e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252080e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436373e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876526e-03 9.98611235e-01]\n",
      " [9.99806384e-01 1.93615955e-04]\n",
      " [9.99991243e-01 8.75717089e-06]\n",
      " ...\n",
      " [1.63217258e-04 9.99836783e-01]\n",
      " [9.94252080e-01 5.74791995e-03]\n",
      " [9.71436373e-01 2.85636273e-02]]\n",
      "FCM training RMSE: 947.0528807102144\n",
      "(2256, 12)\n",
      "[[1.38876405e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217191e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252078e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436355e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876405e-03 9.98611236e-01]\n",
      " [9.99806384e-01 1.93615880e-04]\n",
      " [9.99991243e-01 8.75716225e-06]\n",
      " ...\n",
      " [1.63217191e-04 9.99836783e-01]\n",
      " [9.94252078e-01 5.74792242e-03]\n",
      " [9.71436355e-01 2.85636451e-02]]\n",
      "FCM training RMSE: 947.0528864240435\n",
      "(2256, 12)\n",
      "[[9.98611236e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.93615870e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.75716103e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99836783e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.74792276e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.85636477e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[9.98611236e-01 1.38876387e-03]\n",
      " [1.93615870e-04 9.99806384e-01]\n",
      " [8.75716103e-06 9.99991243e-01]\n",
      " ...\n",
      " [9.99836783e-01 1.63217182e-04]\n",
      " [5.74792276e-03 9.94252077e-01]\n",
      " [2.85636477e-02 9.71436352e-01]]\n",
      "FCM training RMSE: 947.0528872316146\n",
      "(2256, 12)\n",
      "[[1.38876508e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217248e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252080e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436370e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876508e-03 9.98611235e-01]\n",
      " [9.99806384e-01 1.93615944e-04]\n",
      " [9.99991243e-01 8.75716957e-06]\n",
      " ...\n",
      " [1.63217248e-04 9.99836783e-01]\n",
      " [9.94252080e-01 5.74792033e-03]\n",
      " [9.71436370e-01 2.85636300e-02]]\n",
      "FCM training RMSE: 947.0528815824546\n",
      "(2256, 12)\n",
      "[[1.38876373e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217174e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252077e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436350e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876373e-03 9.98611236e-01]\n",
      " [9.99806384e-01 1.93615861e-04]\n",
      " [9.99991243e-01 8.75716003e-06]\n",
      " ...\n",
      " [1.63217174e-04 9.99836783e-01]\n",
      " [9.94252077e-01 5.74792305e-03]\n",
      " [9.71436350e-01 2.85636497e-02]]\n",
      "FCM training RMSE: 947.05288789366\n",
      "(2256, 12)\n",
      "[[9.98611235e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.93615958e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.75717119e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99836783e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.74791987e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.85636266e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[9.98611235e-01 1.38876531e-03]\n",
      " [1.93615958e-04 9.99806384e-01]\n",
      " [8.75717119e-06 9.99991243e-01]\n",
      " ...\n",
      " [9.99836783e-01 1.63217260e-04]\n",
      " [5.74791987e-03 9.94252080e-01]\n",
      " [2.85636266e-02 9.71436373e-01]]\n",
      "FCM training RMSE: 947.052880512155\n",
      "(2256, 12)\n",
      "[[9.98611235e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.93615960e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.75717145e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99836783e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.74791979e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.85636261e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[9.98611235e-01 1.38876534e-03]\n",
      " [1.93615960e-04 9.99806384e-01]\n",
      " [8.75717145e-06 9.99991243e-01]\n",
      " ...\n",
      " [9.99836783e-01 1.63217262e-04]\n",
      " [5.74791979e-03 9.94252080e-01]\n",
      " [2.85636261e-02 9.71436374e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 947.0528803392347\n",
      "(2256, 12)\n",
      "[[1.38876377e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99806384e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99991243e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.63217176e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94252077e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.71436351e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 2)\n",
      "[[1.38876377e-03 9.98611236e-01]\n",
      " [9.99806384e-01 1.93615863e-04]\n",
      " [9.99991243e-01 8.75716030e-06]\n",
      " ...\n",
      " [1.63217176e-04 9.99836783e-01]\n",
      " [9.94252077e-01 5.74792297e-03]\n",
      " [9.71436351e-01 2.85636492e-02]]\n",
      "FCM training RMSE: 947.0528877183035\n",
      "(2256, 18)\n",
      "[[6.21566407e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.35435704e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.56134767e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99582971e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.11763599e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.11624560e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[6.21566407e-02 5.73380085e-03 9.32109558e-01]\n",
      " [1.35435704e-04 9.99804502e-01 6.00619848e-05]\n",
      " [3.56134767e-06 9.99994853e-01 1.58523917e-06]\n",
      " ...\n",
      " [9.99582971e-01 3.86364540e-06 4.13165514e-04]\n",
      " [7.11763599e-03 9.91148150e-01 1.73421432e-03]\n",
      " [2.11624560e-01 7.81848339e-01 6.52710117e-03]]\n",
      "FCM training RMSE: 915.8796698856839\n",
      "(2256, 18)\n",
      "[[5.73379906e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804502e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994853e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.86364637e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91148147e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81848281e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[5.73379906e-03 9.32109549e-01 6.21566516e-02]\n",
      " [9.99804502e-01 6.00619707e-05 1.35435689e-04]\n",
      " [9.99994853e-01 1.58523834e-06 3.56134630e-06]\n",
      " ...\n",
      " [3.86364637e-06 4.13165694e-04 9.99582971e-01]\n",
      " [9.91148147e-01 1.73421456e-03 7.11763808e-03]\n",
      " [7.81848281e-01 6.52710187e-03 2.11624617e-01]]\n",
      "FCM training RMSE: 915.8796805974599\n",
      "(2256, 18)\n",
      "[[9.32109619e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.00620795e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.58524477e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.13164304e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.73421263e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.52709641e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[9.32109619e-01 6.21565678e-02 5.73381299e-03]\n",
      " [6.00620795e-05 1.35435805e-04 9.99804502e-01]\n",
      " [1.58524477e-06 3.56135690e-06 9.99994853e-01]\n",
      " ...\n",
      " [4.13164304e-04 9.99582972e-01 3.86363891e-06]\n",
      " [1.73421263e-03 7.11762183e-03 9.91148166e-01]\n",
      " [6.52709641e-03 2.11624173e-01 7.81848731e-01]]\n",
      "FCM training RMSE: 915.8795974116125\n",
      "(2256, 18)\n",
      "[[9.32109540e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.00619565e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.58523750e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.13165874e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.73421481e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.52710257e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[9.32109540e-01 6.21566631e-02 5.73379731e-03]\n",
      " [6.00619565e-05 1.35435674e-04 9.99804502e-01]\n",
      " [1.58523750e-06 3.56134494e-06 9.99994853e-01]\n",
      " ...\n",
      " [4.13165874e-04 9.99582970e-01 3.86364734e-06]\n",
      " [1.73421481e-03 7.11764018e-03 9.91148145e-01]\n",
      " [6.52710257e-03 2.11624675e-01 7.81848223e-01]]\n",
      "FCM training RMSE: 915.8796912693105\n",
      "(2256, 18)\n",
      "[[5.73380104e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804502e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994853e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.86364549e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91148150e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81848337e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[5.73380104e-03 9.32109555e-01 6.21566441e-02]\n",
      " [9.99804502e-01 6.00619838e-05 1.35435705e-04]\n",
      " [9.99994853e-01 1.58523914e-06 3.56134768e-06]\n",
      " ...\n",
      " [3.86364549e-06 4.13165521e-04 9.99582971e-01]\n",
      " [9.91148150e-01 1.73421428e-03 7.11763605e-03]\n",
      " [7.81848337e-01 6.52710113e-03 2.11624562e-01]]\n",
      "FCM training RMSE: 915.8796696739751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 18)\n",
      "[[5.73379686e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804502e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994853e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.86364760e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91148144e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81848208e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[5.73379686e-03 6.21566661e-02 9.32109537e-01]\n",
      " [9.99804502e-01 1.35435670e-04 6.00619529e-05]\n",
      " [9.99994853e-01 3.56134459e-06 1.58523729e-06]\n",
      " ...\n",
      " [3.86364760e-06 9.99582970e-01 4.13165920e-04]\n",
      " [9.91148144e-01 7.11764073e-03 1.73421487e-03]\n",
      " [7.81848208e-01 2.11624690e-01 6.52710275e-03]]\n",
      "FCM training RMSE: 915.8796940066387\n",
      "(2256, 18)\n",
      "[[6.21566492e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.35435692e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.56134660e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99582971e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.11763762e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.11624604e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[6.21566492e-02 5.73379945e-03 9.32109551e-01]\n",
      " [1.35435692e-04 9.99804502e-01 6.00619738e-05]\n",
      " [3.56134660e-06 9.99994853e-01 1.58523852e-06]\n",
      " ...\n",
      " [9.99582971e-01 3.86364615e-06 4.13165654e-04]\n",
      " [7.11763762e-03 9.91148148e-01 1.73421451e-03]\n",
      " [2.11624604e-01 7.81848294e-01 6.52710172e-03]]\n",
      "FCM training RMSE: 915.879678259271\n",
      "(2256, 18)\n",
      "[[9.32109544e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.00619622e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.58523784e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.13165802e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.73421471e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.52710229e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[9.32109544e-01 5.73379800e-03 6.21566584e-02]\n",
      " [6.00619622e-05 9.99804502e-01 1.35435680e-04]\n",
      " [1.58523784e-06 9.99994853e-01 3.56134548e-06]\n",
      " ...\n",
      " [4.13165802e-04 3.86364695e-06 9.99582971e-01]\n",
      " [1.73421471e-03 9.91148146e-01 7.11763934e-03]\n",
      " [6.52710229e-03 7.81848246e-01 2.11624652e-01]]\n",
      "FCM training RMSE: 915.8796870075448\n",
      "(2256, 18)\n",
      "[[5.73381447e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804502e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994853e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.86364043e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91148164e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81848675e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[5.73381447e-03 6.21566124e-02 9.32109573e-01]\n",
      " [9.99804502e-01 1.35435805e-04 6.00620611e-05]\n",
      " [9.99994853e-01 3.56135650e-06 1.58524406e-06]\n",
      " ...\n",
      " [3.86364043e-06 9.99582972e-01 4.13164467e-04]\n",
      " [9.91148164e-01 7.11762347e-03 1.73421233e-03]\n",
      " [7.81848675e-01 2.11624229e-01 6.52709616e-03]]\n",
      "FCM training RMSE: 915.879599610208\n",
      "(2256, 18)\n",
      "[[5.73381203e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99804502e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99994853e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.86364433e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.91148157e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.81848480e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 3)\n",
      "[[5.73381203e-03 9.32109502e-01 6.21566862e-02]\n",
      " [9.99804502e-01 6.00620089e-05 1.35435772e-04]\n",
      " [9.99994853e-01 1.58524137e-06 3.56135293e-06]\n",
      " ...\n",
      " [3.86364433e-06 4.13165058e-04 9.99582971e-01]\n",
      " [9.91148157e-01 1.73421257e-03 7.11763007e-03]\n",
      " [7.81848480e-01 6.52709750e-03 2.11624422e-01]]\n",
      "FCM training RMSE: 915.8796263862721\n",
      "(2256, 24)\n",
      "[[9.22950375e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.17032867e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.01926319e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.26057743e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.91665444e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.15956387e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[9.22950375e-01 1.07232196e-02 6.27398757e-02 3.58652990e-03]\n",
      " [2.17032867e-06 9.99261692e-01 4.55173903e-06 7.31585861e-04]\n",
      " [4.01926319e-06 3.97577205e-02 8.28053043e-06 9.60229980e-01]\n",
      " ...\n",
      " [2.26057743e-04 1.76470544e-06 9.99768941e-01 3.23649578e-06]\n",
      " [2.91665444e-05 9.99251348e-01 1.10602862e-04 6.08882526e-04]\n",
      " [1.15956387e-03 9.47532477e-01 3.25847350e-02 1.87232242e-02]]\n",
      "FCM training RMSE: 874.8834173801399\n",
      "(2256, 24)\n",
      "[[2.10799046e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.80046094e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42042332e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.91017947e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.83639163e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.99322218e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[2.10799046e-01 2.49869745e-02 4.94547720e-03 7.59268503e-01]\n",
      " [2.80046094e-04 5.68700634e-05 9.99624986e-01 3.80976270e-05]\n",
      " [1.42042332e-06 1.97501040e-06 9.99996061e-01 5.43614096e-07]\n",
      " ...\n",
      " [1.91017947e-02 9.80171306e-01 5.79548702e-06 7.21104024e-04]\n",
      " [5.83639163e-02 2.54213003e-03 9.37322830e-01 1.77112355e-03]\n",
      " [6.99322218e-01 1.97181281e-02 2.78231936e-01 2.72771757e-03]]\n",
      "FCM training RMSE: 957.3172097866972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 24)\n",
      "[[2.10799066e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.80046125e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42042334e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.91017901e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.83639239e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.99322240e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[2.10799066e-01 4.94547705e-03 2.49869721e-02 7.59268485e-01]\n",
      " [2.80046125e-04 9.99624986e-01 5.68700635e-05 3.80976286e-05]\n",
      " [1.42042334e-06 9.99996061e-01 1.97501018e-06 5.43614073e-07]\n",
      " ...\n",
      " [1.91017901e-02 5.79548610e-06 9.80171310e-01 7.21103914e-04]\n",
      " [5.83639239e-02 9.37322822e-01 2.54213000e-03 1.77112360e-03]\n",
      " [6.99322240e-01 2.78231916e-01 1.97181265e-02 2.72771743e-03]]\n",
      "FCM training RMSE: 957.3172102521793\n",
      "(2256, 24)\n",
      "[[1.64679332e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.42151546e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.91904090e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.24848980e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.63938884e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.54521086e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[1.64679332e-01 1.11550520e-02 4.07501077e-04 8.23758115e-01]\n",
      " [1.42151546e-05 2.36742259e-05 9.97883314e-01 2.07879658e-03]\n",
      " [3.91904090e-08 6.18198943e-08 9.99987251e-01 1.26478946e-05]\n",
      " ...\n",
      " [2.24848980e-05 9.99959380e-01 8.34165799e-08 1.80519698e-05]\n",
      " [1.63938884e-03 4.90756304e-03 4.01745724e-01 5.91707324e-01]\n",
      " [1.54521086e-03 2.45932184e-02 7.50325288e-02 8.98829042e-01]]\n",
      "FCM training RMSE: 817.2407150451296\n",
      "(2256, 24)\n",
      "[[1.07232622e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99261686e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.97571830e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.76470962e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99251352e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.47532668e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[1.07232622e-02 9.22950359e-01 3.58651403e-03 6.27398648e-02]\n",
      " [9.99261686e-01 2.17034211e-06 7.31592123e-04 4.55176708e-06]\n",
      " [3.97571830e-02 4.01922552e-06 9.60230517e-01 8.28045422e-06]\n",
      " ...\n",
      " [1.76470962e-06 2.26057785e-04 3.23648427e-06 9.99768941e-01]\n",
      " [9.99251352e-01 2.91664077e-05 6.08879043e-04 1.10602323e-04]\n",
      " [9.47532668e-01 1.15956045e-03 1.87231359e-02 3.25846355e-02]]\n",
      "FCM training RMSE: 874.8834170853768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 24)\n",
      "[[1.11549575e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.36742630e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.18204524e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99959379e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.90756514e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.45936978e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[1.11549575e-02 1.64677231e-01 4.07495804e-04 8.23760316e-01]\n",
      " [2.36742630e-05 1.42151337e-05 9.97883306e-01 2.07880416e-03]\n",
      " [6.18204524e-08 3.91906427e-08 9.99987251e-01 1.26480906e-05]\n",
      " ...\n",
      " [9.99959379e-01 2.24853302e-05 8.34181454e-08 1.80522682e-05]\n",
      " [4.90756514e-03 1.63938369e-03 4.01744259e-01 5.91708792e-01]\n",
      " [2.45936978e-02 1.54523128e-03 7.50337220e-02 8.98827349e-01]]\n",
      "FCM training RMSE: 817.240050591771\n",
      "(2256, 24)\n",
      "[[8.23761743e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.07882433e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.26480504e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.80522606e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.91712039e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.98827635e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[8.23761743e-01 1.11548731e-02 1.64675892e-01 4.07492096e-04]\n",
      " [2.07882433e-03 2.36743697e-05 1.42151923e-05 9.97883286e-01]\n",
      " [1.26480504e-05 6.18202003e-08 3.91904488e-08 9.99987251e-01]\n",
      " ...\n",
      " [1.80522606e-05 9.99959379e-01 2.24853736e-05 8.34182677e-08]\n",
      " [5.91712039e-01 4.90754303e-03 1.63937611e-03 4.01741042e-01]\n",
      " [8.98827635e-01 2.45936615e-02 1.54522775e-03 7.50334758e-02]]\n",
      "FCM training RMSE: 817.2398133828003\n",
      "(2256, 24)\n",
      "[[4.07500550e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.97883312e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99987251e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.34166516e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.01745388e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.50325540e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[4.07500550e-04 1.11550410e-02 8.23758324e-01 1.64679134e-01]\n",
      " [9.97883312e-01 2.36742366e-05 2.07879862e-03 1.42151589e-05]\n",
      " [9.99987251e-01 6.18198942e-08 1.26478988e-05 3.91904013e-08]\n",
      " ...\n",
      " [8.34166516e-08 9.99959380e-01 1.80519808e-05 2.24849186e-05]\n",
      " [4.01745388e-01 4.90756121e-03 5.91707663e-01 1.63938798e-03]\n",
      " [7.50325540e-02 2.45932340e-02 8.98829001e-01 1.54521135e-03]]\n",
      "FCM training RMSE: 817.2406686045289\n",
      "(2256, 24)\n",
      "[[4.07500984e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.97883315e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99987251e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.34166832e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.01745867e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.50326338e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[4.07500984e-04 8.23758163e-01 1.64679285e-01 1.11550517e-02]\n",
      " [9.97883315e-01 2.07879556e-03 1.42151486e-05 2.36742203e-05]\n",
      " [9.99987251e-01 1.26479119e-05 3.91904409e-08 6.18199540e-08]\n",
      " ...\n",
      " [8.34166832e-08 1.80519919e-05 2.24849258e-05 9.99959380e-01]\n",
      " [4.01745867e-01 5.91707179e-01 1.63938906e-03 4.90756490e-03]\n",
      " [7.50326338e-02 8.98828898e-01 1.54521261e-03 2.45932557e-02]]\n",
      "FCM training RMSE: 817.2406855826905\n",
      "(2256, 24)\n",
      "[[9.23977360e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00616309e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.38456900e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.40522039e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.76033194e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.46456643e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 4)\n",
      "[[9.23977360e-01 2.73593473e-03 3.11728830e-02 4.21138222e-02]\n",
      " [1.00616309e-04 9.99747835e-01 1.20437885e-04 3.11109643e-05]\n",
      " [9.38456900e-07 9.99994994e-01 2.63120187e-06 1.43605531e-06]\n",
      " ...\n",
      " [1.40522039e-04 3.39135737e-06 9.99433194e-01 4.22892737e-04]\n",
      " [5.76033194e-03 9.85864364e-01 7.69766760e-03 6.77636508e-04]\n",
      " [1.46456643e-02 7.68317256e-01 2.14226332e-01 2.81074678e-03]]\n",
      "FCM training RMSE: 947.8579645371606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 30)\n",
      "[[8.76448787e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.83565796e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16551166e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.93444750e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.83556653e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.59440132e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[8.76448787e-04 9.36036368e-05 3.63829624e-02 5.21888220e-03\n",
      "  9.57428103e-01]\n",
      " [1.83565796e-05 9.94875500e-01 1.68307322e-05 8.19009098e-05\n",
      "  5.00741136e-03]\n",
      " [2.16551166e-07 9.99914762e-01 9.31913095e-08 1.75265742e-07\n",
      "  8.47531431e-05]\n",
      " ...\n",
      " [9.93444750e-01 4.84020269e-07 1.25639815e-04 6.37289044e-03\n",
      "  5.62357548e-05]\n",
      " [9.83556653e-04 2.10444868e-01 9.41773669e-04 1.58706615e-02\n",
      "  7.71759140e-01]\n",
      " [1.59440132e-02 1.99915283e-01 2.84025244e-03 4.72586990e-01\n",
      "  3.08713462e-01]]\n",
      "FCM training RMSE: 783.9573414579685\n",
      "(2256, 30)\n",
      "[[9.35996358e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94875397e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99914762e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.84029251e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.10440811e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.99916059e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[9.35996358e-05 8.76411828e-04 9.57430087e-01 5.21863113e-03\n",
      "  3.63812702e-02]\n",
      " [9.94875397e-01 1.83568995e-05 5.00751294e-03 8.19020047e-05\n",
      "  1.68309723e-05]\n",
      " [9.99914762e-01 2.16552574e-07 8.47526591e-05 1.75266092e-07\n",
      "  9.31915426e-08]\n",
      " ...\n",
      " [4.84029251e-07 9.93444637e-01 5.62367172e-05 6.37300007e-03\n",
      "  1.25641724e-04]\n",
      " [2.10440811e-01 9.83544579e-04 7.71763498e-01 1.58703875e-02\n",
      "  9.41759025e-04]\n",
      " [1.99916059e-01 1.59440970e-02 3.08712363e-01 4.72587226e-01\n",
      "  2.84025469e-03]]\n",
      "FCM training RMSE: 783.9570462321955\n",
      "(2256, 30)\n",
      "[[1.19764838e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.73450371e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.78132241e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.24080177e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.22357167e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.84190901e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[1.19764838e-01 1.89432728e-02 4.65813411e-02 8.13470470e-01\n",
      "  1.24007811e-03]\n",
      " [9.73450371e-04 2.01405093e-05 9.39411723e-06 2.88820948e-05\n",
      "  9.98968133e-01]\n",
      " [4.78132241e-06 5.33869526e-08 5.53441298e-08 3.55576058e-08\n",
      "  9.99995074e-01]\n",
      " ...\n",
      " [4.24080177e-06 9.99988314e-01 5.54701226e-06 1.87642095e-06\n",
      "  2.21329092e-08]\n",
      " [2.22357167e-01 5.27202972e-03 8.95939661e-04 6.94439855e-03\n",
      "  7.64530465e-01]\n",
      " [9.84190901e-01 2.79157867e-03 1.28245190e-04 6.32556163e-04\n",
      "  1.22567185e-02]]\n",
      "FCM training RMSE: 945.1525966065524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 30)\n",
      "[[1.19764488e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.73446835e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.78133491e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.24081360e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.22356305e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.84190823e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[1.19764488e-01 4.65812961e-02 1.24007784e-03 1.89432669e-02\n",
      "  8.13470871e-01]\n",
      " [9.73446835e-04 9.39410014e-06 9.98968137e-01 2.01404801e-05\n",
      "  2.88820590e-05]\n",
      " [4.78133491e-06 5.53442533e-08 9.99995074e-01 5.33870755e-08\n",
      "  3.55577056e-08]\n",
      " ...\n",
      " [4.24081360e-06 5.54702281e-06 2.21329550e-08 9.99988314e-01\n",
      "  1.87642496e-06]\n",
      " [2.22356305e-01 8.95939316e-04 7.64531323e-01 5.27203112e-03\n",
      "  6.94440121e-03]\n",
      " [9.84190823e-01 1.28245730e-04 1.22567797e-02 2.79159193e-03\n",
      "  6.32559163e-04]]\n",
      "FCM training RMSE: 945.152606023661\n",
      "(2256, 30)\n",
      "[[9.57428180e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.00741506e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.47531322e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.62357922e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.71759293e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.08713395e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[9.57428180e-01 3.63828966e-02 5.21887257e-03 8.76447350e-04\n",
      "  9.36034827e-05]\n",
      " [5.00741506e-03 1.68307413e-05 8.19009526e-05 1.83565917e-05\n",
      "  9.94875497e-01]\n",
      " [8.47531322e-05 9.31913266e-08 1.75265774e-07 2.16551239e-07\n",
      "  9.99914762e-01]\n",
      " ...\n",
      " [5.62357922e-05 1.25639889e-04 6.37289450e-03 9.93444746e-01\n",
      "  4.84020618e-07]\n",
      " [7.71759293e-01 9.41773144e-04 1.58706519e-02 9.83556229e-04\n",
      "  2.10444725e-01]\n",
      " [3.08713395e-01 2.84025254e-03 4.72587016e-01 1.59440165e-02\n",
      "  1.99915320e-01]]\n",
      "FCM training RMSE: 783.9573304804572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 30)\n",
      "[[3.63829521e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.68307337e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.31913122e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.25639827e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.41773587e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.84025246e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[3.63829521e-02 9.57428115e-01 5.21888069e-03 8.76448563e-04\n",
      "  9.36036127e-05]\n",
      " [1.68307337e-05 5.00741193e-03 8.19009165e-05 1.83565815e-05\n",
      "  9.94875500e-01]\n",
      " [9.31913122e-08 8.47531414e-05 1.75265747e-07 2.16551177e-07\n",
      "  9.99914762e-01]\n",
      " ...\n",
      " [1.25639827e-04 5.62357607e-05 6.37289108e-03 9.93444749e-01\n",
      "  4.84020323e-07]\n",
      " [9.41773587e-04 7.71759164e-01 1.58706600e-02 9.83556587e-04\n",
      "  2.10444846e-01]\n",
      " [2.84025246e-03 3.08713451e-01 4.72586994e-01 1.59440137e-02\n",
      "  1.99915289e-01]]\n",
      "FCM training RMSE: 783.9573397423908\n",
      "(2256, 30)\n",
      "[[3.63829272e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.68307371e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.31913187e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.25639855e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.41773389e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.84025249e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[3.63829272e-02 5.21887706e-03 8.76448020e-04 9.36035545e-05\n",
      "  9.57428144e-01]\n",
      " [1.68307371e-05 8.19009327e-05 1.83565861e-05 9.94875498e-01\n",
      "  5.00741333e-03]\n",
      " [9.31913187e-08 1.75265759e-07 2.16551205e-07 9.99914762e-01\n",
      "  8.47531373e-05]\n",
      " ...\n",
      " [1.25639855e-04 6.37289261e-03 9.93444748e-01 4.84020455e-07\n",
      "  5.62357748e-05]\n",
      " [9.41773389e-04 1.58706564e-02 9.83556427e-04 2.10444792e-01\n",
      "  7.71759222e-01]\n",
      " [2.84025249e-03 4.72587004e-01 1.59440150e-02 1.99915303e-01\n",
      "  3.08713426e-01]]\n",
      "FCM training RMSE: 783.957335595878\n",
      "(2256, 30)\n",
      "[[4.76965259e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.39310649e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.59024894e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.85912879e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.94001230e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.36906372e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[4.76965259e-02 5.75072865e-02 2.78574611e-03 8.82577057e-01\n",
      "  9.43338426e-03]\n",
      " [2.39310649e-05 2.16161318e-04 9.99636648e-01 7.40759508e-05\n",
      "  4.91837175e-05]\n",
      " [7.59024894e-07 1.23852970e-06 9.99995811e-01 4.91314536e-07\n",
      "  1.70026891e-06]\n",
      " ...\n",
      " [4.85912879e-04 1.53989266e-02 3.65925540e-06 1.66358864e-04\n",
      "  9.83945142e-01]\n",
      " [6.94001230e-04 3.70329106e-02 9.54692685e-01 5.44612763e-03\n",
      "  2.13427545e-03]\n",
      " [1.36906372e-03 6.53792819e-01 3.17469684e-01 6.76325637e-03\n",
      "  2.06051766e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 968.8051017818673\n",
      "(2256, 30)\n",
      "[[9.35996206e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.94875407e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99914762e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.84029463e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.10441440e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.99916430e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[9.35996206e-05 9.57430122e-01 3.63812355e-02 5.21863214e-03\n",
      "  8.76411035e-04]\n",
      " [9.94875407e-01 5.00750319e-03 1.68309655e-05 8.19020407e-05\n",
      "  1.83568927e-05]\n",
      " [9.99914762e-01 8.47530208e-05 9.31919296e-08 1.75266966e-07\n",
      "  2.16553479e-07]\n",
      " ...\n",
      " [4.84029463e-07 5.62367341e-05 1.25641714e-04 6.37299284e-03\n",
      "  9.93444645e-01]\n",
      " [2.10441440e-01 7.71762818e-01 9.41760816e-04 1.58704349e-02\n",
      "  9.83546492e-04]\n",
      " [1.99916430e-01 3.08711181e-01 2.84025528e-03 4.72588031e-01\n",
      "  1.59441027e-02]]\n",
      "FCM training RMSE: 783.9570638079413\n",
      "(2256, 30)\n",
      "[[9.57428125e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.00741240e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.47531401e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.62357653e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.71759183e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.08713443e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 5)\n",
      "[[9.57428125e-01 3.63829439e-02 8.76448383e-04 5.21887949e-03\n",
      "  9.36035935e-05]\n",
      " [5.00741240e-03 1.68307348e-05 1.83565830e-05 8.19009218e-05\n",
      "  9.94875499e-01]\n",
      " [8.47531401e-05 9.31913143e-08 2.16551187e-07 1.75265751e-07\n",
      "  9.99914762e-01]\n",
      " ...\n",
      " [5.62357653e-05 1.25639836e-04 9.93444749e-01 6.37289158e-03\n",
      "  4.84020367e-07]\n",
      " [7.71759183e-01 9.41773522e-04 9.83556534e-04 1.58706588e-02\n",
      "  2.10444828e-01]\n",
      " [3.08713443e-01 2.84025247e-03 1.59440141e-02 4.72586997e-01\n",
      "  1.99915293e-01]]\n",
      "FCM training RMSE: 783.9573383742104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[3.44209033e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.27025601e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.85984612e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.83175947e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.61882600e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.24647649e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[3.44209033e-03 4.87144148e-05 3.70341521e-06 ... 2.49525678e-04\n",
      "  9.95892686e-01 2.99553122e-04]\n",
      " [1.27025601e-07 1.57745942e-06 7.24209433e-05 ... 4.06645400e-08\n",
      "  1.16497134e-05 2.76786491e-07]\n",
      " [1.85984612e-08 1.24481724e-06 9.98865458e-01 ... 2.56593077e-08\n",
      "  9.15267437e-06 3.38498597e-08]\n",
      " ...\n",
      " [2.83175947e-06 2.92334650e-06 3.28709174e-08 ... 7.76152749e-06\n",
      "  5.94537134e-06 8.18758988e-04]\n",
      " [3.61882600e-04 1.62775998e-03 2.14196724e-03 ... 4.95392117e-05\n",
      "  7.43594098e-02 1.81518979e-03]\n",
      " [3.24647649e-04 9.40090839e-01 1.28456586e-03 ... 6.67240084e-05\n",
      "  5.71944722e-03 1.14638663e-02]]\n",
      "FCM training RMSE: 802.5258830607335\n",
      "(2256, 48)\n",
      "[[3.70341578e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.24209440e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98865458e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.28709171e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.14196712e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.28456583e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[3.70341578e-06 2.49525717e-04 5.18796503e-05 ... 1.18471597e-05\n",
      "  9.95892686e-01 4.87144229e-05]\n",
      " [7.24209440e-05 4.06645401e-08 6.37350184e-08 ... 9.99913844e-01\n",
      "  1.16497128e-05 1.57745944e-06]\n",
      " [9.98865458e-01 2.56593071e-08 3.89937469e-08 ... 1.12402772e-03\n",
      "  9.15267416e-06 1.24481721e-06]\n",
      " ...\n",
      " [3.28709171e-08 7.76152744e-06 9.99161719e-01 ... 2.74309077e-08\n",
      "  5.94537144e-06 2.92334648e-06]\n",
      " [2.14196712e-03 4.95392091e-05 1.23576996e-04 ... 9.19520687e-01\n",
      "  7.43593974e-02 1.62775991e-03]\n",
      " [1.28456583e-03 6.67240066e-05 5.19560604e-04 ... 4.05303494e-02\n",
      "  5.71944679e-03 9.40090840e-01]]\n",
      "FCM training RMSE: 802.5258838757762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[5.08350945e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.54064955e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.45943495e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.37652719e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.24095394e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.24297628e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[5.08350945e-04 5.47628833e-03 1.20689820e-04 ... 2.12807900e-04\n",
      "  9.84713334e-01 8.91829097e-03]\n",
      " [2.54064955e-05 9.50509049e-06 7.97913992e-06 ... 7.27008945e-04\n",
      "  1.40132020e-02 3.13787769e-04]\n",
      " [1.45943495e-08 1.33956407e-08 2.12622755e-08 ... 3.97638063e-07\n",
      "  2.49536925e-06 4.91198316e-06]\n",
      " ...\n",
      " [1.37652719e-03 6.05048117e-06 9.98610501e-01 ... 1.12687254e-06\n",
      "  1.00936849e-06 3.44618914e-06]\n",
      " [5.24095394e-05 6.36514903e-06 5.41153182e-06 ... 6.53027210e-04\n",
      "  9.97946578e-01 1.50370717e-04]\n",
      " [5.24297628e-06 1.43161903e-07 4.68300881e-07 ... 9.99930510e-01\n",
      "  2.93501638e-05 9.45277296e-07]]\n",
      "FCM training RMSE: 838.596981071817\n",
      "(2256, 48)\n",
      "[[2.99533713e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.76785631e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.38500821e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.18760924e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.81521982e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.14639549e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[2.99533713e-04 3.44185576e-03 5.18765047e-05 ... 9.95892962e-01\n",
      "  2.49510879e-04 1.18462636e-05]\n",
      " [2.76785631e-07 1.27025088e-07 6.37349534e-08 ... 1.16499465e-05\n",
      "  4.06645257e-08 9.99913844e-01]\n",
      " [3.38500821e-08 1.85985675e-08 3.89940810e-08 ... 9.15275253e-06\n",
      "  2.56595499e-08 1.12404424e-03]\n",
      " ...\n",
      " [8.18760924e-04 2.83175966e-06 9.99161717e-01 ... 5.94533546e-06\n",
      "  7.76154679e-06 2.74307513e-08]\n",
      " [1.81521982e-03 3.61888203e-04 1.23579432e-04 ... 7.43640757e-02\n",
      "  4.95402210e-05 9.19515900e-01]\n",
      " [1.14639549e-02 3.24649772e-04 5.19565337e-04 ... 5.71960654e-03\n",
      "  6.67246701e-05 4.05304939e-02]]\n",
      "FCM training RMSE: 802.5255777130172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[1.18471439e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99913844e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12402801e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.74309050e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.19520603e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.05303520e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[1.18471439e-05 4.87143691e-05 3.44208681e-03 ... 9.95892690e-01\n",
      "  3.70341198e-06 5.18795950e-05]\n",
      " [9.99913844e-01 1.57745934e-06 1.27025593e-07 ... 1.16497169e-05\n",
      "  7.24209397e-05 6.37350172e-08]\n",
      " [1.12402801e-03 1.24481739e-06 1.85984628e-08 ... 9.15267554e-06\n",
      "  9.98865457e-01 3.89937527e-08]\n",
      " ...\n",
      " [2.74309050e-08 2.92334661e-06 2.83175948e-06 ... 5.94537080e-06\n",
      "  3.28709193e-08 9.99161719e-01]\n",
      " [9.19520603e-01 1.62776037e-03 3.61882684e-04 ... 7.43594797e-02\n",
      "  2.14196789e-03 1.23577039e-04]\n",
      " [4.05303520e-02 9.40090832e-01 3.24647681e-04 ... 5.71944960e-03\n",
      "  1.28456604e-03 5.19560687e-04]]\n",
      "FCM training RMSE: 802.5258784881391\n",
      "(2256, 48)\n",
      "[[1.18471516e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99913844e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12402787e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.74309063e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.19520644e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.05303507e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[1.18471516e-05 4.87143955e-05 2.99552999e-04 ... 9.95892688e-01\n",
      "  3.70341385e-06 5.18796221e-05]\n",
      " [9.99913844e-01 1.57745939e-06 2.76786486e-07 ... 1.16497149e-05\n",
      "  7.24209418e-05 6.37350178e-08]\n",
      " [1.12402787e-03 1.24481730e-06 3.38498611e-08 ... 9.15267486e-06\n",
      "  9.98865458e-01 3.89937499e-08]\n",
      " ...\n",
      " [2.74309063e-08 2.92334655e-06 8.18759000e-04 ... 5.94537111e-06\n",
      "  3.28709182e-08 9.99161719e-01]\n",
      " [9.19520644e-01 1.62776014e-03 1.81518998e-03 ... 7.43594393e-02\n",
      "  2.14196752e-03 1.23577018e-04]\n",
      " [4.05303507e-02 9.40090836e-01 1.14638669e-02 ... 5.71944823e-03\n",
      "  1.28456594e-03 5.19560646e-04]]\n",
      "FCM training RMSE: 802.5258811298544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[1.18462746e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99913844e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.12404404e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.74307532e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.19515958e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.05304921e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[1.18462746e-05 2.49511061e-04 9.95892959e-01 ... 2.99533951e-04\n",
      "  3.70320250e-06 3.44185864e-03]\n",
      " [9.99913844e-01 4.06645259e-08 1.16499437e-05 ... 2.76785641e-07\n",
      "  7.24207060e-05 1.27025094e-07]\n",
      " [1.12404404e-03 2.56595469e-08 9.15275157e-06 ... 3.38500794e-08\n",
      "  9.98865441e-01 1.85985662e-08]\n",
      " ...\n",
      " [2.74307532e-08 7.76154655e-06 5.94533590e-06 ... 8.18760900e-04\n",
      "  3.28710450e-08 2.83175966e-06]\n",
      " [9.19515958e-01 4.95402086e-05 7.43640183e-02 ... 1.81521945e-03\n",
      "  2.14201023e-03 3.61888134e-04]\n",
      " [4.05304921e-02 6.67246620e-05 5.71960458e-03 ... 1.14639538e-02\n",
      "  1.28457736e-03 3.24649746e-04]]\n",
      "FCM training RMSE: 802.5255814680345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[8.37908179e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.39128440e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.77325240e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.06684406e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.20200948e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00561570e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[8.37908179e-03 8.13493484e-01 1.16670038e-03 ... 1.11404565e-01\n",
      "  5.52642595e-02 8.39103034e-03]\n",
      " [4.39128440e-05 6.89982790e-02 2.87999240e-04 ... 2.19329014e-05\n",
      "  8.10485237e-04 7.18757556e-06]\n",
      " [1.77325240e-08 5.83128009e-06 8.21853608e-07 ... 1.04307701e-08\n",
      "  1.53239029e-05 1.44693794e-08]\n",
      " ...\n",
      " [1.06684406e-03 8.16697023e-07 2.26962158e-06 ... 3.18272236e-06\n",
      "  2.50398456e-06 8.68436955e-06]\n",
      " [1.20200948e-05 9.99786427e-01 1.10653965e-05 ... 2.73242019e-06\n",
      "  3.91328204e-05 3.87872535e-07]\n",
      " [1.00561570e-02 1.01277519e-01 8.80942933e-01 ... 3.12218044e-04\n",
      "  1.39203755e-03 6.59443244e-05]]\n",
      "FCM training RMSE: 801.4027657150592\n",
      "(2256, 48)\n",
      "[[9.95892694e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.16497196e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.15267644e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.94537039e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.43595339e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.71945145e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[9.95892694e-01 5.18795585e-05 3.70340948e-06 ... 3.44208409e-03\n",
      "  2.49525284e-04 4.87143336e-05]\n",
      " [1.16497196e-05 6.37350165e-08 7.24209369e-05 ... 1.27025587e-07\n",
      "  4.06645397e-08 1.57745927e-06]\n",
      " [9.15267644e-06 3.89937566e-08 9.98865457e-01 ... 1.85984641e-08\n",
      "  2.56593142e-08 1.24481751e-06]\n",
      " ...\n",
      " [5.94537039e-06 9.99161719e-01 3.28709208e-08 ... 2.83175948e-06\n",
      "  7.76152801e-06 2.92334669e-06]\n",
      " [7.43595339e-02 1.23577067e-04 2.14196840e-03 ... 3.61882749e-04\n",
      "  4.95392386e-05 1.62776068e-03]\n",
      " [5.71945145e-03 5.19560742e-04 1.28456617e-03 ... 3.24647705e-04\n",
      "  6.67240260e-05 9.40090828e-01]]\n",
      "FCM training RMSE: 802.5258749408817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 48)\n",
      "[[1.76828713e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.14949867e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.25186507e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.98915658e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.89247686e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.36076857e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 8)\n",
      "[[1.76828713e-03 5.52599257e-02 1.11396880e-01 ... 8.13506759e-01\n",
      "  8.37853550e-03 8.39051250e-03]\n",
      " [1.14949867e-05 8.10471753e-04 2.19323708e-05 ... 6.89934416e-02\n",
      "  4.39118140e-05 7.18742052e-06]\n",
      " [2.25186507e-08 1.53246364e-05 1.04311031e-08 ... 5.83130591e-06\n",
      "  1.77331050e-08 1.44698778e-08]\n",
      " ...\n",
      " [9.98915658e-01 2.50399569e-06 3.18276222e-06 ... 8.16729023e-07\n",
      "  1.06686107e-03 8.68449644e-06]\n",
      " [9.89247686e-07 3.91348352e-05 2.73255167e-06 ... 9.99786414e-01\n",
      "  1.20206847e-05 3.87892617e-07]\n",
      " [5.36076857e-04 1.39201684e-03 3.12212597e-04 ... 1.01274158e-01\n",
      "  1.00559856e-02 6.59433369e-05]]\n",
      "FCM training RMSE: 801.4026479744057\n",
      "(2256, 60)\n",
      "[[2.98187222e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.43895186e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.98330966e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.70928543e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.68213738e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.08013688e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[2.98187222e-04 7.96117622e-06 4.83588651e-06 ... 4.06098842e-03\n",
      "  6.47919120e-05 9.51348542e-03]\n",
      " [1.43895186e-07 9.99868461e-01 5.67629190e-05 ... 8.59621706e-08\n",
      "  4.12383719e-08 1.79390852e-06]\n",
      " [1.98330966e-08 1.67636610e-03 9.98313683e-01 ... 1.36306191e-08\n",
      "  2.54013621e-08 5.48115571e-06]\n",
      " ...\n",
      " [4.70928543e-04 4.68077759e-09 8.00045790e-09 ... 7.13213281e-07\n",
      "  9.99522400e-01 1.54462517e-06]\n",
      " [6.68213738e-05 1.48134526e-02 1.21210016e-04 ... 1.85934991e-05\n",
      "  6.35625836e-06 2.29898700e-04]\n",
      " [1.08013688e-05 4.08839595e-05 2.47999497e-06 ... 5.79541376e-07\n",
      "  8.15028290e-07 2.37240905e-06]]\n",
      "FCM training RMSE: 809.0425390864497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[8.90382850e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.90626848e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.14633282e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.17836165e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.86969451e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.05688293e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[8.90382850e-03 7.19370724e-04 1.53756353e-04 ... 9.83480278e-01\n",
      "  5.55045324e-03 2.19640540e-04]\n",
      " [3.90626848e-08 9.92498479e-08 2.82369487e-08 ... 4.16425332e-06\n",
      "  7.42579352e-08 1.39370542e-08]\n",
      " [2.14633282e-08 2.20428194e-08 2.81984828e-08 ... 8.13486495e-06\n",
      "  1.32372035e-08 1.99012612e-08]\n",
      " ...\n",
      " [2.17836165e-06 4.90250922e-04 9.99501817e-01 ... 1.55279836e-06\n",
      "  3.94693943e-07 1.42493501e-06]\n",
      " [1.86969451e-04 1.44415111e-03 1.35318268e-04 ... 4.34002931e-02\n",
      "  5.69445669e-04 3.28790913e-05]\n",
      " [8.05688293e-07 2.73140783e-05 2.04282244e-06 ... 1.75476267e-05\n",
      "  1.86647724e-06 1.94625218e-07]]\n",
      "FCM training RMSE: 838.1855908280781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[1.42425250e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.28489402e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.52758742e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.72012257e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.06987281e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99832583e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[1.42425250e-04 3.31155066e-04 3.64027641e-05 ... 9.51346275e-03\n",
      "  9.85539799e-01 4.83587789e-06]\n",
      " [3.28489402e-06 2.86381877e-08 3.43710187e-07 ... 1.79390137e-06\n",
      "  6.90531147e-05 5.67626387e-05]\n",
      " [4.52758742e-07 1.90054823e-08 5.98709390e-07 ... 5.48117988e-06\n",
      "  3.34001602e-06 9.98313674e-01]\n",
      " ...\n",
      " [4.72012257e-07 1.93747588e-06 1.61119351e-06 ... 1.54460421e-06\n",
      "  3.80468070e-07 8.00035782e-09]\n",
      " [7.06987281e-04 2.72440152e-06 2.16584532e-05 ... 2.29899080e-04\n",
      "  9.84012281e-01 1.21210183e-04]\n",
      " [9.99832583e-01 1.24418701e-07 4.89526842e-05 ... 2.37236140e-06\n",
      "  6.04088781e-05 2.47994721e-06]]\n",
      "FCM training RMSE: 809.0425589129859\n",
      "(2256, 60)\n",
      "[[6.47917087e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.12381551e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.54014175e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99522407e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.35626050e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.15010889e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[6.47917087e-05 3.31155093e-04 9.51346369e-03 ... 4.83587824e-06\n",
      "  1.42425285e-04 3.64027610e-05]\n",
      " [4.12381551e-08 2.86381928e-08 1.79390166e-06 ... 5.67626503e-05\n",
      "  3.28489388e-06 3.43710309e-07]\n",
      " [2.54014175e-08 1.90054792e-08 5.48117887e-06 ... 9.98313674e-01\n",
      "  4.52758560e-07 5.98709459e-07]\n",
      " ...\n",
      " [9.99522407e-01 1.93747692e-06 1.54460508e-06 ... 8.00036199e-09\n",
      "  4.72012650e-07 1.61119357e-06]\n",
      " [6.35626050e-06 2.72440136e-06 2.29899064e-04 ... 1.21210176e-04\n",
      "  7.06987173e-04 2.16584533e-05]\n",
      " [8.15010889e-07 1.24418804e-07 2.37236337e-06 ... 2.47994918e-06\n",
      "  9.99832583e-01 4.89527359e-05]]\n",
      "FCM training RMSE: 809.04255811556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[4.83588675e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.67629264e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.98313684e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.00046028e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.21210011e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.47999625e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[4.83588675e-06 1.42426126e-04 6.47919175e-05 ... 9.51348603e-03\n",
      "  3.31155753e-04 4.06098866e-03]\n",
      " [5.67629264e-05 3.28489049e-06 4.12383779e-08 ... 1.79390872e-06\n",
      "  2.86383149e-08 8.59621808e-08]\n",
      " [9.98313684e-01 4.52754255e-07 2.54013608e-08 ... 5.48115513e-06\n",
      "  1.90054075e-08 1.36306179e-08]\n",
      " ...\n",
      " [8.00046028e-09 4.72021933e-07 9.99522400e-01 ... 1.54462567e-06\n",
      "  1.93750150e-06 7.13213501e-07]\n",
      " [1.21210011e-04 7.06984593e-04 6.35625828e-06 ... 2.29898690e-04\n",
      "  2.72439746e-06 1.85934984e-05]\n",
      " [2.47999625e-06 9.99832579e-01 8.15028771e-07 ... 2.37241033e-06\n",
      "  1.24421261e-07 5.79541688e-07]]\n",
      "FCM training RMSE: 809.0425384053573\n",
      "(2256, 60)\n",
      "[[1.07079480e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.23941767e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.11138940e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99256215e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.57862081e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.01757270e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[1.07079480e-04 6.63917234e-03 3.45460610e-06 ... 4.93553934e-04\n",
      "  1.39361948e-05 2.05749914e-04]\n",
      " [6.23941767e-08 1.23610450e-07 6.45400556e-05 ... 3.95217672e-08\n",
      "  9.99797797e-01 4.10785960e-05]\n",
      " [5.11138940e-08 2.51762560e-08 9.91842316e-01 ... 3.34412185e-08\n",
      "  2.36025409e-03 5.78678286e-03]\n",
      " ...\n",
      " [9.99256215e-01 1.86531256e-06 1.25459546e-08 ... 4.80682494e-06\n",
      "  1.30889962e-08 1.47491710e-07]\n",
      " [6.57862081e-06 1.86450134e-05 6.39862011e-05 ... 2.59498728e-06\n",
      "  1.64765218e-02 5.28860362e-04]\n",
      " [5.01757270e-04 3.14200532e-04 1.14341467e-03 ... 6.48290125e-05\n",
      "  2.89331647e-02 1.60821323e-03]]\n",
      "FCM training RMSE: 774.479042019878\n",
      "(2256, 60)\n",
      "[[9.51348424e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.79390815e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.48115695e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.54462409e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.29898720e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.37240658e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[9.51348424e-03 3.31155699e-04 7.96117516e-06 ... 2.98187201e-04\n",
      "  4.83588606e-06 3.64026940e-05]\n",
      " [1.79390815e-06 2.86383051e-08 9.99868461e-01 ... 1.43895160e-07\n",
      "  5.67629044e-05 3.43712979e-07]\n",
      " [5.48115695e-06 1.90054130e-08 1.67636659e-03 ... 1.98331013e-08\n",
      "  9.98313683e-01 5.98710971e-07]\n",
      " ...\n",
      " [1.54462409e-06 1.93749962e-06 4.68077433e-09 ... 4.70928170e-04\n",
      "  8.00045275e-09 1.61119476e-06]\n",
      " [2.29898720e-04 2.72439777e-06 1.48134535e-02 ... 6.68213824e-05\n",
      "  1.21210025e-04 2.16584536e-05]\n",
      " [2.37240658e-06 1.24421065e-07 4.08839118e-05 ... 1.08013588e-05\n",
      "  2.47999249e-06 4.89538683e-05]]\n",
      "FCM training RMSE: 809.042540136749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[9.99212523e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.87279048e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.16067816e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [6.95140241e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.93255109e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.76967937e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[9.99212523e-01 3.78906157e-05 9.24140731e-06 ... 4.91393781e-04\n",
      "  7.93660181e-07 1.64580922e-05]\n",
      " [2.87279048e-05 1.35870996e-07 4.11612540e-07 ... 8.01210933e-08\n",
      "  4.72355474e-05 2.35873614e-08]\n",
      " [1.16067816e-05 3.49735951e-08 1.54383872e-06 ... 2.35866495e-08\n",
      "  9.97189766e-01 4.14649193e-08]\n",
      " ...\n",
      " [6.95140241e-07 4.40423939e-04 2.31342657e-06 ... 6.68018617e-07\n",
      "  9.28019775e-09 1.49358696e-06]\n",
      " [7.93255109e-01 7.96186443e-04 3.72135956e-04 ... 2.17707959e-04\n",
      "  1.58508319e-03 2.29983974e-05]\n",
      " [2.76967937e-05 1.20151269e-05 3.80695906e-05 ... 6.36525935e-07\n",
      "  2.77570938e-06 1.01509589e-07]]\n",
      "FCM training RMSE: 842.2244327672223\n",
      "(2256, 60)\n",
      "[[1.42425317e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.28489375e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.52758396e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.72013004e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.06987074e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99832583e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[1.42425317e-04 7.96115748e-06 9.51346454e-03 ... 6.47917166e-05\n",
      "  4.06098021e-03 9.85539796e-01]\n",
      " [3.28489375e-06 9.99868462e-01 1.79390193e-06 ... 4.12381636e-08\n",
      "  8.59618230e-08 6.90531448e-05]\n",
      " [4.52758396e-07 1.67637494e-03 5.48117797e-06 ... 2.54014153e-08\n",
      "  1.36306666e-08 3.34001528e-06]\n",
      " ...\n",
      " [4.72013004e-07 4.68071936e-09 1.54460586e-06 ... 9.99522406e-01\n",
      "  7.13204756e-07 3.80468437e-07]\n",
      " [7.06987074e-04 1.48134673e-02 2.29899050e-04 ... 6.35626041e-06\n",
      "  1.85935225e-05 9.84012282e-01]\n",
      " [9.99832583e-01 4.08831142e-05 2.37236517e-06 ... 8.15011573e-07\n",
      "  5.79530648e-07 6.04089734e-05]]\n",
      "FCM training RMSE: 809.0425573469759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 60)\n",
      "[[3.64027595e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.43710363e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.98709490e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.61119359e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16584533e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.89527588e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 10)\n",
      "[[3.64027595e-05 4.06098004e-03 1.42425301e-04 ... 7.96115708e-06\n",
      "  9.51346410e-03 6.47917126e-05]\n",
      " [3.43710363e-07 8.59618156e-08 3.28489381e-06 ... 9.99868462e-01\n",
      "  1.79390179e-06 4.12381592e-08]\n",
      " [5.98709490e-07 1.36306675e-08 4.52758479e-07 ... 1.67637512e-03\n",
      "  5.48117841e-06 2.54014164e-08]\n",
      " ...\n",
      " [1.61119359e-06 7.13204585e-07 4.72012826e-07 ... 4.68071819e-09\n",
      "  1.54460548e-06 9.99522407e-01]\n",
      " [2.16584533e-05 1.85935230e-05 7.06987126e-04 ... 1.48134677e-02\n",
      "  2.29899057e-04 6.35626046e-06]\n",
      " [4.89527588e-05 5.79530419e-07 9.99832583e-01 ... 4.08830962e-05\n",
      "  2.37236424e-06 8.15011219e-07]]\n",
      "FCM training RMSE: 809.0425577939156\n",
      "(2256, 90)\n",
      "[[2.05150716e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.18934837e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.61113208e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.73359330e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.71422462e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.05273846e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[2.05150716e-05 2.98864606e-06 1.34211968e-06 ... 1.88787271e-07\n",
      "  1.99046371e-06 7.53804473e-08]\n",
      " [1.18934837e-06 3.47246297e-07 5.99089187e-08 ... 1.07234355e-08\n",
      "  3.19206778e-08 1.64518903e-06]\n",
      " [1.61113208e-06 1.09568471e-08 1.31045232e-09 ... 1.97009169e-09\n",
      "  2.24481868e-09 5.02267552e-06]\n",
      " ...\n",
      " [1.73359330e-07 1.36154893e-06 1.44917542e-05 ... 7.31642226e-03\n",
      "  9.92660004e-01 1.06676378e-08]\n",
      " [3.71422462e-05 4.79150770e-05 1.08226821e-05 ... 4.42411040e-07\n",
      "  3.24396332e-06 7.85443492e-06]\n",
      " [1.05273846e-06 1.79758568e-03 4.07087572e-06 ... 1.50093576e-07\n",
      "  1.11013547e-06 2.27070286e-05]]\n",
      "FCM training RMSE: 775.2662962845978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[9.61193148e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.01648510e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.78378057e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.59346227e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.85640539e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.22349365e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[9.61193148e-01 6.35281869e-05 3.63310686e-04 ... 7.46142976e-05\n",
      "  8.27361459e-06 1.68243526e-04]\n",
      " [3.01648510e-05 1.40013379e-08 3.98128222e-08 ... 6.23787869e-08\n",
      "  9.99912204e-01 5.25765261e-08]\n",
      " [6.78378057e-07 4.06885822e-09 3.97908162e-09 ... 3.37586205e-08\n",
      "  3.84368529e-04 2.43729918e-09]\n",
      " ...\n",
      " [9.59346227e-08 9.94707559e-01 5.27067377e-03 ... 5.29483433e-06\n",
      "  1.11824960e-09 1.31979821e-05]\n",
      " [9.85640539e-01 4.62700540e-06 3.19301929e-05 ... 1.30295567e-05\n",
      "  1.15693071e-02 5.56203287e-05]\n",
      " [4.22349365e-05 4.41304338e-07 3.42870949e-06 ... 1.25222150e-05\n",
      "  1.92397106e-05 6.01646664e-06]]\n",
      "FCM training RMSE: 775.6567927339316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[1.57528231e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.06015069e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.12883124e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.98186045e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.39347607e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.86485225e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[1.57528231e-04 6.34764211e-06 2.34772732e-05 ... 3.71220963e-03\n",
      "  6.59813831e-06 2.75010441e-04]\n",
      " [7.06015069e-06 9.99921306e-01 7.24474650e-08 ... 2.62655286e-08\n",
      "  1.53103849e-06 8.36597967e-09]\n",
      " [2.12883124e-04 2.80071594e-04 4.91037414e-08 ... 1.83300442e-09\n",
      "  1.39801158e-05 2.42139319e-09]\n",
      " ...\n",
      " [2.98186045e-09 1.86549020e-10 7.35113114e-08 ... 3.29880117e-08\n",
      "  1.37568834e-09 8.43476217e-08]\n",
      " [5.39347607e-04 1.44581688e-02 1.50658353e-05 ... 1.94826535e-05\n",
      "  5.44245887e-05 2.70159691e-06]\n",
      " [4.86485225e-06 5.34315845e-05 9.34619220e-05 ... 1.26830703e-06\n",
      "  7.63057191e-05 2.60667802e-07]]\n",
      "FCM training RMSE: 770.0863441255098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[3.43991033e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.45716898e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.64699106e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.22708169e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.22953137e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.78990035e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[3.43991033e-06 4.40222473e-07 7.24310300e-07 ... 6.60859738e-06\n",
      "  9.99475117e-01 8.68800732e-07]\n",
      " [4.45716898e-08 7.43121888e-05 6.20830370e-08 ... 6.89043562e-02\n",
      "  2.17735478e-05 2.71228390e-07]\n",
      " [1.64699106e-08 4.60407071e-06 2.09196190e-08 ... 1.88334751e-04\n",
      "  9.28026402e-07 1.69092108e-07]\n",
      " ...\n",
      " [4.22708169e-07 1.11902257e-08 9.99775934e-01 ... 7.32162795e-09\n",
      "  2.75433324e-07 5.52737347e-06]\n",
      " [2.22953137e-07 1.80789181e-04 5.15158852e-07 ... 9.93726487e-01\n",
      "  5.60914172e-03 1.43782752e-06]\n",
      " [3.78990035e-08 9.98792096e-01 2.10677445e-07 ... 1.36236214e-05\n",
      "  1.28530052e-05 5.70492177e-06]]\n",
      "FCM training RMSE: 762.9908958396934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[7.75525064e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.41270543e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.24393690e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.97342298e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.98876157e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.46301069e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[7.75525064e-06 2.07996689e-02 3.71253536e-03 ... 2.74683569e-04\n",
      "  1.70261547e-06 2.53865241e-04]\n",
      " [1.41270543e-06 3.36479866e-07 3.36281426e-08 ... 1.07049342e-08\n",
      "  2.47312777e-05 3.18956049e-07]\n",
      " [8.24393690e-06 2.80820964e-07 2.40065238e-09 ... 3.16952151e-09\n",
      "  9.99348585e-01 1.95324464e-08]\n",
      " ...\n",
      " [1.97342298e-09 2.06871894e-07 3.48569008e-08 ... 8.90693967e-08\n",
      "  1.85758436e-10 1.84060355e-07]\n",
      " [4.98876157e-05 1.41235242e-04 1.93862969e-05 ... 2.68624211e-06\n",
      "  6.84243802e-05 3.00179564e-04]\n",
      " [3.46301069e-05 1.34201664e-06 4.14135104e-07 ... 8.50571188e-08\n",
      "  8.88746549e-07 4.01266644e-03]]\n",
      "FCM training RMSE: 773.082453514985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[1.23559412e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.32758553e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.99795328e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.74862529e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.70971444e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.62178359e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[1.23559412e-07 6.35507905e-07 2.18812558e-04 ... 7.08348614e-06\n",
      "  9.99406504e-01 2.51225725e-07]\n",
      " [1.32758553e-04 4.30968727e-08 1.39896485e-07 ... 2.01873098e-07\n",
      "  2.88699450e-05 7.75330400e-06]\n",
      " [9.99795328e-01 2.23960601e-09 2.08986420e-09 ... 1.80703098e-09\n",
      "  1.28237041e-07 8.08653497e-06]\n",
      " ...\n",
      " [3.74862529e-10 1.53122990e-03 8.87051125e-08 ... 4.93347500e-05\n",
      "  5.85722326e-08 2.15837016e-09]\n",
      " [1.70971444e-05 3.91986911e-07 2.19434423e-06 ... 7.22118269e-06\n",
      "  1.38445653e-02 7.51210924e-06]\n",
      " [4.62178359e-07 1.01544724e-07 1.59777190e-07 ... 1.93195641e-06\n",
      "  1.46214676e-05 1.35887657e-05]]\n",
      "FCM training RMSE: 770.2067797951216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[3.91027559e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.27920518e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.00328232e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.65973915e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.04830733e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.40553203e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[3.91027559e-04 2.00191797e-04 2.13164353e-04 ... 1.22566465e-05\n",
      "  1.74293853e-03 9.57393402e-01]\n",
      " [2.27920518e-08 2.05686387e-06 1.94474044e-05 ... 6.29695339e-06\n",
      "  7.17463323e-08 6.63381827e-05]\n",
      " [3.00328232e-09 5.58241357e-08 2.88580692e-04 ... 1.60893127e-05\n",
      "  1.63075213e-09 6.08567858e-07]\n",
      " ...\n",
      " [8.65973915e-08 2.89774883e-08 2.97886994e-09 ... 1.54071337e-09\n",
      "  1.54342941e-08 1.68602879e-08]\n",
      " [2.04830733e-06 4.55291319e-04 3.99547317e-04 ... 6.66955830e-05\n",
      "  1.52404568e-05 9.86719788e-01]\n",
      " [2.40553203e-07 9.99464184e-01 4.50078342e-06 ... 1.73502136e-04\n",
      "  1.20529500e-06 1.30516915e-04]]\n",
      "FCM training RMSE: 780.6598703297524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[1.55565403e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.27013250e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.44089117e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [9.99076357e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.41566591e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.52490680e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[1.55565403e-06 1.00341141e-04 3.41002751e-08 ... 2.08968082e-07\n",
      "  3.71023066e-05 4.52714154e-06]\n",
      " [7.27013250e-08 2.35089173e-06 9.54271774e-01 ... 2.91604125e-08\n",
      "  1.04278060e-07 7.40405660e-07]\n",
      " [2.44089117e-09 5.67764915e-07 1.55437041e-04 ... 1.79586674e-09\n",
      "  1.27570817e-09 6.90177066e-09]\n",
      " ...\n",
      " [9.99076357e-01 4.22044778e-08 7.84683803e-11 ... 8.90372541e-04\n",
      "  2.01664897e-08 3.20529699e-07]\n",
      " [1.41566591e-06 2.70360286e-05 4.21570083e-04 ... 2.98512125e-07\n",
      "  2.02656138e-06 3.23400031e-05]\n",
      " [4.52490680e-06 7.26394554e-06 6.26845993e-05 ... 9.02325306e-07\n",
      "  1.73884421e-06 2.54870911e-03]]\n",
      "FCM training RMSE: 766.2212003846194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[4.11357082e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.39845577e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.28531378e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.48180903e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.70477342e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.41407366e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[4.11357082e-08 2.64503251e-07 1.90097810e-04 ... 1.99434117e-06\n",
      "  1.33592311e-05 3.46073881e-05]\n",
      " [9.39845577e-01 5.76623015e-07 2.60548795e-06 ... 3.64433528e-06\n",
      "  1.03587339e-07 2.02200522e-07]\n",
      " [2.28531378e-04 6.90408227e-08 4.21401428e-07 ... 3.69967084e-08\n",
      "  3.79269556e-09 2.46433407e-09]\n",
      " ...\n",
      " [1.48180903e-10 7.52355578e-08 1.52391180e-07 ... 5.74947912e-08\n",
      "  1.04020636e-07 3.09000038e-08]\n",
      " [3.70477342e-04 1.11784591e-06 1.25737648e-05 ... 3.34754298e-05\n",
      "  4.05527534e-07 1.36609287e-06]\n",
      " [5.41407366e-04 6.10862302e-04 3.09330643e-05 ... 9.94744410e-01\n",
      "  3.16424864e-06 8.38804000e-06]]\n",
      "FCM training RMSE: 768.441455318789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 90)\n",
      "[[2.55845011e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.08037519e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.03893951e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.89890340e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.14744333e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.19110555e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 15)\n",
      "[[2.55845011e-05 7.93828863e-05 1.00261974e-05 ... 1.68219171e-03\n",
      "  2.42706528e-02 1.04108407e-02]\n",
      " [2.08037519e-08 1.46252839e-07 9.99846083e-01 ... 7.58268443e-08\n",
      "  9.15467546e-07 7.19525582e-08]\n",
      " [4.03893951e-09 3.94632033e-08 3.34271680e-04 ... 2.07429137e-09\n",
      "  4.54348931e-07 3.99835266e-09]\n",
      " ...\n",
      " [4.89890340e-04 3.03586954e-07 8.37532589e-11 ... 5.88728892e-09\n",
      "  6.44891412e-08 2.69132710e-08]\n",
      " [2.14744333e-06 1.29019530e-05 1.21822453e-02 ... 1.56136042e-05\n",
      "  1.30462556e-04 1.30845490e-05]\n",
      " [5.19110555e-07 3.28546095e-05 6.89167723e-05 ... 1.01114385e-06\n",
      "  3.54031670e-06 8.70992268e-07]]\n",
      "FCM training RMSE: 782.7400657504015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[9.83189056e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.39575156e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.07353114e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [8.43676050e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.76010316e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.72465207e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[9.83189056e-01 3.19164268e-06 4.45936046e-07 ... 1.67021382e-02\n",
      "  4.23565721e-07 3.39572174e-05]\n",
      " [3.39575156e-07 1.22456757e-08 1.25125096e-08 ... 1.84015060e-05\n",
      "  2.16648334e-08 2.51640273e-06]\n",
      " [3.07353114e-07 1.86595615e-08 1.56851847e-08 ... 1.86964938e-06\n",
      "  5.38951060e-08 3.82725526e-05]\n",
      " ...\n",
      " [8.43676050e-08 1.60294231e-08 9.99929911e-01 ... 4.99076522e-09\n",
      "  7.46287758e-06 5.41734133e-09]\n",
      " [5.76010316e-05 4.60493127e-07 7.76083403e-07 ... 9.89299178e-02\n",
      "  8.96322307e-07 9.52475263e-05]\n",
      " [5.72465207e-07 2.24936327e-08 7.00269168e-08 ... 1.60030041e-05\n",
      "  2.05171621e-07 8.01729789e-07]]\n",
      "FCM training RMSE: 758.3938604663724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[2.28495110e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.58157046e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.75986962e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.71119481e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.30204639e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.44351916e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[2.28495110e-09 7.29047592e-10 5.35988279e-09 ... 3.93042489e-08\n",
      "  4.88819960e-08 9.90859945e-11]\n",
      " [2.58157046e-05 8.70247124e-07 4.61623292e-08 ... 8.75172670e-08\n",
      "  2.16627775e-08 1.15288244e-05]\n",
      " [1.75986962e-01 2.99339711e-05 1.65270376e-07 ... 3.72354766e-08\n",
      "  8.56532002e-09 8.21223982e-01]\n",
      " ...\n",
      " [4.71119481e-09 1.17546650e-08 5.58313582e-06 ... 1.93289029e-05\n",
      "  3.73761432e-08 7.55877534e-10]\n",
      " [4.30204639e-05 4.05354264e-06 1.42937658e-06 ... 1.41698099e-05\n",
      "  1.15865088e-06 3.66711941e-06]\n",
      " [1.44351916e-06 3.96939737e-05 1.23374149e-05 ... 5.34505432e-05\n",
      "  3.46187138e-07 7.87243357e-07]]\n",
      "FCM training RMSE: 759.5304263305769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[2.38342159e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.37034308e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.02883728e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.17285617e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.11157560e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.73190462e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[2.38342159e-07 9.81294158e-07 9.98645481e-01 ... 5.74194449e-07\n",
      "  3.76556562e-08 1.02082103e-07]\n",
      " [7.37034308e-06 1.38237599e-04 2.54607633e-05 ... 3.20213385e-08\n",
      "  5.87753258e-05 9.18648215e-01]\n",
      " [8.02883728e-05 1.22251840e-01 9.69505895e-07 ... 1.37854233e-08\n",
      "  8.76244072e-01 1.21030007e-03]\n",
      " ...\n",
      " [1.17285617e-11 7.36090480e-12 3.39239297e-10 ... 1.43210748e-05\n",
      "  1.11646361e-12 1.03097274e-12]\n",
      " [6.11157560e-06 5.97472175e-05 1.16516939e-02 ... 2.78969275e-07\n",
      "  4.51947271e-06 4.16159795e-04]\n",
      " [4.73190462e-05 2.50698808e-06 5.56872810e-05 ... 3.30753249e-07\n",
      "  1.28775055e-06 2.81917200e-05]]\n",
      "FCM training RMSE: 760.4342852816629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[7.71472999e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.39217776e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.16295816e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.16472779e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.67901307e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.35719921e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[7.71472999e-08 2.02514789e-09 9.99934411e-01 ... 1.10851351e-07\n",
      "  6.88948362e-09 1.15782120e-06]\n",
      " [3.39217776e-09 1.37147587e-02 1.00567812e-06 ... 1.58453577e-08\n",
      "  9.37674787e-07 1.49682051e-08]\n",
      " [2.16295816e-09 9.32710964e-05 6.66813523e-08 ... 8.69306675e-09\n",
      "  1.46962054e-05 1.27044859e-09]\n",
      " ...\n",
      " [5.16472779e-08 9.67911549e-11 7.40733907e-08 ... 9.69816529e-05\n",
      "  1.22458956e-09 1.35413457e-08]\n",
      " [7.67901307e-08 8.18779630e-05 8.31285268e-04 ... 7.02660690e-07\n",
      "  2.84727359e-06 9.85398835e-07]\n",
      " [1.35719921e-08 5.77452277e-06 3.86604676e-06 ... 7.89939676e-07\n",
      "  6.62391393e-06 1.07676213e-07]]\n",
      "FCM training RMSE: 757.1166957276256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[3.00827502e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.31622992e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.32873716e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.44800862e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.06833190e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.74284178e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[3.00827502e-06 4.61107549e-09 3.52246988e-07 ... 6.60947891e-08\n",
      "  1.06714951e-04 8.29923196e-09]\n",
      " [1.31622992e-07 1.04025530e-04 3.61859288e-05 ... 8.50085201e-05\n",
      "  2.87282553e-05 9.15748058e-01]\n",
      " [1.32873716e-09 9.99475106e-01 2.72473071e-04 ... 8.17751117e-07\n",
      "  1.79183822e-07 2.06007481e-04]\n",
      " ...\n",
      " [1.44800862e-08 1.70454443e-10 2.68030796e-09 ... 1.61950034e-09\n",
      "  7.65952890e-08 1.27606072e-10]\n",
      " [2.06833190e-06 7.53869616e-06 5.20996016e-05 ... 2.08583596e-04\n",
      "  1.06680705e-02 4.27897411e-04]\n",
      " [3.74284178e-07 7.75685670e-07 1.35828354e-06 ... 9.95374855e-01\n",
      "  6.86092180e-04 1.53221758e-05]]\n",
      "FCM training RMSE: 759.6185131837348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[9.46391363e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.25128596e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.11448013e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [5.66272890e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.27477041e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.80620371e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[9.46391363e-07 1.00981139e-06 1.27598259e-06 ... 5.32623897e-03\n",
      "  8.52129255e-06 3.05958867e-06]\n",
      " [1.25128596e-07 1.98327446e-07 2.73763711e-01 ... 8.09591590e-05\n",
      "  1.39425791e-07 4.72158918e-07]\n",
      " [6.11448013e-09 5.54072524e-08 2.93868041e-04 ... 1.09244842e-06\n",
      "  5.39713162e-09 2.08971541e-08]\n",
      " ...\n",
      " [5.66272890e-07 1.97952785e-07 7.20624465e-12 ... 1.68685547e-10\n",
      "  1.21449294e-10 2.92626433e-08]\n",
      " [9.27477041e-06 5.34403228e-06 7.53565271e-01 ... 2.44235346e-01\n",
      "  5.79838538e-06 4.51442783e-05]\n",
      " [2.80620371e-06 7.97996485e-06 3.40858118e-05 ... 1.00345379e-04\n",
      "  6.72230146e-07 8.18441338e-05]]\n",
      "FCM training RMSE: 762.8111580684458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[5.17266837e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.97649786e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.88962105e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.42299167e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.48502413e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.25575542e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[5.17266837e-06 2.20762042e-06 1.42233965e-07 ... 9.99803483e-01\n",
      "  2.55474266e-07 1.70439239e-07]\n",
      " [4.97649786e-07 2.80364286e-08 6.34324878e-09 ... 3.35122020e-07\n",
      "  3.29754935e-07 1.46757509e-08]\n",
      " [3.88962105e-06 5.86684900e-09 1.02354887e-08 ... 2.26920689e-07\n",
      "  9.46433283e-08 1.13164996e-08]\n",
      " ...\n",
      " [4.42299167e-10 1.19885958e-10 4.74277992e-10 ... 2.64068489e-09\n",
      "  5.62629578e-10 9.99985124e-01]\n",
      " [2.48502413e-05 3.16595974e-06 2.42223417e-07 ... 8.40140452e-05\n",
      "  4.06527921e-05 1.53168561e-06]\n",
      " [4.25575542e-06 1.33430718e-06 1.66196900e-07 ... 8.44293276e-06\n",
      "  7.71100737e-02 2.06855197e-06]]\n",
      "FCM training RMSE: 770.7263451253212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[1.33459182e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.23513114e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.64583879e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.20134487e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.92075010e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.61060030e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[1.33459182e-06 5.45254094e-05 6.37552004e-08 ... 6.97650560e-07\n",
      "  3.97420018e-07 1.55431562e-08]\n",
      " [1.23513114e-02 3.09549266e-07 1.20840914e-05 ... 9.86620684e-09\n",
      "  7.21404471e-06 1.86371469e-04]\n",
      " [2.64583879e-05 2.39616578e-07 5.33935541e-07 ... 2.71228031e-09\n",
      "  2.01697528e-04 8.35911106e-04]\n",
      " ...\n",
      " [4.20134487e-10 5.52207443e-08 5.81675692e-10 ... 2.60048489e-08\n",
      "  9.62023677e-10 1.23776292e-10]\n",
      " [9.92075010e-01 1.16847455e-05 1.25151510e-04 ... 2.26080974e-07\n",
      "  3.98522707e-05 6.26053304e-05]\n",
      " [4.61060030e-06 2.21100653e-07 9.98701472e-01 ... 1.49088535e-08\n",
      "  2.68739267e-07 1.07332135e-05]]\n",
      "FCM training RMSE: 757.6950674970648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[2.06601409e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.47727095e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.28085981e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [4.43605115e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.73439316e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.94639759e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[2.06601409e-07 2.79631600e-06 1.15119221e-06 ... 2.20118669e-06\n",
      "  2.11270715e-06 3.16291560e-06]\n",
      " [5.47727095e-09 8.90995981e-05 3.77350735e-08 ... 6.02684749e-08\n",
      "  1.75055194e-09 1.10812537e-08]\n",
      " [1.28085981e-08 6.67664590e-04 2.02126237e-08 ... 7.40557348e-09\n",
      "  1.81051953e-09 9.33727634e-09]\n",
      " ...\n",
      " [4.43605115e-10 9.80435210e-13 1.06492117e-10 ... 5.84736627e-11\n",
      "  4.40874673e-11 4.21971003e-08]\n",
      " [2.73439316e-06 1.32111804e-02 4.26726681e-05 ... 2.08536937e-04\n",
      "  1.07718749e-06 1.56989890e-05]\n",
      " [7.94639759e-07 2.10223600e-06 4.75078043e-04 ... 6.44500243e-04\n",
      "  2.44090822e-08 2.87764291e-06]]\n",
      "FCM training RMSE: 771.2026723154366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 120)\n",
      "[[4.66338452e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.81343051e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.07766461e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.28590998e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.45593611e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.03201247e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 20)\n",
      "[[4.66338452e-07 1.45889301e-07 1.71442245e-09 ... 6.77099378e-10\n",
      "  4.12903366e-09 2.25143641e-07]\n",
      " [4.81343051e-06 2.01103272e-08 9.95710613e-01 ... 2.35909675e-05\n",
      "  3.75775279e-06 7.32649402e-07]\n",
      " [5.07766461e-05 1.06857595e-08 6.16200965e-04 ... 4.33953666e-01\n",
      "  5.98053682e-05 4.57106948e-08]\n",
      " ...\n",
      " [1.28590998e-08 8.27814006e-08 1.24919337e-10 ... 1.53015271e-10\n",
      "  1.52228851e-09 1.46675320e-07]\n",
      " [7.45593611e-06 5.02527454e-08 8.63213244e-05 ... 7.32665849e-07\n",
      "  1.08582618e-06 1.21575161e-05]\n",
      " [1.03201247e-05 4.45063310e-07 7.99179357e-05 ... 3.54360684e-06\n",
      "  1.44846213e-04 6.88510750e-03]]\n",
      "FCM training RMSE: 766.2686308564029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[9.73556981e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.03616750e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.04598690e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.37759933e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.46638484e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.41207823e-03 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[9.73556981e-08 4.77910207e-08 1.57979444e-07 ... 3.51140260e-08\n",
      "  5.65146509e-06 2.47435179e-09]\n",
      " [7.03616750e-08 9.82280561e-09 2.25591359e-09 ... 2.60017212e-09\n",
      "  1.69134081e-07 6.36432076e-06]\n",
      " [5.04598690e-08 2.16954555e-08 2.86552008e-09 ... 3.00594427e-09\n",
      "  1.03198581e-06 9.95848904e-01]\n",
      " ...\n",
      " [2.37759933e-11 3.40547979e-10 2.88418299e-11 ... 7.08100235e-07\n",
      "  2.67973919e-11 6.54265600e-14]\n",
      " [4.46638484e-06 4.77592390e-07 1.11821506e-07 ... 1.90623579e-07\n",
      "  1.08532822e-05 3.66812993e-06]\n",
      " [5.41207823e-03 5.83603589e-06 1.08732518e-07 ... 4.06392137e-07\n",
      "  2.60428401e-06 1.18673686e-06]]\n",
      "FCM training RMSE: 749.0269344282273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[3.44061755e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.66382136e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.94533418e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.18847111e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.77419459e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.25609911e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[3.44061755e-08 6.49033024e-07 6.33458916e-06 ... 4.70939382e-06\n",
      "  1.24934635e-03 1.85801712e-07]\n",
      " [3.66382136e-09 2.76029951e-08 7.65359459e-04 ... 1.77207488e-08\n",
      "  4.50502955e-07 7.69164939e-09]\n",
      " [2.94533418e-09 1.63446852e-08 1.00152290e-05 ... 2.04464844e-09\n",
      "  5.25126518e-07 3.34772626e-09]\n",
      " ...\n",
      " [1.18847111e-06 4.31122561e-08 1.40768114e-12 ... 1.65955864e-11\n",
      "  9.63769131e-11 9.99997284e-01]\n",
      " [6.77419459e-08 9.11216713e-07 9.98660473e-01 ... 8.22252459e-07\n",
      "  2.32296373e-05 2.58815771e-07]\n",
      " [7.25609911e-07 3.89938714e-05 2.07278871e-04 ... 2.30550950e-06\n",
      "  1.80677498e-05 2.56750783e-06]]\n",
      "FCM training RMSE: 768.1888555747284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[3.05113519e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.64157037e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.65620745e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.21647785e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.50706056e-04 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.93990639e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[3.05113519e-09 2.21515191e-06 5.22531170e-10 ... 4.70059091e-08\n",
      "  2.72732254e-10 1.16907089e-08]\n",
      " [1.64157037e-05 2.07036500e-07 2.51528447e-04 ... 7.73642940e-08\n",
      "  8.86864639e-01 2.67732434e-08]\n",
      " [3.65620745e-09 6.82089016e-10 9.99941749e-01 ... 3.50370565e-11\n",
      "  1.23784333e-07 8.31050272e-12]\n",
      " ...\n",
      " [1.21647785e-11 1.08153137e-09 1.61897974e-12 ... 3.23753523e-07\n",
      "  6.57078330e-13 4.97988371e-07]\n",
      " [2.50706056e-04 1.05881409e-05 5.68189846e-05 ... 1.06299164e-05\n",
      "  7.77761093e-04 3.59145193e-06]\n",
      " [9.93990639e-01 2.39105906e-07 5.69459436e-07 ... 6.26682572e-06\n",
      "  6.29130348e-06 4.26820965e-07]]\n",
      "FCM training RMSE: 755.525390363631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[2.05025438e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.06709588e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.51113727e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.85078886e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.60644235e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.95145750e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[2.05025438e-06 5.24869891e-05 5.06968822e-08 ... 4.44785931e-07\n",
      "  4.99157648e-08 4.79735851e-06]\n",
      " [3.06709588e-08 2.96179017e-07 5.42250220e-08 ... 5.84098310e-08\n",
      "  8.79409594e-05 9.67486656e-07]\n",
      " [1.51113727e-08 3.91153900e-07 7.58761888e-08 ... 1.22052424e-08\n",
      "  2.89592176e-01 2.36043105e-06]\n",
      " ...\n",
      " [1.85078886e-11 5.18534659e-11 3.06579631e-10 ... 5.14498177e-07\n",
      "  1.52704698e-13 8.10783426e-11]\n",
      " [4.60644235e-07 5.67922515e-06 5.45831446e-07 ... 2.58945256e-06\n",
      "  4.94089798e-05 1.86486747e-05]\n",
      " [4.95145750e-08 2.46462864e-07 7.69140463e-07 ... 5.53923925e-07\n",
      "  5.00617389e-07 2.25793112e-06]]\n",
      "FCM training RMSE: 741.6593937236476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[3.78745879e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.68017061e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.74422069e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.24528655e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.05941315e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.68998905e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[3.78745879e-06 1.08858918e-06 2.08846272e-05 ... 3.51294865e-06\n",
      "  7.94659210e-09 5.34542026e-07]\n",
      " [6.68017061e-08 1.81924775e-08 3.90725954e-07 ... 3.49454218e-07\n",
      "  4.20139233e-06 3.23605246e-01]\n",
      " [3.74422069e-08 1.54660955e-08 2.09564723e-06 ... 7.24722907e-08\n",
      "  4.57501148e-02 2.74755799e-03]\n",
      " ...\n",
      " [1.24528655e-06 9.99972545e-01 8.49287208e-09 ... 2.02370721e-09\n",
      "  1.81027833e-12 7.34175134e-12]\n",
      " [3.05941315e-06 5.32754949e-07 7.48144410e-06 ... 2.50556335e-05\n",
      "  8.04113983e-07 1.37475307e-02]\n",
      " [1.68998905e-05 7.87704525e-07 8.54745537e-06 ... 1.36782710e-03\n",
      "  5.25435301e-07 1.94434845e-05]]\n",
      "FCM training RMSE: 747.7554707737422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[1.14089181e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.41664372e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.43812608e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.30335832e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.02340403e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.98281078e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[1.14089181e-08 1.67914614e-09 9.99984578e-01 ... 4.14703405e-09\n",
      "  5.58364656e-09 3.73966684e-06]\n",
      " [3.41664372e-09 2.45333648e-07 5.08031158e-07 ... 1.12347992e-05\n",
      "  1.06504613e-08 1.19064081e-04]\n",
      " [5.43812608e-09 2.11981154e-06 1.07935105e-07 ... 2.15044321e-06\n",
      "  2.33660725e-08 4.59928861e-06]\n",
      " ...\n",
      " [2.30335832e-11 1.92656405e-12 3.89372689e-11 ... 6.89230741e-13\n",
      "  5.21448594e-09 2.11615141e-12]\n",
      " [1.02340403e-07 2.31881432e-06 2.92008141e-04 ... 1.53396050e-04\n",
      "  4.14096336e-07 9.84710635e-01]\n",
      " [4.98281078e-08 5.98119673e-05 6.80892833e-06 ... 9.78851240e-01\n",
      "  1.05512259e-06 3.79404336e-05]]\n",
      "FCM training RMSE: 748.0510192829959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[1.69416035e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.47134877e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.88422931e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.93029021e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.05242527e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.65939674e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[1.69416035e-07 4.37337602e-08 5.62358514e-07 ... 1.10644687e-08\n",
      "  3.88895816e-06 3.50765931e-06]\n",
      " [5.47134877e-08 1.67129202e-05 4.18842052e-07 ... 3.18188296e-03\n",
      "  8.32481144e-07 3.55053461e-08]\n",
      " [5.88422931e-10 1.92511647e-07 3.58140052e-09 ... 2.92532235e-05\n",
      "  2.68351835e-07 6.20492733e-10]\n",
      " ...\n",
      " [3.93029021e-10 3.05393050e-13 2.26758308e-11 ... 4.80311834e-14\n",
      "  3.13876908e-11 4.12594351e-12]\n",
      " [1.05242527e-05 3.17652129e-04 1.05145411e-04 ... 7.49599907e-04\n",
      "  4.92835873e-05 2.97323562e-06]\n",
      " [7.65939674e-07 9.97568112e-01 1.86440585e-04 ... 4.12459818e-05\n",
      "  1.06637223e-06 6.33270134e-08]]\n",
      "FCM training RMSE: 757.6215696790584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[9.00227362e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.66334190e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.90539467e-10 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.06041023e-11 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.37540506e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.59961017e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[9.00227362e-07 1.21573922e-07 9.99974270e-01 ... 8.03670948e-06\n",
      "  3.74589094e-08 1.21782768e-07]\n",
      " [1.66334190e-08 1.75376292e-08 1.01143900e-06 ... 1.84798510e-07\n",
      "  7.32961484e-09 1.70547404e-07]\n",
      " [4.90539467e-10 9.63320666e-10 2.56576134e-08 ... 1.04194475e-07\n",
      "  8.08860319e-10 3.53150261e-09]\n",
      " ...\n",
      " [1.06041023e-11 3.09513531e-07 2.41093745e-11 ... 4.80253739e-11\n",
      "  9.99998805e-01 3.33751278e-11]\n",
      " [1.37540506e-06 1.92498364e-06 7.73192198e-04 ... 8.22185545e-06\n",
      "  4.45357780e-07 2.69679842e-05]\n",
      " [2.59961017e-07 1.72868150e-06 6.66711963e-06 ... 7.33177402e-07\n",
      "  2.92125942e-07 1.21874853e-03]]\n",
      "FCM training RMSE: 768.0890800899895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[3.26740714e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.80745479e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.93258178e-09 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.30041961e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.37920767e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [9.53352433e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[3.26740714e-08 8.45830447e-09 3.02408247e-09 ... 2.29670639e-08\n",
      "  4.69276714e-07 4.49410103e-06]\n",
      " [3.80745479e-08 4.98739051e-09 1.71433322e-05 ... 2.01702142e-08\n",
      "  1.77285924e-08 9.56074105e-05]\n",
      " [6.93258178e-09 1.42414134e-09 5.62017700e-07 ... 1.33309552e-09\n",
      "  1.35800865e-09 8.02095874e-07]\n",
      " ...\n",
      " [3.30041961e-08 1.87720919e-11 5.36516156e-13 ... 6.70410978e-07\n",
      "  1.90974756e-11 2.46370750e-12]\n",
      " [2.37920767e-06 1.15861643e-07 1.88656840e-04 ... 2.20617545e-06\n",
      "  1.00021873e-06 9.85075688e-01]\n",
      " [9.53352433e-06 6.26502603e-08 9.66845175e-01 ... 2.17632541e-06\n",
      "  3.66859834e-07 8.12359516e-05]]\n",
      "FCM training RMSE: 761.8289959556474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2256, 150)\n",
      "[[1.78371546e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.01796357e-08 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.01515113e-07 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.30639635e-12 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.29400488e-06 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.01340057e-05 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(2256, 25)\n",
      "[[1.78371546e-08 1.41276970e-09 2.05286346e-06 ... 1.61098609e-10\n",
      "  7.53575096e-09 9.99989941e-01]\n",
      " [4.01796357e-08 4.11921210e-09 1.23681094e-04 ... 1.79854306e-02\n",
      "  1.42534787e-07 5.64690498e-07]\n",
      " [1.01515113e-07 1.27531832e-08 9.65048068e-06 ... 5.87615958e-04\n",
      "  9.10772746e-08 2.69865955e-07]\n",
      " ...\n",
      " [1.30639635e-12 4.16825510e-10 9.21486899e-16 ... 1.82517975e-17\n",
      "  1.22788735e-14 1.72134467e-14]\n",
      " [2.29400488e-06 1.57789727e-07 9.87902790e-01 ... 9.78713734e-05\n",
      "  1.00854171e-05 2.74015319e-04]\n",
      " [2.01340057e-05 1.45668753e-07 3.68114283e-05 ... 1.66174572e-05\n",
      "  1.65302588e-02 6.08054127e-06]]\n",
      "FCM training RMSE: 748.0556058520451\n",
      "Number of rules: 2\n",
      "GP Train RMSE: 1908.092 ± 283.836\n",
      "GP Test RMSE: 1921.656 ± 275.861\n",
      "GP R2: -0.39 ± 0.349\n",
      "GP Time: 0.013 ± 0.008\n",
      "Number of rules: 3\n",
      "GP Train RMSE: 1566.108 ± 396.82\n",
      "GP Test RMSE: 1589.152 ± 385.735\n",
      "GP R2: 0.014 ± 0.474\n",
      "GP Time: 0.016 ± 0.006\n",
      "Number of rules: 4\n",
      "GP Train RMSE: 1333.874 ± 479.14\n",
      "GP Test RMSE: 1358.005 ± 469.609\n",
      "GP R2: 0.239 ± 0.533\n",
      "GP Time: 0.02 ± 0.012\n",
      "Number of rules: 5\n",
      "GP Train RMSE: 1170.033 ± 441.399\n",
      "GP Test RMSE: 1199.971 ± 430.987\n",
      "GP R2: 0.401 ± 0.484\n",
      "GP Time: 0.019 ± 0.008\n",
      "Number of rules: 8\n",
      "GP Train RMSE: 1428.359 ± 623.567\n",
      "GP Test RMSE: 1461.768 ± 599.617\n",
      "GP R2: 0.08 ± 0.646\n",
      "GP Time: 0.013 ± 0.01\n",
      "Number of rules: 10\n",
      "GP Train RMSE: 1032.675 ± 509.704\n",
      "GP Test RMSE: 1083.148 ± 489.144\n",
      "GP R2: 0.479 ± 0.523\n",
      "GP Time: 0.018 ± 0.011\n",
      "Number of rules: 15\n",
      "GP Train RMSE: 744.706 ± 4.854\n",
      "GP Test RMSE: 804.133 ± 4.764\n",
      "GP R2: 0.762 ± 0.003\n",
      "GP Time: 0.023 ± 0.008\n",
      "Number of rules: 20\n",
      "GP Train RMSE: 730.582 ± 3.489\n",
      "GP Test RMSE: 791.992 ± 3.577\n",
      "GP R2: 0.769 ± 0.002\n",
      "GP Time: 0.025 ± 0.014\n",
      "Number of rules: 25\n",
      "GP Train RMSE: 724.839 ± 3.699\n",
      "GP Test RMSE: 786.878 ± 2.865\n",
      "GP R2: 0.772 ± 0.002\n",
      "GP Time: 0.029 ± 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model\n",
    "gp_tsc_train_accuracy = []\n",
    "gp_tsc_test_accuracy = []\n",
    "tsc_train_accuracy = []\n",
    "tsc_test_accuracy = []\n",
    "gp_tsc_r2s = []\n",
    "gp_tsc_time = []\n",
    "gpr_tsc_model = None\n",
    "\n",
    "# From ts constant\n",
    "for number_of_rules in number_of_rules_array:\n",
    "    for fold in range(number_of_folds):\n",
    "        \n",
    "        kernel = 1.0 * Matern(length_scale=1e-1, nu=1.5)\n",
    "        gpr_tsc_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "        tsc_model = get_tsc_model(x_train, y_train, number_of_rules)\n",
    "        start_time = time.time()\n",
    "        gpr_tsc_model.fit(tsc_model.cen, tsc_model.predict(tsc_model.cen + 1e-8))\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        train_means = gpr_tsc_model.predict(x_train)\n",
    "        test_means = gpr_tsc_model.predict(x_test)\n",
    "        tsc_train_means = tsc_model.predict(x_train)\n",
    "        tsc_test_means = tsc_model.predict(x_test)\n",
    "\n",
    "        train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "        test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "        gp_tsc_train_accuracy.append(train_rmse)\n",
    "        gp_tsc_test_accuracy.append(test_rmse)\n",
    "        tsc_train_accuracy.append(root_mean_squared_error(y_train, tsc_train_means))\n",
    "        tsc_test_accuracy.append(root_mean_squared_error(y_test, tsc_test_means))\n",
    "        gp_r2 = r2_score(y_test, test_means)\n",
    "        gp_tsc_r2s.append(gp_r2)\n",
    "        gp_tsc_time.append(time_used)\n",
    "\n",
    "\n",
    "for idx, number_of_rules in enumerate(number_of_rules_array):\n",
    "    gp_train_accuracy_mean = np.round(np.mean(gp_tsc_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_train_accuracy_std = np.round(np.std(gp_tsc_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_mean = np.round(np.mean(gp_tsc_test_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_std = np.round(np.std(gp_tsc_test_accuracy[idx*10:idx*10+10]),3)\n",
    "    gp_r2_mean = np.round(np.mean(gp_tsc_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_r2_std = np.round(np.std(gp_tsc_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_time_mean = np.round(np.mean(gp_tsc_time[idx*10:idx*10+10]),3)\n",
    "    gp_time_std = np.round(np.std(gp_tsc_time[idx*10:idx*10+10]),3)\n",
    "\n",
    "    print(f\"Number of rules: {number_of_rules}\")\n",
    "    print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "    print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "    print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "    print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d1d833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 727.2435268056248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "FCM training RMSE: 727.2435230032165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 727.2435239613184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "FCM training RMSE: 727.2435302218879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 727.2435290222899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 727.2435255164033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 727.2435282888797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 727.2435258556926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "FCM training RMSE: 727.2435248788969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 727.2435224001367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "FCM training RMSE: 710.5560687947005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 710.5560658761917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 710.556064802779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "FCM training RMSE: 710.5560688782343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "FCM training RMSE: 710.5560807942414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 710.5560764377083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 710.5560646266442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 710.55606763696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 710.5560686982335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 710.5560778337577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step\n",
      "FCM training RMSE: 696.0571368068283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 709.9474541264411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 709.9474544181973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.0571376372687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 696.0571361444551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 709.947455548479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "FCM training RMSE: 696.0571375837613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.0571386247698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "FCM training RMSE: 706.0208390210921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 706.0208402640542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.5534209864181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "FCM training RMSE: 696.3628316143993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "FCM training RMSE: 706.119089860498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 696.5534196487081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 691.2228746905001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 710.4612885577039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 691.2228573161775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 696.5534126033541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 706.1190792944058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 696.5534208149129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800566345523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 690.5048907271532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800439259384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 694.4712822569785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800443218843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.1966026424608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800442742268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "FCM training RMSE: 687.0728279359927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.080044183913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 690.0800443254948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 684.7121332689195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 686.4405536914309\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 689.3582560422291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 684.7121317214832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.7121331733096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 687.2469694347494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 685.6269731753027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n",
      "FCM training RMSE: 684.7121482123323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 684.7121328580173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 687.1269859349377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 676.3791353635175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 678.5650270189205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 676.6199807418409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 675.6095297329291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 679.8975643827556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 680.1291834633445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 682.4010078789228\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 679.1991586384835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 675.8495297031285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 680.7179994146072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.6344918818187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.5466245098587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.5412692628244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 675.436922580166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 672.6422876161506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 674.2273179385277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 673.7731297413711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 670.8696807717051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 675.1311066800134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.9126874005759\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 667.8643333286457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 669.4056315133947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 671.27132317195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 669.6006533479921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.5345907664824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 667.2542948420335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 668.4954061952131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 670.2060008547625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 664.5247816740346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCM training RMSE: 665.1018996150169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Number of rules: 2\n",
      "GP Train RMSE: 1208.941 ± 0.001\n",
      "GP Test RMSE: 1238.014 ± 0.001\n",
      "GP R2: 0.435 ± 0.0\n",
      "GP Time: 0.025 ± 0.008\n",
      "TS NN R2: 0.977 ± 0.0\n",
      "Number of rules: 3\n",
      "GP Train RMSE: 2046.176 ± 15.333\n",
      "GP Test RMSE: 2056.494 ± 13.13\n",
      "GP R2: -0.56 ± 0.02\n",
      "GP Time: 0.009 ± 0.003\n",
      "TS NN R2: 0.942 ± 0.0\n",
      "Number of rules: 4\n",
      "GP Train RMSE: 1384.368 ± 428.7\n",
      "GP Test RMSE: 1406.793 ± 424.982\n",
      "GP R2: 0.204 ± 0.467\n",
      "GP Time: 0.025 ± 0.012\n",
      "TS NN R2: 0.936 ± 0.036\n",
      "Number of rules: 5\n",
      "GP Train RMSE: 1168.357 ± 338.036\n",
      "GP Test RMSE: 1194.197 ± 332.627\n",
      "GP R2: 0.433 ± 0.369\n",
      "GP Time: 0.026 ± 0.008\n",
      "TS NN R2: 0.897 ± 0.034\n",
      "Number of rules: 8\n",
      "GP Train RMSE: 823.414 ± 23.894\n",
      "GP Test RMSE: 877.559 ± 15.53\n",
      "GP R2: 0.716 ± 0.01\n",
      "GP Time: 0.031 ± 0.012\n",
      "TS NN R2: 0.958 ± 0.026\n",
      "Number of rules: 10\n",
      "GP Train RMSE: 797.757 ± 9.559\n",
      "GP Test RMSE: 862.969 ± 9.291\n",
      "GP R2: 0.725 ± 0.006\n",
      "GP Time: 0.048 ± 0.025\n",
      "TS NN R2: 0.983 ± 0.01\n",
      "Number of rules: 15\n",
      "GP Train RMSE: 767.48 ± 11.595\n",
      "GP Test RMSE: 830.036 ± 12.007\n",
      "GP R2: 0.746 ± 0.007\n",
      "GP Time: 0.066 ± 0.013\n",
      "TS NN R2: 0.969 ± 0.007\n",
      "Number of rules: 20\n",
      "GP Train RMSE: 749.351 ± 5.88\n",
      "GP Test RMSE: 816.092 ± 7.248\n",
      "GP R2: 0.754 ± 0.004\n",
      "GP Time: 0.056 ± 0.03\n",
      "TS NN R2: 0.97 ± 0.008\n",
      "Number of rules: 25\n",
      "GP Train RMSE: 756.419 ± 7.521\n",
      "GP Test RMSE: 820.794 ± 5.473\n",
      "GP R2: 0.752 ± 0.003\n",
      "GP Time: 0.029 ± 0.013\n",
      "TS NN R2: 0.959 ± 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\PPL\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# GPR model from NN\n",
    "gp_nn_tsl_train_accuracy = []\n",
    "gp_nn_tsl_test_accuracy = []\n",
    "gp_nn_tsl_r2s = []\n",
    "nn_tsl_r2s = []\n",
    "gp_nn_tsl_time = []\n",
    "gpr_nn_tsl_model = None\n",
    "\n",
    "# From NN and ts linear\n",
    "for number_of_rules in number_of_rules_array:\n",
    "    for fold in range(number_of_folds):\n",
    "        \n",
    "        kernel = 1.0 * Matern(length_scale=1.0, nu=1.5)\n",
    "        gpr_nn_tsl_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, normalize_y=False)\n",
    "        tsl_model = get_tsl_model(x_train, y_train, number_of_rules)\n",
    "\n",
    "        start_time = time.time()\n",
    "        inputs = tsl_model.cen\n",
    "        ts_predictions = tsl_model.predict(tsl_model.cen + 1e-8)\n",
    "        nn_predictions = nn_model.predict(inputs)\n",
    "        gpr_nn_tsl_model.fit(inputs, nn_predictions)\n",
    "        time_used = time.time() - start_time\n",
    "\n",
    "        train_means = gpr_nn_tsl_model.predict(x_train)\n",
    "        test_means = gpr_nn_tsl_model.predict(x_test)\n",
    "\n",
    "        train_rmse = root_mean_squared_error(y_train, train_means)\n",
    "        test_rmse = root_mean_squared_error(y_test, test_means)\n",
    "\n",
    "        gp_nn_tsl_train_accuracy.append(train_rmse)\n",
    "        gp_nn_tsl_test_accuracy.append(test_rmse)\n",
    "        gp_r2 = r2_score(y_test, test_means)\n",
    "        gp_nn_tsl_r2s.append(gp_r2)\n",
    "        gp_nn_tsl_time.append(time_used)\n",
    "        nn_tsl_r2s.append(r2_score(ts_predictions, nn_predictions))\n",
    "\n",
    "for idx, number_of_rules in enumerate(number_of_rules_array):\n",
    "    gp_train_accuracy_mean = np.round(np.mean(gp_nn_tsl_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_train_accuracy_std = np.round(np.std(gp_nn_tsl_train_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_mean = np.round(np.mean(gp_nn_tsl_test_accuracy[idx*10:idx*10+10]), 3)\n",
    "    gp_test_accuracy_std = np.round(np.std(gp_nn_tsl_test_accuracy[idx*10:idx*10+10]),3)\n",
    "    gp_r2_mean = np.round(np.mean(gp_nn_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_r2_std = np.round(np.std(gp_nn_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "    gp_time_mean = np.round(np.mean(gp_nn_tsl_time[idx*10:idx*10+10]),3)\n",
    "    gp_time_std = np.round(np.std(gp_nn_tsl_time[idx*10:idx*10+10]),3)\n",
    "    nn_ts_r2_mean = np.round(np.mean(nn_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "    nn_ts_r2_std = np.round(np.std(nn_tsl_r2s[idx*10:idx*10+10]),3)\n",
    "\n",
    "    print(f\"Number of rules: {number_of_rules}\")\n",
    "    print(f\"GP Train RMSE: {gp_train_accuracy_mean} ± {gp_train_accuracy_std}\")\n",
    "    print(f\"GP Test RMSE: {gp_test_accuracy_mean} ± {gp_test_accuracy_std}\")\n",
    "    print(f\"GP R2: {gp_r2_mean} ± {gp_r2_std}\")\n",
    "    print(f\"GP Time: {gp_time_mean} ± {gp_time_std}\")\n",
    "    print(f\"TS NN R2: {nn_ts_r2_mean} ± {nn_ts_r2_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45b0fc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "number_of_rules_array_strings = [str(number) for number in number_of_rules_array]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_nn_tsl_train_accuracy).reshape(-1, 10), axis=1), '--o', label='GP-NN')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_tsl_train_accuracy).reshape(-1, 10), axis=1), '--v', label='GP-TSL')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_tsc_train_accuracy).reshape(-1, 10), axis=1), '--s', label='GP-TSC')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsc_train_accuracy).reshape(-1, 10), axis=1), '-.s', label='TSC')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsl_train_accuracy).reshape(-1, 10), axis=1), '-.v', label='TSL')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "14f97076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "number_of_rules_array_strings = [str(number) for number in number_of_rules_array]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_nn_tsl_test_accuracy).reshape(-1, 10), axis=1), '--o', label='GP-NN')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_tsl_test_accuracy).reshape(-1, 10), axis=1), '--v', label='GP-TSL')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(gp_tsc_test_accuracy).reshape(-1, 10), axis=1), '--s', label='GP-TSC')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsc_test_accuracy).reshape(-1, 10), axis=1), '-.s', label='TSC')\n",
    "ax.plot(number_of_rules_array_strings, np.mean(np.array(tsl_test_accuracy).reshape(-1, 10), axis=1), '-.v', label='TSL')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
